{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b8c12f4",
   "metadata": {},
   "source": [
    "# CAPSTONE: Modeling and Evaluation\n",
    "\n",
    "**Storm Intensity Change Prediction**<br><br>\n",
    "**Author: Ishan Singh Bhullar**<br>\n",
    "**Date: 11 December 2022**<br>\n",
    "**Contact: ishanbhullar@gmail.com**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6499e55",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#Introduction)<br><br>\n",
    "2. [Modeling and Evaluation](#Modeling-and-Evaluation)<br><br>\n",
    "    - [X (features) and y (target)](#X-(features)-and-y-(target))<br><br>\n",
    "    - [Test, Train, Validation Split](#Test,-Train,-Validation-Split)<br><br>\n",
    "    - [Statsmodels Logistic Regression](#Statsmodels-Logistic-Regression)<br><br>\n",
    "    - [Logistic Regression Model](#Logistic-Regression-Model)<br><br>\n",
    "    - [Random Forest](#Random-Forest)<br><br>\n",
    "    - [XGBoost Model](#XGBoost-Model)<br><br>\n",
    "3. [Summary](#Summary)<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9cb31e",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8db213f",
   "metadata": {},
   "source": [
    "In this notebook, I will be training various models to effectively predict the target variable. Let's start by stating/describing the target variable and variable features. \n",
    "\n",
    "The target variable is called `intensity_delta` and it is an engineered label based on whether current storm conditions cause an increase (1 for increase, 0 for no increase) in surface winds 6 hours in the future. This can be an effective first step in gauging whether a storm is intensifying or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb945ae",
   "metadata": {},
   "source": [
    "### Models Used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6fc648",
   "metadata": {},
   "source": [
    "I will be training the following models in this notebook to work towards the goal of predicting the target variable:\n",
    "1. Logistic Regression - I don't have high hopes for this model as the data is quite non-linear in nature. This will help set up a base model to compare others against.\n",
    "2. Decision Trees - This model should fare better in theory due to its ability to map non-linear boundaries. \n",
    "3. Random Forests and XGBoost (Gradient Boosted Decision Trees) - These should be the most promising, delivering the best results. However, I will have to be careful with hyperparamter optimization to prevent overfitting which these models are quite prone to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d5db18",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec8ac56",
   "metadata": {},
   "source": [
    "When predicting calamitous events, it is important to not miss one in order to minimize casualties.. At the same time, false alarms can be very expensive economically. For evaluation I want to balance between minimizing False Positives and False Negatives. I will be using the following metrics to evaluate models:\n",
    "- Accuracy Scores - How well the model predicts the target variable.\n",
    "- Recall (True Positive Rate) - The ratio of correct positive predictions to total postive values.\n",
    "$$R=\\frac{TP}{TP+FN}$$\n",
    "- Precision - The ratio of correct positive predictions to total positive predictions.\n",
    "$$R=\\frac{TP}{TP+FP}$$\n",
    "- F1 Score - The harmonic mean of Recall and Precision. USeful to try and balance Precision and Recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a8e0c0",
   "metadata": {},
   "source": [
    "### Importing Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9aba7449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1a6484ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "81e31467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, precision_score, recall_score, classification_report\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349ab023",
   "metadata": {},
   "source": [
    "### Custom Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bf535f",
   "metadata": {},
   "source": [
    "#### Runtime Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b65aac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(started=None):\n",
    "    '''\n",
    "    A simple function to print runtime of a line or block of lines of code and return the resulting\n",
    "    datetime.timedelta variable.\n",
    "    \n",
    "    It accepts one datetime parameter which is used in an If loop to decide\n",
    "    whether the timer is starting or stopping.\n",
    "    \n",
    "    Parameters\n",
    "    ---------------\n",
    "    started: datetime type\n",
    "        Default value = False\n",
    "        \n",
    "    Returns\n",
    "    ---------------\n",
    "    If started parameter is None, returns current time.\n",
    "    If started parameter is not None:\n",
    "        1. prints runtime of code \n",
    "        2. datetime.timedelta variable.\n",
    "    '''  \n",
    "    if started==None:\n",
    "        return datetime.now()\n",
    "    else:\n",
    "        end = datetime.now()\n",
    "        runtime = end - started\n",
    "        print(f'The runtime of your code is: {runtime} (h:mm:ss)')\n",
    "        return runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a31d1d5",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75f68d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.read_csv(\"\\data\\model_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d187e2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>dist2land</th>\n",
       "      <th>wind_surface</th>\n",
       "      <th>pressure_surface</th>\n",
       "      <th>category</th>\n",
       "      <th>storm_speed</th>\n",
       "      <th>storm_dir</th>\n",
       "      <th>geo_250</th>\n",
       "      <th>...</th>\n",
       "      <th>u_dir_550</th>\n",
       "      <th>v_wind_550</th>\n",
       "      <th>v_dir_550</th>\n",
       "      <th>geo_850</th>\n",
       "      <th>u_wind_850</th>\n",
       "      <th>u_dir_850</th>\n",
       "      <th>v_wind_850</th>\n",
       "      <th>v_dir_850</th>\n",
       "      <th>wind_lag</th>\n",
       "      <th>intensity_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1959-06-01 00:00:00</td>\n",
       "      <td>32.1000</td>\n",
       "      <td>-90.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>depression</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>106941.04</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.103929</td>\n",
       "      <td>1</td>\n",
       "      <td>14684.576</td>\n",
       "      <td>1.299480</td>\n",
       "      <td>1</td>\n",
       "      <td>2.507897</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1959-06-01 03:00:00</td>\n",
       "      <td>32.2799</td>\n",
       "      <td>-90.2298</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>depression</td>\n",
       "      <td>6</td>\n",
       "      <td>59</td>\n",
       "      <td>106903.90</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.907968</td>\n",
       "      <td>0</td>\n",
       "      <td>14733.608</td>\n",
       "      <td>0.864694</td>\n",
       "      <td>1</td>\n",
       "      <td>2.880090</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1959-06-01 06:00:00</td>\n",
       "      <td>32.4000</td>\n",
       "      <td>-89.9000</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>depression</td>\n",
       "      <td>6</td>\n",
       "      <td>69</td>\n",
       "      <td>106783.48</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.847706</td>\n",
       "      <td>0</td>\n",
       "      <td>14732.032</td>\n",
       "      <td>2.117519</td>\n",
       "      <td>1</td>\n",
       "      <td>3.888728</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1959-06-01 09:00:00</td>\n",
       "      <td>32.5150</td>\n",
       "      <td>-89.5150</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>depression</td>\n",
       "      <td>7</td>\n",
       "      <td>74</td>\n",
       "      <td>106455.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.913183</td>\n",
       "      <td>0</td>\n",
       "      <td>14646.824</td>\n",
       "      <td>3.203289</td>\n",
       "      <td>1</td>\n",
       "      <td>2.605515</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1959-06-01 12:00:00</td>\n",
       "      <td>32.6000</td>\n",
       "      <td>-89.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>depression</td>\n",
       "      <td>7</td>\n",
       "      <td>78</td>\n",
       "      <td>106473.04</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.893531</td>\n",
       "      <td>1</td>\n",
       "      <td>14696.572</td>\n",
       "      <td>2.416132</td>\n",
       "      <td>1</td>\n",
       "      <td>0.628975</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time      lat      lon  dist2land  wind_surface  \\\n",
       "0  1959-06-01 00:00:00  32.1000 -90.5000          0          25.0   \n",
       "1  1959-06-01 03:00:00  32.2799 -90.2298          0          25.0   \n",
       "2  1959-06-01 06:00:00  32.4000 -89.9000          0          25.0   \n",
       "3  1959-06-01 09:00:00  32.5150 -89.5150          0          25.0   \n",
       "4  1959-06-01 12:00:00  32.6000 -89.1000          0          25.0   \n",
       "\n",
       "   pressure_surface    category  storm_speed  storm_dir    geo_250  ...  \\\n",
       "0            1008.0  depression            6         42  106941.04  ...   \n",
       "1            1008.0  depression            6         59  106903.90  ...   \n",
       "2            1008.0  depression            6         69  106783.48  ...   \n",
       "3            1008.0  depression            7         74  106455.28  ...   \n",
       "4            1008.0  depression            7         78  106473.04  ...   \n",
       "\n",
       "   u_dir_550  v_wind_550  v_dir_550    geo_850  u_wind_850  u_dir_850  \\\n",
       "0          1    0.103929          1  14684.576    1.299480          1   \n",
       "1          1    1.907968          0  14733.608    0.864694          1   \n",
       "2          1    2.847706          0  14732.032    2.117519          1   \n",
       "3          0    1.913183          0  14646.824    3.203289          1   \n",
       "4          1    1.893531          1  14696.572    2.416132          1   \n",
       "\n",
       "   v_wind_850  v_dir_850  wind_lag  intensity_delta  \n",
       "0    2.507897          1      25.0              0.0  \n",
       "1    2.880090          1      25.0              0.0  \n",
       "2    3.888728          1      25.0              0.0  \n",
       "3    2.605515          1      25.0              0.0  \n",
       "4    0.628975          1      25.0              0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3966ad08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27531 entries, 0 to 28797\n",
      "Data columns (total 26 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   time              27531 non-null  object \n",
      " 1   lat               27531 non-null  float64\n",
      " 2   lon               27531 non-null  float64\n",
      " 3   dist2land         27531 non-null  int64  \n",
      " 4   wind_surface      27531 non-null  float64\n",
      " 5   pressure_surface  27531 non-null  float64\n",
      " 6   category          27531 non-null  object \n",
      " 7   storm_speed       27531 non-null  int64  \n",
      " 8   storm_dir         27531 non-null  int64  \n",
      " 9   geo_250           27531 non-null  float64\n",
      " 10  u_wind_250        27531 non-null  float64\n",
      " 11  u_dir_250         27531 non-null  int64  \n",
      " 12  v_wind_250        27531 non-null  float64\n",
      " 13  v_dir_250         27531 non-null  int64  \n",
      " 14  geo_550           27531 non-null  float64\n",
      " 15  u_wind_550        27531 non-null  float64\n",
      " 16  u_dir_550         27531 non-null  int64  \n",
      " 17  v_wind_550        27531 non-null  float64\n",
      " 18  v_dir_550         27531 non-null  int64  \n",
      " 19  geo_850           27531 non-null  float64\n",
      " 20  u_wind_850        27531 non-null  float64\n",
      " 21  u_dir_850         27531 non-null  int64  \n",
      " 22  v_wind_850        27531 non-null  float64\n",
      " 23  v_dir_850         27531 non-null  int64  \n",
      " 24  wind_lag          27531 non-null  float64\n",
      " 25  intensity_delta   27531 non-null  float64\n",
      "dtypes: float64(15), int64(9), object(2)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "model_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc93424",
   "metadata": {},
   "source": [
    "Everything looks fine, we just have to change the `time` column to datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97e93354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27531 entries, 0 to 28797\n",
      "Data columns (total 26 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   time              27531 non-null  datetime64[ns]\n",
      " 1   lat               27531 non-null  float64       \n",
      " 2   lon               27531 non-null  float64       \n",
      " 3   dist2land         27531 non-null  int64         \n",
      " 4   wind_surface      27531 non-null  float64       \n",
      " 5   pressure_surface  27531 non-null  float64       \n",
      " 6   category          27531 non-null  object        \n",
      " 7   storm_speed       27531 non-null  int64         \n",
      " 8   storm_dir         27531 non-null  int64         \n",
      " 9   geo_250           27531 non-null  float64       \n",
      " 10  u_wind_250        27531 non-null  float64       \n",
      " 11  u_dir_250         27531 non-null  int64         \n",
      " 12  v_wind_250        27531 non-null  float64       \n",
      " 13  v_dir_250         27531 non-null  int64         \n",
      " 14  geo_550           27531 non-null  float64       \n",
      " 15  u_wind_550        27531 non-null  float64       \n",
      " 16  u_dir_550         27531 non-null  int64         \n",
      " 17  v_wind_550        27531 non-null  float64       \n",
      " 18  v_dir_550         27531 non-null  int64         \n",
      " 19  geo_850           27531 non-null  float64       \n",
      " 20  u_wind_850        27531 non-null  float64       \n",
      " 21  u_dir_850         27531 non-null  int64         \n",
      " 22  v_wind_850        27531 non-null  float64       \n",
      " 23  v_dir_850         27531 non-null  int64         \n",
      " 24  wind_lag          27531 non-null  float64       \n",
      " 25  intensity_delta   27531 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(15), int64(9), object(1)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# convert column to datetime format\n",
    "model_df['time'] = pd.to_datetime(model_df['time'])\n",
    "model_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f799dfb0",
   "metadata": {},
   "source": [
    "Column converted successfully. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c6a772",
   "metadata": {},
   "source": [
    "### Encoding Non-Numeric Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267213b6",
   "metadata": {},
   "source": [
    "There is only one non-numerica data column in the dataset - `category`. It consists of three classes: 'depression, 'storm' and 'severe'. We can go with dummy encoding for this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1be7cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy or one hot encoding `category` column\n",
    "model_df = pd.get_dummies(model_df, columns=['category'], prefix='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "34bf1b91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27531 entries, 0 to 28797\n",
      "Data columns (total 28 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   time                 27531 non-null  datetime64[ns]\n",
      " 1   lat                  27531 non-null  float64       \n",
      " 2   lon                  27531 non-null  float64       \n",
      " 3   dist2land            27531 non-null  int64         \n",
      " 4   wind_surface         27531 non-null  float64       \n",
      " 5   pressure_surface     27531 non-null  float64       \n",
      " 6   storm_speed          27531 non-null  int64         \n",
      " 7   storm_dir            27531 non-null  int64         \n",
      " 8   geo_250              27531 non-null  float64       \n",
      " 9   u_wind_250           27531 non-null  float64       \n",
      " 10  u_dir_250            27531 non-null  int64         \n",
      " 11  v_wind_250           27531 non-null  float64       \n",
      " 12  v_dir_250            27531 non-null  int64         \n",
      " 13  geo_550              27531 non-null  float64       \n",
      " 14  u_wind_550           27531 non-null  float64       \n",
      " 15  u_dir_550            27531 non-null  int64         \n",
      " 16  v_wind_550           27531 non-null  float64       \n",
      " 17  v_dir_550            27531 non-null  int64         \n",
      " 18  geo_850              27531 non-null  float64       \n",
      " 19  u_wind_850           27531 non-null  float64       \n",
      " 20  u_dir_850            27531 non-null  int64         \n",
      " 21  v_wind_850           27531 non-null  float64       \n",
      " 22  v_dir_850            27531 non-null  int64         \n",
      " 23  wind_lag             27531 non-null  float64       \n",
      " 24  intensity_delta      27531 non-null  float64       \n",
      " 25  category_depression  27531 non-null  uint8         \n",
      " 26  category_severe      27531 non-null  uint8         \n",
      " 27  category_storm       27531 non-null  uint8         \n",
      "dtypes: datetime64[ns](1), float64(15), int64(9), uint8(3)\n",
      "memory usage: 5.5 MB\n"
     ]
    }
   ],
   "source": [
    "model_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cc063458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'lat', 'lon', 'dist2land', 'wind_surface', 'pressure_surface',\n",
       "       'storm_speed', 'storm_dir', 'geo_250', 'u_wind_250', 'u_dir_250',\n",
       "       'v_wind_250', 'v_dir_250', 'geo_550', 'u_wind_550', 'u_dir_550',\n",
       "       'v_wind_550', 'v_dir_550', 'geo_850', 'u_wind_850', 'u_dir_850',\n",
       "       'v_wind_850', 'v_dir_850', 'wind_lag', 'intensity_delta',\n",
       "       'category_depression', 'category_severe', 'category_storm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5177e4a",
   "metadata": {},
   "source": [
    "We need to drop one of the dummy columns to avoid multi-collinearity. Let's drop the `category_severe` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d5175a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'lat', 'lon', 'dist2land', 'wind_surface', 'pressure_surface',\n",
       "       'storm_speed', 'storm_dir', 'geo_250', 'u_wind_250', 'u_dir_250',\n",
       "       'v_wind_250', 'v_dir_250', 'geo_550', 'u_wind_550', 'u_dir_550',\n",
       "       'v_wind_550', 'v_dir_550', 'geo_850', 'u_wind_850', 'u_dir_850',\n",
       "       'v_wind_850', 'v_dir_850', 'wind_lag', 'intensity_delta',\n",
       "       'category_depression', 'category_storm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping column\n",
    "model_df.drop(columns='category_severe', inplace=True)\n",
    "model_df.columns #sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624aabe3",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4118aee",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da3513b",
   "metadata": {},
   "source": [
    "### X (features) and y (target)\n",
    "\n",
    "Let's start by declaring the features and target label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "26f2d594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'lat', 'lon', 'dist2land', 'wind_surface', 'pressure_surface',\n",
       "       'storm_speed', 'storm_dir', 'geo_250', 'u_wind_250', 'u_dir_250',\n",
       "       'v_wind_250', 'v_dir_250', 'geo_550', 'u_wind_550', 'u_dir_550',\n",
       "       'v_wind_550', 'v_dir_550', 'geo_850', 'u_wind_850', 'u_dir_850',\n",
       "       'v_wind_850', 'v_dir_850', 'wind_lag', 'intensity_delta',\n",
       "       'category_depression', 'category_storm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426172cb",
   "metadata": {},
   "source": [
    "I will not be including any of the 550hPa variables as they are closely correlated to 250hPa and 850hPa variables as we saw in the EDA Notebook. Further, since we are trying to predict change in intensity of surface wind, I will keep the `wind_surface` feature and drop `pressure_surface` feature (as they have an almost perfect correlation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1d7e5206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lat', 'lon', 'dist2land', 'wind_surface', 'storm_speed', 'storm_dir',\n",
       "       'geo_250', 'u_wind_250', 'u_dir_250', 'v_wind_250', 'v_dir_250',\n",
       "       'geo_850', 'u_wind_850', 'u_dir_850', 'v_wind_850', 'v_dir_850',\n",
       "       'category_depression', 'category_storm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = model_df.drop(columns=['time', 'pressure_surface', 'geo_550', 'u_wind_550', \n",
    "                           'u_dir_550', 'v_wind_550', 'v_dir_550', 'wind_lag', 'intensity_delta'])\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ea04c2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intensity_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28793</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28794</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28795</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28796</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28797</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27531 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       intensity_delta\n",
       "0                  0.0\n",
       "1                  0.0\n",
       "2                  0.0\n",
       "3                  0.0\n",
       "4                  0.0\n",
       "...                ...\n",
       "28793              0.0\n",
       "28794              0.0\n",
       "28795              0.0\n",
       "28796              0.0\n",
       "28797              0.0\n",
       "\n",
       "[27531 rows x 1 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model_df[['intensity_delta']]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07df4ebe",
   "metadata": {},
   "source": [
    "### Test, Train, Validation Split\n",
    "\n",
    "First, I will split the features and labels into test and remainder sets. This is done to prevent data leakage which can bias the results of our models. We will then split the remainder set further into train and validation sets. This is done so that we can keep the test set completely hidden from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8a3a67ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the split ratio\n",
    "split_ratio = 0.25 # 25% of data goes into test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a8a066e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_remainder, X_test, y_remainder, y_test = train_test_split(X, y, \n",
    "                                                            test_size=split_ratio, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "de192b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "X.shape[0] == X_remainder.shape[0] + X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3423794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X_remainder, y_remainder, \n",
    "                                                                test_size=split_ratio, stratify=y_remainder, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "03b25274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "X_remainder.shape[0] == X_train.shape[0] + X_validation.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fb6f19",
   "metadata": {},
   "source": [
    "I will start with a statsmodels Logistic Regression model. This, in addition to the correlation matrix from the EDA Notebook, will allow me to get a closer look at the variables and decide which ones to feature in more advanced models. Since, we are not interested in accuracy scores, I will forego the scaling for this step. Let's use the remainder data set for this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3fbcb7",
   "metadata": {},
   "source": [
    "### Statsmodels Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c35d3c",
   "metadata": {},
   "source": [
    "#### Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f13f0517",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>dist2land</th>\n",
       "      <th>wind_surface</th>\n",
       "      <th>storm_speed</th>\n",
       "      <th>storm_dir</th>\n",
       "      <th>geo_250</th>\n",
       "      <th>u_wind_250</th>\n",
       "      <th>u_dir_250</th>\n",
       "      <th>v_wind_250</th>\n",
       "      <th>v_dir_250</th>\n",
       "      <th>geo_850</th>\n",
       "      <th>u_wind_850</th>\n",
       "      <th>u_dir_850</th>\n",
       "      <th>v_wind_850</th>\n",
       "      <th>v_dir_850</th>\n",
       "      <th>category_depression</th>\n",
       "      <th>category_storm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>-58.8000</td>\n",
       "      <td>736</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>106635.88</td>\n",
       "      <td>16.072563</td>\n",
       "      <td>1</td>\n",
       "      <td>8.375745</td>\n",
       "      <td>0</td>\n",
       "      <td>14826.376</td>\n",
       "      <td>0.543960</td>\n",
       "      <td>0</td>\n",
       "      <td>1.580342</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22770</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.269</td>\n",
       "      <td>-38.2722</td>\n",
       "      <td>1765</td>\n",
       "      <td>72.0</td>\n",
       "      <td>24</td>\n",
       "      <td>358</td>\n",
       "      <td>105226.94</td>\n",
       "      <td>1.256100</td>\n",
       "      <td>0</td>\n",
       "      <td>18.352348</td>\n",
       "      <td>1</td>\n",
       "      <td>14019.216</td>\n",
       "      <td>1.029442</td>\n",
       "      <td>1</td>\n",
       "      <td>11.933826</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25076</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.300</td>\n",
       "      <td>-50.6000</td>\n",
       "      <td>918</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13</td>\n",
       "      <td>282</td>\n",
       "      <td>107423.66</td>\n",
       "      <td>7.818411</td>\n",
       "      <td>0</td>\n",
       "      <td>0.428727</td>\n",
       "      <td>0</td>\n",
       "      <td>14747.231</td>\n",
       "      <td>1.195222</td>\n",
       "      <td>1</td>\n",
       "      <td>5.580057</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13092</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.200</td>\n",
       "      <td>-42.8000</td>\n",
       "      <td>1535</td>\n",
       "      <td>85.0</td>\n",
       "      <td>18</td>\n",
       "      <td>83</td>\n",
       "      <td>105825.46</td>\n",
       "      <td>15.006169</td>\n",
       "      <td>1</td>\n",
       "      <td>1.166901</td>\n",
       "      <td>0</td>\n",
       "      <td>13498.480</td>\n",
       "      <td>5.785726</td>\n",
       "      <td>1</td>\n",
       "      <td>3.113857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9261</th>\n",
       "      <td>1.0</td>\n",
       "      <td>25.300</td>\n",
       "      <td>-96.8000</td>\n",
       "      <td>51</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>107191.97</td>\n",
       "      <td>3.097380</td>\n",
       "      <td>1</td>\n",
       "      <td>0.955518</td>\n",
       "      <td>0</td>\n",
       "      <td>14183.869</td>\n",
       "      <td>1.004887</td>\n",
       "      <td>1</td>\n",
       "      <td>3.435564</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       const     lat      lon  dist2land  wind_surface  storm_speed  \\\n",
       "2577     1.0  20.000 -58.8000        736          25.0           10   \n",
       "22770    1.0  35.269 -38.2722       1765          72.0           24   \n",
       "25076    1.0  13.300 -50.6000        918          35.0           13   \n",
       "13092    1.0  35.200 -42.8000       1535          85.0           18   \n",
       "9261     1.0  25.300 -96.8000         51          50.0            9   \n",
       "\n",
       "       storm_dir    geo_250  u_wind_250  u_dir_250  v_wind_250  v_dir_250  \\\n",
       "2577          42  106635.88   16.072563          1    8.375745          0   \n",
       "22770        358  105226.94    1.256100          0   18.352348          1   \n",
       "25076        282  107423.66    7.818411          0    0.428727          0   \n",
       "13092         83  105825.46   15.006169          1    1.166901          0   \n",
       "9261          31  107191.97    3.097380          1    0.955518          0   \n",
       "\n",
       "         geo_850  u_wind_850  u_dir_850  v_wind_850  v_dir_850  \\\n",
       "2577   14826.376    0.543960          0    1.580342          1   \n",
       "22770  14019.216    1.029442          1   11.933826          1   \n",
       "25076  14747.231    1.195222          1    5.580057          1   \n",
       "13092  13498.480    5.785726          1    3.113857          0   \n",
       "9261   14183.869    1.004887          1    3.435564          1   \n",
       "\n",
       "       category_depression  category_storm  \n",
       "2577                     1               0  \n",
       "22770                    0               1  \n",
       "25076                    0               1  \n",
       "13092                    0               1  \n",
       "9261                     0               1  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to manually add an intercept for statsmodels logit\n",
    "X_train_wc = sm.add_constant(X_train)\n",
    "X_train_wc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1192a8e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.584233\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>intensity_delta</td> <th>  No. Observations:  </th>   <td> 15486</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td> 15467</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>    18</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 11 Dec 2022</td> <th>  Pseudo R-squ.:     </th>   <td>0.05587</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>22:09:10</td>     <th>  Log-Likelihood:    </th>  <td> -9047.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -9582.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>4.978e-216</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>   21.3124</td> <td>    3.189</td> <td>    6.683</td> <td> 0.000</td> <td>   15.062</td> <td>   27.563</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lat</th>                 <td>   -0.0455</td> <td>    0.003</td> <td>  -13.845</td> <td> 0.000</td> <td>   -0.052</td> <td>   -0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lon</th>                 <td>   -0.0119</td> <td>    0.002</td> <td>   -7.777</td> <td> 0.000</td> <td>   -0.015</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dist2land</th>           <td> 7.833e-05</td> <td> 4.59e-05</td> <td>    1.706</td> <td> 0.088</td> <td>-1.17e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wind_surface</th>        <td>   -0.0039</td> <td>    0.001</td> <td>   -2.790</td> <td> 0.005</td> <td>   -0.007</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>storm_speed</th>         <td>    0.0239</td> <td>    0.004</td> <td>    5.931</td> <td> 0.000</td> <td>    0.016</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>storm_dir</th>           <td>   -0.0008</td> <td>    0.000</td> <td>   -3.870</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>geo_250</th>             <td>   -0.0002</td> <td> 3.24e-05</td> <td>   -7.428</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>u_wind_250</th>          <td>   -0.0147</td> <td>    0.004</td> <td>   -3.401</td> <td> 0.001</td> <td>   -0.023</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>u_dir_250</th>           <td>   -0.3125</td> <td>    0.044</td> <td>   -7.131</td> <td> 0.000</td> <td>   -0.398</td> <td>   -0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>v_wind_250</th>          <td>   -0.0406</td> <td>    0.005</td> <td>   -8.495</td> <td> 0.000</td> <td>   -0.050</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>v_dir_250</th>           <td>    0.1720</td> <td>    0.042</td> <td>    4.087</td> <td> 0.000</td> <td>    0.090</td> <td>    0.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>geo_850</th>             <td>    0.0003</td> <td> 5.23e-05</td> <td>    6.293</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>u_wind_850</th>          <td>   -0.0385</td> <td>    0.007</td> <td>   -5.490</td> <td> 0.000</td> <td>   -0.052</td> <td>   -0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>u_dir_850</th>           <td>    0.1287</td> <td>    0.049</td> <td>    2.604</td> <td> 0.009</td> <td>    0.032</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>v_wind_850</th>          <td>   -0.0178</td> <td>    0.008</td> <td>   -2.317</td> <td> 0.021</td> <td>   -0.033</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>v_dir_850</th>           <td>    0.0885</td> <td>    0.045</td> <td>    1.988</td> <td> 0.047</td> <td>    0.001</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>category_depression</th> <td>   -1.1009</td> <td>    0.141</td> <td>   -7.811</td> <td> 0.000</td> <td>   -1.377</td> <td>   -0.825</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>category_storm</th>      <td>    0.0551</td> <td>    0.111</td> <td>    0.497</td> <td> 0.619</td> <td>   -0.162</td> <td>    0.272</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:        intensity_delta   No. Observations:                15486\n",
       "Model:                          Logit   Df Residuals:                    15467\n",
       "Method:                           MLE   Df Model:                           18\n",
       "Date:                Sun, 11 Dec 2022   Pseudo R-squ.:                 0.05587\n",
       "Time:                        22:09:10   Log-Likelihood:                -9047.4\n",
       "converged:                       True   LL-Null:                       -9582.9\n",
       "Covariance Type:            nonrobust   LLR p-value:                4.978e-216\n",
       "=======================================================================================\n",
       "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                  21.3124      3.189      6.683      0.000      15.062      27.563\n",
       "lat                    -0.0455      0.003    -13.845      0.000      -0.052      -0.039\n",
       "lon                    -0.0119      0.002     -7.777      0.000      -0.015      -0.009\n",
       "dist2land            7.833e-05   4.59e-05      1.706      0.088   -1.17e-05       0.000\n",
       "wind_surface           -0.0039      0.001     -2.790      0.005      -0.007      -0.001\n",
       "storm_speed             0.0239      0.004      5.931      0.000       0.016       0.032\n",
       "storm_dir              -0.0008      0.000     -3.870      0.000      -0.001      -0.000\n",
       "geo_250                -0.0002   3.24e-05     -7.428      0.000      -0.000      -0.000\n",
       "u_wind_250             -0.0147      0.004     -3.401      0.001      -0.023      -0.006\n",
       "u_dir_250              -0.3125      0.044     -7.131      0.000      -0.398      -0.227\n",
       "v_wind_250             -0.0406      0.005     -8.495      0.000      -0.050      -0.031\n",
       "v_dir_250               0.1720      0.042      4.087      0.000       0.090       0.254\n",
       "geo_850                 0.0003   5.23e-05      6.293      0.000       0.000       0.000\n",
       "u_wind_850             -0.0385      0.007     -5.490      0.000      -0.052      -0.025\n",
       "u_dir_850               0.1287      0.049      2.604      0.009       0.032       0.226\n",
       "v_wind_850             -0.0178      0.008     -2.317      0.021      -0.033      -0.003\n",
       "v_dir_850               0.0885      0.045      1.988      0.047       0.001       0.176\n",
       "category_depression    -1.1009      0.141     -7.811      0.000      -1.377      -0.825\n",
       "category_storm          0.0551      0.111      0.497      0.619      -0.162       0.272\n",
       "=======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Instantiate model\n",
    "mylogreg_one = sm.Logit(y_train, X_train_wc)\n",
    "\n",
    "#2. Fit the model (this returns a separate object with the parameters)\n",
    "mylogreg_results_one = mylogreg_one.fit()\n",
    "mylogreg_results_one.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7b7628",
   "metadata": {},
   "source": [
    "The p-value for `category_storm` variable is much greater than the significance level of 0.05 at 0.619. Let's drop this feature and re-run the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a744a9a",
   "metadata": {},
   "source": [
    "#### Iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6c144978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lat', 'lon', 'dist2land', 'wind_surface', 'storm_speed', 'storm_dir',\n",
       "       'geo_250', 'u_wind_250', 'u_dir_250', 'v_wind_250', 'v_dir_250',\n",
       "       'geo_850', 'u_wind_850', 'u_dir_850', 'v_wind_850', 'v_dir_850',\n",
       "       'category_depression'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping column category_storm\n",
    "X_train_two = X_train.drop(columns='category_storm')\n",
    "X_train_two.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b9f6bbb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>dist2land</th>\n",
       "      <th>wind_surface</th>\n",
       "      <th>storm_speed</th>\n",
       "      <th>storm_dir</th>\n",
       "      <th>geo_250</th>\n",
       "      <th>u_wind_250</th>\n",
       "      <th>u_dir_250</th>\n",
       "      <th>v_wind_250</th>\n",
       "      <th>v_dir_250</th>\n",
       "      <th>geo_850</th>\n",
       "      <th>u_wind_850</th>\n",
       "      <th>u_dir_850</th>\n",
       "      <th>v_wind_850</th>\n",
       "      <th>v_dir_850</th>\n",
       "      <th>category_depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>-58.8000</td>\n",
       "      <td>736</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>106635.88</td>\n",
       "      <td>16.072563</td>\n",
       "      <td>1</td>\n",
       "      <td>8.375745</td>\n",
       "      <td>0</td>\n",
       "      <td>14826.376</td>\n",
       "      <td>0.543960</td>\n",
       "      <td>0</td>\n",
       "      <td>1.580342</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22770</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.269</td>\n",
       "      <td>-38.2722</td>\n",
       "      <td>1765</td>\n",
       "      <td>72.0</td>\n",
       "      <td>24</td>\n",
       "      <td>358</td>\n",
       "      <td>105226.94</td>\n",
       "      <td>1.256100</td>\n",
       "      <td>0</td>\n",
       "      <td>18.352348</td>\n",
       "      <td>1</td>\n",
       "      <td>14019.216</td>\n",
       "      <td>1.029442</td>\n",
       "      <td>1</td>\n",
       "      <td>11.933826</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25076</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.300</td>\n",
       "      <td>-50.6000</td>\n",
       "      <td>918</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13</td>\n",
       "      <td>282</td>\n",
       "      <td>107423.66</td>\n",
       "      <td>7.818411</td>\n",
       "      <td>0</td>\n",
       "      <td>0.428727</td>\n",
       "      <td>0</td>\n",
       "      <td>14747.231</td>\n",
       "      <td>1.195222</td>\n",
       "      <td>1</td>\n",
       "      <td>5.580057</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13092</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.200</td>\n",
       "      <td>-42.8000</td>\n",
       "      <td>1535</td>\n",
       "      <td>85.0</td>\n",
       "      <td>18</td>\n",
       "      <td>83</td>\n",
       "      <td>105825.46</td>\n",
       "      <td>15.006169</td>\n",
       "      <td>1</td>\n",
       "      <td>1.166901</td>\n",
       "      <td>0</td>\n",
       "      <td>13498.480</td>\n",
       "      <td>5.785726</td>\n",
       "      <td>1</td>\n",
       "      <td>3.113857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9261</th>\n",
       "      <td>1.0</td>\n",
       "      <td>25.300</td>\n",
       "      <td>-96.8000</td>\n",
       "      <td>51</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>107191.97</td>\n",
       "      <td>3.097380</td>\n",
       "      <td>1</td>\n",
       "      <td>0.955518</td>\n",
       "      <td>0</td>\n",
       "      <td>14183.869</td>\n",
       "      <td>1.004887</td>\n",
       "      <td>1</td>\n",
       "      <td>3.435564</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       const     lat      lon  dist2land  wind_surface  storm_speed  \\\n",
       "2577     1.0  20.000 -58.8000        736          25.0           10   \n",
       "22770    1.0  35.269 -38.2722       1765          72.0           24   \n",
       "25076    1.0  13.300 -50.6000        918          35.0           13   \n",
       "13092    1.0  35.200 -42.8000       1535          85.0           18   \n",
       "9261     1.0  25.300 -96.8000         51          50.0            9   \n",
       "\n",
       "       storm_dir    geo_250  u_wind_250  u_dir_250  v_wind_250  v_dir_250  \\\n",
       "2577          42  106635.88   16.072563          1    8.375745          0   \n",
       "22770        358  105226.94    1.256100          0   18.352348          1   \n",
       "25076        282  107423.66    7.818411          0    0.428727          0   \n",
       "13092         83  105825.46   15.006169          1    1.166901          0   \n",
       "9261          31  107191.97    3.097380          1    0.955518          0   \n",
       "\n",
       "         geo_850  u_wind_850  u_dir_850  v_wind_850  v_dir_850  \\\n",
       "2577   14826.376    0.543960          0    1.580342          1   \n",
       "22770  14019.216    1.029442          1   11.933826          1   \n",
       "25076  14747.231    1.195222          1    5.580057          1   \n",
       "13092  13498.480    5.785726          1    3.113857          0   \n",
       "9261   14183.869    1.004887          1    3.435564          1   \n",
       "\n",
       "       category_depression  \n",
       "2577                     1  \n",
       "22770                    0  \n",
       "25076                    0  \n",
       "13092                    0  \n",
       "9261                     0  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to manually add an intercept for statsmodels logit\n",
    "X_train_wc_two = sm.add_constant(X_train_two)\n",
    "X_train_wc_two.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "34969247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.584241\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>intensity_delta</td> <th>  No. Observations:  </th>   <td> 15486</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td> 15468</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>    17</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 11 Dec 2022</td> <th>  Pseudo R-squ.:     </th>   <td>0.05586</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>22:09:11</td>     <th>  Log-Likelihood:    </th>  <td> -9047.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -9582.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>6.976e-217</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>   21.4114</td> <td>    3.183</td> <td>    6.727</td> <td> 0.000</td> <td>   15.173</td> <td>   27.650</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lat</th>                 <td>   -0.0453</td> <td>    0.003</td> <td>  -13.846</td> <td> 0.000</td> <td>   -0.052</td> <td>   -0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lon</th>                 <td>   -0.0119</td> <td>    0.002</td> <td>   -7.773</td> <td> 0.000</td> <td>   -0.015</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dist2land</th>           <td> 7.977e-05</td> <td> 4.58e-05</td> <td>    1.741</td> <td> 0.082</td> <td>-1.01e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wind_surface</th>        <td>   -0.0044</td> <td>    0.001</td> <td>   -4.133</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>storm_speed</th>         <td>    0.0239</td> <td>    0.004</td> <td>    5.931</td> <td> 0.000</td> <td>    0.016</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>storm_dir</th>           <td>   -0.0008</td> <td>    0.000</td> <td>   -3.894</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>geo_250</th>             <td>   -0.0002</td> <td> 3.24e-05</td> <td>   -7.433</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>u_wind_250</th>          <td>   -0.0147</td> <td>    0.004</td> <td>   -3.412</td> <td> 0.001</td> <td>   -0.023</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>u_dir_250</th>           <td>   -0.3122</td> <td>    0.044</td> <td>   -7.125</td> <td> 0.000</td> <td>   -0.398</td> <td>   -0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>v_wind_250</th>          <td>   -0.0407</td> <td>    0.005</td> <td>   -8.520</td> <td> 0.000</td> <td>   -0.050</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>v_dir_250</th>           <td>    0.1721</td> <td>    0.042</td> <td>    4.090</td> <td> 0.000</td> <td>    0.090</td> <td>    0.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>geo_850</th>             <td>    0.0003</td> <td> 5.23e-05</td> <td>    6.284</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>u_wind_850</th>          <td>   -0.0384</td> <td>    0.007</td> <td>   -5.480</td> <td> 0.000</td> <td>   -0.052</td> <td>   -0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>u_dir_850</th>           <td>    0.1289</td> <td>    0.049</td> <td>    2.607</td> <td> 0.009</td> <td>    0.032</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>v_wind_850</th>          <td>   -0.0177</td> <td>    0.008</td> <td>   -2.309</td> <td> 0.021</td> <td>   -0.033</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>v_dir_850</th>           <td>    0.0881</td> <td>    0.045</td> <td>    1.979</td> <td> 0.048</td> <td>    0.001</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>category_depression</th> <td>   -1.1660</td> <td>    0.052</td> <td>  -22.473</td> <td> 0.000</td> <td>   -1.268</td> <td>   -1.064</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:        intensity_delta   No. Observations:                15486\n",
       "Model:                          Logit   Df Residuals:                    15468\n",
       "Method:                           MLE   Df Model:                           17\n",
       "Date:                Sun, 11 Dec 2022   Pseudo R-squ.:                 0.05586\n",
       "Time:                        22:09:11   Log-Likelihood:                -9047.6\n",
       "converged:                       True   LL-Null:                       -9582.9\n",
       "Covariance Type:            nonrobust   LLR p-value:                6.976e-217\n",
       "=======================================================================================\n",
       "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                  21.4114      3.183      6.727      0.000      15.173      27.650\n",
       "lat                    -0.0453      0.003    -13.846      0.000      -0.052      -0.039\n",
       "lon                    -0.0119      0.002     -7.773      0.000      -0.015      -0.009\n",
       "dist2land            7.977e-05   4.58e-05      1.741      0.082   -1.01e-05       0.000\n",
       "wind_surface           -0.0044      0.001     -4.133      0.000      -0.006      -0.002\n",
       "storm_speed             0.0239      0.004      5.931      0.000       0.016       0.032\n",
       "storm_dir              -0.0008      0.000     -3.894      0.000      -0.001      -0.000\n",
       "geo_250                -0.0002   3.24e-05     -7.433      0.000      -0.000      -0.000\n",
       "u_wind_250             -0.0147      0.004     -3.412      0.001      -0.023      -0.006\n",
       "u_dir_250              -0.3122      0.044     -7.125      0.000      -0.398      -0.226\n",
       "v_wind_250             -0.0407      0.005     -8.520      0.000      -0.050      -0.031\n",
       "v_dir_250               0.1721      0.042      4.090      0.000       0.090       0.255\n",
       "geo_850                 0.0003   5.23e-05      6.284      0.000       0.000       0.000\n",
       "u_wind_850             -0.0384      0.007     -5.480      0.000      -0.052      -0.025\n",
       "u_dir_850               0.1289      0.049      2.607      0.009       0.032       0.226\n",
       "v_wind_850             -0.0177      0.008     -2.309      0.021      -0.033      -0.003\n",
       "v_dir_850               0.0881      0.045      1.979      0.048       0.001       0.175\n",
       "category_depression    -1.1660      0.052    -22.473      0.000      -1.268      -1.064\n",
       "=======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Instantiate model\n",
    "mylogreg_two = sm.Logit(y_train, X_train_wc_two)\n",
    "\n",
    "#2. Fit the model (this returns a separate object with the parameters)\n",
    "mylogreg_results_two = mylogreg_two.fit()\n",
    "mylogreg_results_two.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ea7199",
   "metadata": {},
   "source": [
    "The p-value for `dist2land` variable is greater than the significance level of 0.05 at 0.082. Let's drop this feature and re-run the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e1137",
   "metadata": {},
   "source": [
    "#### Iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "46721f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lat', 'lon', 'wind_surface', 'storm_speed', 'storm_dir', 'geo_250',\n",
       "       'u_wind_250', 'u_dir_250', 'v_wind_250', 'v_dir_250', 'geo_850',\n",
       "       'u_wind_850', 'u_dir_850', 'v_wind_850', 'v_dir_850',\n",
       "       'category_depression'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping column dist2land\n",
    "X_train_three = X_train_two.drop(columns='dist2land')\n",
    "X_train_three.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ae969e7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>wind_surface</th>\n",
       "      <th>storm_speed</th>\n",
       "      <th>storm_dir</th>\n",
       "      <th>geo_250</th>\n",
       "      <th>u_wind_250</th>\n",
       "      <th>u_dir_250</th>\n",
       "      <th>v_wind_250</th>\n",
       "      <th>v_dir_250</th>\n",
       "      <th>geo_850</th>\n",
       "      <th>u_wind_850</th>\n",
       "      <th>u_dir_850</th>\n",
       "      <th>v_wind_850</th>\n",
       "      <th>v_dir_850</th>\n",
       "      <th>category_depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>-58.8000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>106635.88</td>\n",
       "      <td>16.072563</td>\n",
       "      <td>1</td>\n",
       "      <td>8.375745</td>\n",
       "      <td>0</td>\n",
       "      <td>14826.376</td>\n",
       "      <td>0.543960</td>\n",
       "      <td>0</td>\n",
       "      <td>1.580342</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22770</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.269</td>\n",
       "      <td>-38.2722</td>\n",
       "      <td>72.0</td>\n",
       "      <td>24</td>\n",
       "      <td>358</td>\n",
       "      <td>105226.94</td>\n",
       "      <td>1.256100</td>\n",
       "      <td>0</td>\n",
       "      <td>18.352348</td>\n",
       "      <td>1</td>\n",
       "      <td>14019.216</td>\n",
       "      <td>1.029442</td>\n",
       "      <td>1</td>\n",
       "      <td>11.933826</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25076</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.300</td>\n",
       "      <td>-50.6000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13</td>\n",
       "      <td>282</td>\n",
       "      <td>107423.66</td>\n",
       "      <td>7.818411</td>\n",
       "      <td>0</td>\n",
       "      <td>0.428727</td>\n",
       "      <td>0</td>\n",
       "      <td>14747.231</td>\n",
       "      <td>1.195222</td>\n",
       "      <td>1</td>\n",
       "      <td>5.580057</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13092</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.200</td>\n",
       "      <td>-42.8000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>18</td>\n",
       "      <td>83</td>\n",
       "      <td>105825.46</td>\n",
       "      <td>15.006169</td>\n",
       "      <td>1</td>\n",
       "      <td>1.166901</td>\n",
       "      <td>0</td>\n",
       "      <td>13498.480</td>\n",
       "      <td>5.785726</td>\n",
       "      <td>1</td>\n",
       "      <td>3.113857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9261</th>\n",
       "      <td>1.0</td>\n",
       "      <td>25.300</td>\n",
       "      <td>-96.8000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>107191.97</td>\n",
       "      <td>3.097380</td>\n",
       "      <td>1</td>\n",
       "      <td>0.955518</td>\n",
       "      <td>0</td>\n",
       "      <td>14183.869</td>\n",
       "      <td>1.004887</td>\n",
       "      <td>1</td>\n",
       "      <td>3.435564</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       const     lat      lon  wind_surface  storm_speed  storm_dir  \\\n",
       "2577     1.0  20.000 -58.8000          25.0           10         42   \n",
       "22770    1.0  35.269 -38.2722          72.0           24        358   \n",
       "25076    1.0  13.300 -50.6000          35.0           13        282   \n",
       "13092    1.0  35.200 -42.8000          85.0           18         83   \n",
       "9261     1.0  25.300 -96.8000          50.0            9         31   \n",
       "\n",
       "         geo_250  u_wind_250  u_dir_250  v_wind_250  v_dir_250    geo_850  \\\n",
       "2577   106635.88   16.072563          1    8.375745          0  14826.376   \n",
       "22770  105226.94    1.256100          0   18.352348          1  14019.216   \n",
       "25076  107423.66    7.818411          0    0.428727          0  14747.231   \n",
       "13092  105825.46   15.006169          1    1.166901          0  13498.480   \n",
       "9261   107191.97    3.097380          1    0.955518          0  14183.869   \n",
       "\n",
       "       u_wind_850  u_dir_850  v_wind_850  v_dir_850  category_depression  \n",
       "2577     0.543960          0    1.580342          1                    1  \n",
       "22770    1.029442          1   11.933826          1                    0  \n",
       "25076    1.195222          1    5.580057          1                    0  \n",
       "13092    5.785726          1    3.113857          0                    0  \n",
       "9261     1.004887          1    3.435564          1                    0  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to manually add an intercept for statsmodels logit\n",
    "X_train_wc_three = sm.add_constant(X_train_three)\n",
    "X_train_wc_three.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "045ae160",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.584339\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>intensity_delta</td> <th>  No. Observations:  </th>   <td> 15486</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td> 15469</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>    16</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 11 Dec 2022</td> <th>  Pseudo R-squ.:     </th>   <td>0.05570</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>22:09:12</td>     <th>  Log-Likelihood:    </th>  <td> -9049.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -9582.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>3.754e-217</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>   21.8822</td> <td>    3.171</td> <td>    6.901</td> <td> 0.000</td> <td>   15.667</td> <td>   28.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lat</th>                 <td>   -0.0449</td> <td>    0.003</td> <td>  -13.760</td> <td> 0.000</td> <td>   -0.051</td> <td>   -0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lon</th>                 <td>   -0.0100</td> <td>    0.001</td> <td>   -9.283</td> <td> 0.000</td> <td>   -0.012</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wind_surface</th>        <td>   -0.0042</td> <td>    0.001</td> <td>   -4.017</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>storm_speed</th>         <td>    0.0235</td> <td>    0.004</td> <td>    5.851</td> <td> 0.000</td> <td>    0.016</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>storm_dir</th>           <td>   -0.0008</td> <td>    0.000</td> <td>   -3.852</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>geo_250</th>             <td>   -0.0002</td> <td> 3.22e-05</td> <td>   -7.617</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>u_wind_250</th>          <td>   -0.0150</td> <td>    0.004</td> <td>   -3.484</td> <td> 0.000</td> <td>   -0.023</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>u_dir_250</th>           <td>   -0.3079</td> <td>    0.044</td> <td>   -7.036</td> <td> 0.000</td> <td>   -0.394</td> <td>   -0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>v_wind_250</th>          <td>   -0.0403</td> <td>    0.005</td> <td>   -8.440</td> <td> 0.000</td> <td>   -0.050</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>v_dir_250</th>           <td>    0.1709</td> <td>    0.042</td> <td>    4.062</td> <td> 0.000</td> <td>    0.088</td> <td>    0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>geo_850</th>             <td>    0.0003</td> <td> 5.15e-05</td> <td>    6.667</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>u_wind_850</th>          <td>   -0.0379</td> <td>    0.007</td> <td>   -5.414</td> <td> 0.000</td> <td>   -0.052</td> <td>   -0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>u_dir_850</th>           <td>    0.1285</td> <td>    0.049</td> <td>    2.600</td> <td> 0.009</td> <td>    0.032</td> <td>    0.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>v_wind_850</th>          <td>   -0.0178</td> <td>    0.008</td> <td>   -2.316</td> <td> 0.021</td> <td>   -0.033</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>v_dir_850</th>           <td>    0.0867</td> <td>    0.045</td> <td>    1.948</td> <td> 0.051</td> <td>   -0.001</td> <td>    0.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>category_depression</th> <td>   -1.1705</td> <td>    0.052</td> <td>  -22.582</td> <td> 0.000</td> <td>   -1.272</td> <td>   -1.069</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:        intensity_delta   No. Observations:                15486\n",
       "Model:                          Logit   Df Residuals:                    15469\n",
       "Method:                           MLE   Df Model:                           16\n",
       "Date:                Sun, 11 Dec 2022   Pseudo R-squ.:                 0.05570\n",
       "Time:                        22:09:12   Log-Likelihood:                -9049.1\n",
       "converged:                       True   LL-Null:                       -9582.9\n",
       "Covariance Type:            nonrobust   LLR p-value:                3.754e-217\n",
       "=======================================================================================\n",
       "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                  21.8822      3.171      6.901      0.000      15.667      28.097\n",
       "lat                    -0.0449      0.003    -13.760      0.000      -0.051      -0.038\n",
       "lon                    -0.0100      0.001     -9.283      0.000      -0.012      -0.008\n",
       "wind_surface           -0.0042      0.001     -4.017      0.000      -0.006      -0.002\n",
       "storm_speed             0.0235      0.004      5.851      0.000       0.016       0.031\n",
       "storm_dir              -0.0008      0.000     -3.852      0.000      -0.001      -0.000\n",
       "geo_250                -0.0002   3.22e-05     -7.617      0.000      -0.000      -0.000\n",
       "u_wind_250             -0.0150      0.004     -3.484      0.000      -0.023      -0.007\n",
       "u_dir_250              -0.3079      0.044     -7.036      0.000      -0.394      -0.222\n",
       "v_wind_250             -0.0403      0.005     -8.440      0.000      -0.050      -0.031\n",
       "v_dir_250               0.1709      0.042      4.062      0.000       0.088       0.253\n",
       "geo_850                 0.0003   5.15e-05      6.667      0.000       0.000       0.000\n",
       "u_wind_850             -0.0379      0.007     -5.414      0.000      -0.052      -0.024\n",
       "u_dir_850               0.1285      0.049      2.600      0.009       0.032       0.225\n",
       "v_wind_850             -0.0178      0.008     -2.316      0.021      -0.033      -0.003\n",
       "v_dir_850               0.0867      0.045      1.948      0.051      -0.001       0.174\n",
       "category_depression    -1.1705      0.052    -22.582      0.000      -1.272      -1.069\n",
       "=======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Instantiate model\n",
    "mylogreg_three = sm.Logit(y_train, X_train_wc_three)\n",
    "\n",
    "#2. Fit the model (this returns a separate object with the parameters)\n",
    "mylogreg_results_three = mylogreg_three.fit()\n",
    "mylogreg_results_three.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c8344b",
   "metadata": {},
   "source": [
    "The p-value for `v_dir_850` variable is greater than the significance level of 0.05 at 0.051. Let's drop this feature and re-run the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e21cf08",
   "metadata": {},
   "source": [
    "#### Iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "402978f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lat', 'lon', 'wind_surface', 'storm_speed', 'storm_dir', 'geo_250',\n",
       "       'u_wind_250', 'u_dir_250', 'v_wind_250', 'v_dir_250', 'geo_850',\n",
       "       'u_wind_850', 'u_dir_850', 'v_wind_850', 'category_depression'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping column v_dir_850\n",
    "X_train_four = X_train_three.drop(columns='v_dir_850')\n",
    "X_train_four.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "801a3b1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>wind_surface</th>\n",
       "      <th>storm_speed</th>\n",
       "      <th>storm_dir</th>\n",
       "      <th>geo_250</th>\n",
       "      <th>u_wind_250</th>\n",
       "      <th>u_dir_250</th>\n",
       "      <th>v_wind_250</th>\n",
       "      <th>v_dir_250</th>\n",
       "      <th>geo_850</th>\n",
       "      <th>u_wind_850</th>\n",
       "      <th>u_dir_850</th>\n",
       "      <th>v_wind_850</th>\n",
       "      <th>category_depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>-58.8000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>106635.88</td>\n",
       "      <td>16.072563</td>\n",
       "      <td>1</td>\n",
       "      <td>8.375745</td>\n",
       "      <td>0</td>\n",
       "      <td>14826.376</td>\n",
       "      <td>0.543960</td>\n",
       "      <td>0</td>\n",
       "      <td>1.580342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22770</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.269</td>\n",
       "      <td>-38.2722</td>\n",
       "      <td>72.0</td>\n",
       "      <td>24</td>\n",
       "      <td>358</td>\n",
       "      <td>105226.94</td>\n",
       "      <td>1.256100</td>\n",
       "      <td>0</td>\n",
       "      <td>18.352348</td>\n",
       "      <td>1</td>\n",
       "      <td>14019.216</td>\n",
       "      <td>1.029442</td>\n",
       "      <td>1</td>\n",
       "      <td>11.933826</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25076</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.300</td>\n",
       "      <td>-50.6000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13</td>\n",
       "      <td>282</td>\n",
       "      <td>107423.66</td>\n",
       "      <td>7.818411</td>\n",
       "      <td>0</td>\n",
       "      <td>0.428727</td>\n",
       "      <td>0</td>\n",
       "      <td>14747.231</td>\n",
       "      <td>1.195222</td>\n",
       "      <td>1</td>\n",
       "      <td>5.580057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13092</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.200</td>\n",
       "      <td>-42.8000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>18</td>\n",
       "      <td>83</td>\n",
       "      <td>105825.46</td>\n",
       "      <td>15.006169</td>\n",
       "      <td>1</td>\n",
       "      <td>1.166901</td>\n",
       "      <td>0</td>\n",
       "      <td>13498.480</td>\n",
       "      <td>5.785726</td>\n",
       "      <td>1</td>\n",
       "      <td>3.113857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9261</th>\n",
       "      <td>1.0</td>\n",
       "      <td>25.300</td>\n",
       "      <td>-96.8000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>107191.97</td>\n",
       "      <td>3.097380</td>\n",
       "      <td>1</td>\n",
       "      <td>0.955518</td>\n",
       "      <td>0</td>\n",
       "      <td>14183.869</td>\n",
       "      <td>1.004887</td>\n",
       "      <td>1</td>\n",
       "      <td>3.435564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       const     lat      lon  wind_surface  storm_speed  storm_dir  \\\n",
       "2577     1.0  20.000 -58.8000          25.0           10         42   \n",
       "22770    1.0  35.269 -38.2722          72.0           24        358   \n",
       "25076    1.0  13.300 -50.6000          35.0           13        282   \n",
       "13092    1.0  35.200 -42.8000          85.0           18         83   \n",
       "9261     1.0  25.300 -96.8000          50.0            9         31   \n",
       "\n",
       "         geo_250  u_wind_250  u_dir_250  v_wind_250  v_dir_250    geo_850  \\\n",
       "2577   106635.88   16.072563          1    8.375745          0  14826.376   \n",
       "22770  105226.94    1.256100          0   18.352348          1  14019.216   \n",
       "25076  107423.66    7.818411          0    0.428727          0  14747.231   \n",
       "13092  105825.46   15.006169          1    1.166901          0  13498.480   \n",
       "9261   107191.97    3.097380          1    0.955518          0  14183.869   \n",
       "\n",
       "       u_wind_850  u_dir_850  v_wind_850  category_depression  \n",
       "2577     0.543960          0    1.580342                    1  \n",
       "22770    1.029442          1   11.933826                    0  \n",
       "25076    1.195222          1    5.580057                    0  \n",
       "13092    5.785726          1    3.113857                    0  \n",
       "9261     1.004887          1    3.435564                    0  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to manually add an intercept for statsmodels logit\n",
    "X_train_wc_four = sm.add_constant(X_train_four)\n",
    "X_train_wc_four.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0bb0448f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.584462\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>intensity_delta</td> <th>  No. Observations:  </th>   <td> 15486</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td> 15470</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>    15</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 11 Dec 2022</td> <th>  Pseudo R-squ.:     </th>   <td>0.05550</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>22:09:13</td>     <th>  Log-Likelihood:    </th>  <td> -9051.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -9582.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>2.869e-217</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>   21.3110</td> <td>    3.158</td> <td>    6.749</td> <td> 0.000</td> <td>   15.122</td> <td>   27.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lat</th>                 <td>   -0.0445</td> <td>    0.003</td> <td>  -13.677</td> <td> 0.000</td> <td>   -0.051</td> <td>   -0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lon</th>                 <td>   -0.0101</td> <td>    0.001</td> <td>   -9.322</td> <td> 0.000</td> <td>   -0.012</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wind_surface</th>        <td>   -0.0042</td> <td>    0.001</td> <td>   -3.944</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>storm_speed</th>         <td>    0.0239</td> <td>    0.004</td> <td>    5.964</td> <td> 0.000</td> <td>    0.016</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>storm_dir</th>           <td>   -0.0008</td> <td>    0.000</td> <td>   -3.877</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>geo_250</th>             <td>   -0.0002</td> <td> 3.22e-05</td> <td>   -7.497</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>u_wind_250</th>          <td>   -0.0157</td> <td>    0.004</td> <td>   -3.648</td> <td> 0.000</td> <td>   -0.024</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>u_dir_250</th>           <td>   -0.3030</td> <td>    0.044</td> <td>   -6.937</td> <td> 0.000</td> <td>   -0.389</td> <td>   -0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>v_wind_250</th>          <td>   -0.0403</td> <td>    0.005</td> <td>   -8.452</td> <td> 0.000</td> <td>   -0.050</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>v_dir_250</th>           <td>    0.1789</td> <td>    0.042</td> <td>    4.272</td> <td> 0.000</td> <td>    0.097</td> <td>    0.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>geo_850</th>             <td>    0.0004</td> <td> 5.14e-05</td> <td>    6.850</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>u_wind_850</th>          <td>   -0.0380</td> <td>    0.007</td> <td>   -5.439</td> <td> 0.000</td> <td>   -0.052</td> <td>   -0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>u_dir_850</th>           <td>    0.1298</td> <td>    0.049</td> <td>    2.625</td> <td> 0.009</td> <td>    0.033</td> <td>    0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>v_wind_850</th>          <td>   -0.0148</td> <td>    0.008</td> <td>   -1.968</td> <td> 0.049</td> <td>   -0.029</td> <td>-5.83e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>category_depression</th> <td>   -1.1736</td> <td>    0.052</td> <td>  -22.651</td> <td> 0.000</td> <td>   -1.275</td> <td>   -1.072</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:        intensity_delta   No. Observations:                15486\n",
       "Model:                          Logit   Df Residuals:                    15470\n",
       "Method:                           MLE   Df Model:                           15\n",
       "Date:                Sun, 11 Dec 2022   Pseudo R-squ.:                 0.05550\n",
       "Time:                        22:09:13   Log-Likelihood:                -9051.0\n",
       "converged:                       True   LL-Null:                       -9582.9\n",
       "Covariance Type:            nonrobust   LLR p-value:                2.869e-217\n",
       "=======================================================================================\n",
       "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                  21.3110      3.158      6.749      0.000      15.122      27.500\n",
       "lat                    -0.0445      0.003    -13.677      0.000      -0.051      -0.038\n",
       "lon                    -0.0101      0.001     -9.322      0.000      -0.012      -0.008\n",
       "wind_surface           -0.0042      0.001     -3.944      0.000      -0.006      -0.002\n",
       "storm_speed             0.0239      0.004      5.964      0.000       0.016       0.032\n",
       "storm_dir              -0.0008      0.000     -3.877      0.000      -0.001      -0.000\n",
       "geo_250                -0.0002   3.22e-05     -7.497      0.000      -0.000      -0.000\n",
       "u_wind_250             -0.0157      0.004     -3.648      0.000      -0.024      -0.007\n",
       "u_dir_250              -0.3030      0.044     -6.937      0.000      -0.389      -0.217\n",
       "v_wind_250             -0.0403      0.005     -8.452      0.000      -0.050      -0.031\n",
       "v_dir_250               0.1789      0.042      4.272      0.000       0.097       0.261\n",
       "geo_850                 0.0004   5.14e-05      6.850      0.000       0.000       0.000\n",
       "u_wind_850             -0.0380      0.007     -5.439      0.000      -0.052      -0.024\n",
       "u_dir_850               0.1298      0.049      2.625      0.009       0.033       0.227\n",
       "v_wind_850             -0.0148      0.008     -1.968      0.049      -0.029   -5.83e-05\n",
       "category_depression    -1.1736      0.052    -22.651      0.000      -1.275      -1.072\n",
       "=======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Instantiate model\n",
    "mylogreg_four = sm.Logit(y_train, X_train_wc_four)\n",
    "\n",
    "#2. Fit the model (this returns a separate object with the parameters)\n",
    "mylogreg_results_four = mylogreg_four.fit()\n",
    "mylogreg_results_four.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4291c3e8",
   "metadata": {},
   "source": [
    "All features have p-values within the significance threshold of 0.05. So, we can keep all the variables in here for our more advanced modelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7b5220d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['const', 'lat', 'lon', 'wind_surface', 'storm_speed', 'storm_dir',\n",
       "       'geo_250', 'u_wind_250', 'u_dir_250', 'v_wind_250', 'v_dir_250',\n",
       "       'geo_850', 'u_wind_850', 'u_dir_850', 'v_wind_850',\n",
       "       'category_depression'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get list of columns to keep in final datasets\n",
    "X_train_wc_four.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce01b6c0",
   "metadata": {},
   "source": [
    "Let's keep decalre X and y with the new set of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f5d3f797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lat', 'lon', 'wind_surface', 'storm_speed', 'storm_dir', 'geo_250',\n",
       "       'u_wind_250', 'u_dir_250', 'v_wind_250', 'v_dir_250', 'geo_850',\n",
       "       'u_wind_850', 'u_dir_850', 'v_wind_850', 'category_depression',\n",
       "       'intensity_delta'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new df with only significant featurs and target \n",
    "final_df = model_df[['lat', 'lon', 'wind_surface', 'storm_speed', 'storm_dir',\n",
    "       'geo_250', 'u_wind_250', 'u_dir_250', 'v_wind_250', 'v_dir_250',\n",
    "       'geo_850', 'u_wind_850', 'u_dir_850', 'v_wind_850',\n",
    "       'category_depression', 'intensity_delta']]\n",
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "87d1bc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>wind_surface</th>\n",
       "      <th>storm_speed</th>\n",
       "      <th>storm_dir</th>\n",
       "      <th>geo_250</th>\n",
       "      <th>u_wind_250</th>\n",
       "      <th>u_dir_250</th>\n",
       "      <th>v_wind_250</th>\n",
       "      <th>v_dir_250</th>\n",
       "      <th>geo_850</th>\n",
       "      <th>u_wind_850</th>\n",
       "      <th>u_dir_850</th>\n",
       "      <th>v_wind_850</th>\n",
       "      <th>category_depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.1000</td>\n",
       "      <td>-90.5000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>106941.04</td>\n",
       "      <td>9.345726</td>\n",
       "      <td>1</td>\n",
       "      <td>1.314173</td>\n",
       "      <td>1</td>\n",
       "      <td>14684.576</td>\n",
       "      <td>1.299480</td>\n",
       "      <td>1</td>\n",
       "      <td>2.507897</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.2799</td>\n",
       "      <td>-90.2298</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>59</td>\n",
       "      <td>106903.90</td>\n",
       "      <td>9.797820</td>\n",
       "      <td>1</td>\n",
       "      <td>3.676654</td>\n",
       "      <td>1</td>\n",
       "      <td>14733.608</td>\n",
       "      <td>0.864694</td>\n",
       "      <td>1</td>\n",
       "      <td>2.880090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.4000</td>\n",
       "      <td>-89.9000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>69</td>\n",
       "      <td>106783.48</td>\n",
       "      <td>10.698173</td>\n",
       "      <td>1</td>\n",
       "      <td>7.318680</td>\n",
       "      <td>1</td>\n",
       "      <td>14732.032</td>\n",
       "      <td>2.117519</td>\n",
       "      <td>1</td>\n",
       "      <td>3.888728</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.5150</td>\n",
       "      <td>-89.5150</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7</td>\n",
       "      <td>74</td>\n",
       "      <td>106455.28</td>\n",
       "      <td>14.590856</td>\n",
       "      <td>1</td>\n",
       "      <td>11.222942</td>\n",
       "      <td>1</td>\n",
       "      <td>14646.824</td>\n",
       "      <td>3.203289</td>\n",
       "      <td>1</td>\n",
       "      <td>2.605515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.6000</td>\n",
       "      <td>-89.1000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7</td>\n",
       "      <td>78</td>\n",
       "      <td>106473.04</td>\n",
       "      <td>14.877510</td>\n",
       "      <td>1</td>\n",
       "      <td>10.828848</td>\n",
       "      <td>1</td>\n",
       "      <td>14696.572</td>\n",
       "      <td>2.416132</td>\n",
       "      <td>1</td>\n",
       "      <td>0.628975</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lat      lon  wind_surface  storm_speed  storm_dir    geo_250  \\\n",
       "0  32.1000 -90.5000          25.0            6         42  106941.04   \n",
       "1  32.2799 -90.2298          25.0            6         59  106903.90   \n",
       "2  32.4000 -89.9000          25.0            6         69  106783.48   \n",
       "3  32.5150 -89.5150          25.0            7         74  106455.28   \n",
       "4  32.6000 -89.1000          25.0            7         78  106473.04   \n",
       "\n",
       "   u_wind_250  u_dir_250  v_wind_250  v_dir_250    geo_850  u_wind_850  \\\n",
       "0    9.345726          1    1.314173          1  14684.576    1.299480   \n",
       "1    9.797820          1    3.676654          1  14733.608    0.864694   \n",
       "2   10.698173          1    7.318680          1  14732.032    2.117519   \n",
       "3   14.590856          1   11.222942          1  14646.824    3.203289   \n",
       "4   14.877510          1   10.828848          1  14696.572    2.416132   \n",
       "\n",
       "   u_dir_850  v_wind_850  category_depression  \n",
       "0          1    2.507897                    1  \n",
       "1          1    2.880090                    1  \n",
       "2          1    3.888728                    1  \n",
       "3          1    2.605515                    1  \n",
       "4          1    0.628975                    1  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X(features) decalaration\n",
    "X = final_df.drop(columns='intensity_delta')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2cc39361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intensity_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9788</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26545</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21125</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16953</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11152</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6244</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11797</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8806</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5740</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       intensity_delta\n",
       "9788               0.0\n",
       "26545              0.0\n",
       "21125              0.0\n",
       "16953              0.0\n",
       "11152              0.0\n",
       "7184               0.0\n",
       "6244               1.0\n",
       "11797              0.0\n",
       "8806               0.0\n",
       "5740               0.0"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y (labels/target) decalration\n",
    "y = final_df[['intensity_delta']]\n",
    "y.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46313470",
   "metadata": {},
   "source": [
    "### Final Test, Train, Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ccb147c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the split ratio\n",
    "split_ratio = 0.25 # 25% of data goes into test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bb047dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_remainder, X_test, y_remainder, y_test = train_test_split(X, y, \n",
    "                                                            test_size=split_ratio, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5e781ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "X.shape[0] == X_remainder.shape[0] + X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "13a964d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X_remainder, y_remainder, \n",
    "                                                                test_size=split_ratio, stratify=y_remainder, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ae83074f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "X_remainder.shape[0] == X_train.shape[0] + X_validation.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f921041f",
   "metadata": {},
   "source": [
    "### Scaling the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52077b4b",
   "metadata": {},
   "source": [
    "Let's scale the data. We will use the `MinMaxScaler` for this task as the MinMaxScaler preserves the distribution of the data. The scaler will be fit to the training data and using that to transform the training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "18255f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The runtime of your code is: 0:00:00.002100 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer() # start timer\n",
    "# Instatiate Scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform the data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_validation_scaled = scaler.transform(X_validation)\n",
    "runtime = timer(time) # stop timer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040ea4af",
   "metadata": {},
   "source": [
    "Now, I will fit the scaler to the entirity of the remainder data set and use it to transform the remainder and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f150b8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The runtime of your code is: 0:00:00.007115 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer() # start timer\n",
    "# Instatiate Scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "scaler.fit(X_remainder)\n",
    "\n",
    "# Transform the data\n",
    "X_remainder_scaled = scaler.transform(X_remainder)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "runtime = timer(time) # stop timer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c11ab7",
   "metadata": {},
   "source": [
    "### Dimension Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20da89d4",
   "metadata": {},
   "source": [
    "Let's conduct some dimension reduction via Principal Component Analysis (PCA).\n",
    "\n",
    "Initially, we will instatiate and fit a PCA object to the remainder set with no value for n_components. The we will use the explained_variance_ratio_ to find the optimal number of components.\n",
    "\n",
    "PCA object instatiation and fitting with no value for `n_components`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "79b98623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The runtime of your code is: 0:00:00.016741 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(microseconds=16741)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = timer() # start timer\n",
    "# instantiate the PCA object\n",
    "model_PCA = PCA()\n",
    "\n",
    "# fitting PCA\n",
    "model_PCA.fit(X_remainder_scaled)\n",
    "\n",
    "# transforming datasets\n",
    "X_remainder_scaled_PCA = model_PCA.transform(X_remainder_scaled)\n",
    "X_test_scaled_PCA = model_PCA.transform(X_test_scaled)\n",
    "timer(time) # stop timer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c12160",
   "metadata": {},
   "source": [
    "We can now use the `explained_variance_ratio_` to find the best value for n_components by plotting the ratios vs the number of Principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a7d2bf1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "expl_var = model_PCA.explained_variance_ratio_\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(range(1,X_remainder_scaled.shape[1]+1),expl_var,marker='.')\n",
    "plt.title('Explained Variance Ratio Scree Plot')\n",
    "plt.xlabel('Number of PCs')\n",
    "plt.ylabel('Proportion of Variance Explained')\n",
    "plt.xticks(range(1,X_remainder_scaled.shape[1]+1,1))\n",
    "\n",
    "\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f6e896",
   "metadata": {},
   "source": [
    "The scree plot tells us that the ideal `n_components` for PCA would be 5 (elbow point). Let's use cumulative sums to see how many components we need to cover 80%, 90%, and 95% of variance. We will store the number of components in a list which we can later use to reduce dimension using PCA in a 5-fold GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b030a573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 8]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_sum = np.cumsum(expl_var)\n",
    "components = [ \n",
    "    np.argmax(cumulative_sum > 0.85) + 1,\n",
    "    np.argmax(cumulative_sum > 0.9) + 1,\n",
    "    np.argmax(cumulative_sum > 0.95) + 1\n",
    "]\n",
    "components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b98d8b6",
   "metadata": {},
   "source": [
    "- 5 components explain 85% of varaince in data\n",
    "- 6 components explain 90% of varaince in data\n",
    "- 8 components explain 95% of varaince in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c953e1b",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d10dc6",
   "metadata": {},
   "source": [
    "#### Five-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15a0e79",
   "metadata": {},
   "source": [
    "We will use GridSearchCV and Pipeline to perform a 5-fold cross validation to optimize the following hyperparameters for Logistic Regression:\n",
    "\n",
    "1. C or regularization \n",
    "2. solver\n",
    "\n",
    "In addition, we will also test for 3 different values for PCA dimension reduction n_components and two different Scalers (MinMax and Standard).\n",
    "\n",
    "First let's create the list of pipeline estimators and create the Pipeline using this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "99d42e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimators for pipeline\n",
    "estimators = [\n",
    "    ('scale', StandardScaler()),\n",
    "    ('reduce_dim', PCA()),\n",
    "    ('LR', LogisticRegression())\n",
    "]\n",
    "\n",
    "# pipeline creation\n",
    "pipe = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3ecde2",
   "metadata": {},
   "source": [
    "Next, let's create the `param-grid`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0202321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param-grid\n",
    "params = [\n",
    "    {'LR': [LogisticRegression(max_iter=5000, penalty='l2', random_state=1)],\n",
    "     'scale': [StandardScaler(), MinMaxScaler()],\n",
    "     'reduce_dim': [PCA()],\n",
    "     'LR__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "     'LR__solver': ['liblinear', 'lbfgs'],\n",
    "     'reduce_dim__n_components': [6, 8, None]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787347d8",
   "metadata": {},
   "source": [
    "Now we create `GridSearchCV` object and fit the grid to the remainder data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8fe433d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.001, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.01, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=0.1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=10, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=100, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=StandardScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END LR=LogisticRegression(max_iter=5000, random_state=1), LR__C=1000, LR__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=None, scale=MinMaxScaler(); total time=   0.0s\n",
      "The runtime of your code is: 0:00:23.095066 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer() # start timer\n",
    "# GridSearchCv object\n",
    "grid = GridSearchCV(pipe, param_grid=params, cv=5, verbose=2)\n",
    "\n",
    "# fitting the grid\n",
    "fittedgrid = grid.fit(X_remainder, y_remainder)\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759d78b2",
   "metadata": {},
   "source": [
    "Let's find the best params and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c5fa823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model\n",
    "best_model = fittedgrid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "fb2f93da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': LogisticRegression(C=1000, max_iter=5000, random_state=1, solver='liblinear'),\n",
       " 'LR__C': 1000,\n",
       " 'LR__solver': 'liblinear',\n",
       " 'reduce_dim': PCA(),\n",
       " 'reduce_dim__n_components': None,\n",
       " 'scale': MinMaxScaler()}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best set of parameters\n",
    "fittedgrid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "97e1b4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6958058075022415"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best score\n",
    "fittedgrid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aef4925",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ecd6d1",
   "metadata": {},
   "source": [
    "##### Accuracy Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a622341",
   "metadata": {},
   "source": [
    "Let's fit the best model to the reaminder set and calculate accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "200700c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The runtime of your code is: 0:00:00.102023 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer()\n",
    "# fit best_model\n",
    "best_model.fit(X_remainder, y_remainder)\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "527a0c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remainder Set Score: 0.696241766757071\n",
      "Test Set Score: 0.691413627778585\n",
      "The runtime of your code is: 0:00:00.006114 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer()\n",
    "# accuracy scores\n",
    "print(f'Remainder Set Score: {best_model.score(X_remainder, y_remainder)}')\n",
    "print(f'Test Set Score: {best_model.score(X_test, y_test)}')\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "407b611c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.690313\n",
       "1.0    0.309687\n",
       "Name: intensity_delta, dtype: float64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['intensity_delta'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc6a9cd",
   "metadata": {},
   "source": [
    "##### Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e4f3cf",
   "metadata": {},
   "source": [
    "Let's plot the confusion matrix for the Logistic Regression model and get prediction for test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3b895088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting confusion matrix\n",
    "plot_confusion_matrix(best_model, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "747db296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class predictions\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1715b835",
   "metadata": {},
   "source": [
    "Let's get the Classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1e4a3cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.94      0.81      4751\n",
      "         1.0       0.51      0.14      0.23      2132\n",
      "\n",
      "    accuracy                           0.69      6883\n",
      "   macro avg       0.61      0.54      0.52      6883\n",
      "weighted avg       0.65      0.69      0.63      6883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification score\n",
    "logit_report = classification_report(y_test, y_pred)\n",
    "print(logit_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc54ea9",
   "metadata": {},
   "source": [
    "Summary of Models:\n",
    "\n",
    "|      **Model**      | **Remainder Accuracy** | **Test Accuracy** | **Recall** | **Precision** | **F1 Score** | **Best Parameters**                                                          |\n",
    "|:-------------------:|:----------------------:|:-----------------:|------------|---------------|--------------|------------------------------------------------------------------------------|\n",
    "| Logistic Regression | 0.696                  | 0.691             | 0.14       | 0.51          | 0.23         | MinMaxScaler(), No dimension reduction,  LR__C=1000, LR__solver='liblinear'  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c75cda3",
   "metadata": {},
   "source": [
    "Recall of 0.14 and Precision of 0.51 are quite bad. Let's see if we can increase them with other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b25828d",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ace10c",
   "metadata": {},
   "source": [
    "#### Optimize for `max_depth`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c9a922",
   "metadata": {},
   "source": [
    "Let's use a for loop to optimize for max_depth. We will also use the unscaled train and validation sets for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e4d09f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [00:22<00:00,  5.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# running model for different max depths\n",
    "depths = list(range(1, int(np.sqrt(len(X_train))))) # range of max_depths to be tested\n",
    "train_scores_dt = []\n",
    "validation_scores_dt = []\n",
    "\n",
    "for d in tqdm(depths):\n",
    "\n",
    "    dt = DecisionTreeClassifier(max_depth = d)\n",
    "    dt.fit(X_train, y_train)\n",
    "        \n",
    "    # Evaluate\n",
    "    train_scores_dt.append(dt.score(X_train, y_train))\n",
    "    validation_scores_dt.append(dt.score(X_validation, y_validation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c16470",
   "metadata": {},
   "source": [
    "Let's plot the accuracy scores against max_depth to find out the best max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "aec88bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The runtime of your code is: 0:00:00.111494 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer()\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(depths, train_scores_dt, c='blue', label='train')\n",
    "plt.plot(depths, validation_scores_dt, c='red', label='validation')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title(\"Decision tree max_depth tuning\")\n",
    "plt.legend()\n",
    "\n",
    "sns.despine()\n",
    "plt.show()\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb0bfec",
   "metadata": {},
   "source": [
    "From the plot, we can see that the model starts to seriously over fit sometime around a max_depth of 10. Let's make a plot for max_depth from 1-20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9384b7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The runtime of your code is: 0:00:00.134025 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer()\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(depths, train_scores_dt, c='blue', label='train')\n",
    "plt.plot(depths, validation_scores_dt, c='red', label='validation')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title(\"Decision tree max_depth tuning\")\n",
    "plt.xlim([1,21])\n",
    "plt.xticks(range(0,21,1))\n",
    "plt.legend()\n",
    "\n",
    "sns.despine()\n",
    "plt.show()\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a7740e",
   "metadata": {},
   "source": [
    "Based on the plot, we will choose a max_depth of 6. This will maximize test set accuracy while keeping over-fitting low. max_depth of 5 would also be a good option.\n",
    "\n",
    "Let's find the accuracy score for a DT Classifier model with max_depth of 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "859d4195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The runtime of your code is: 0:00:00.088698 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer() # start timer\n",
    "\n",
    "# Instantiate DT model\n",
    "dt = DecisionTreeClassifier(max_depth=6, random_state=1)\n",
    "\n",
    "# Fit the model\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "runtime = timer(time) # stop timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d1080823",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Score: 0.7220069740410694\n",
      "Validation Set Score: 0.7171638899651298\n",
      "The runtime of your code is: 0:00:00.008008 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer()\n",
    "# Accuracy scores\n",
    "print(f'Train Set Score: {dt.score(X_train, y_train)}')\n",
    "print(f'Validation Set Score: {dt.score(X_validation, y_validation)}')\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3661e1e6",
   "metadata": {},
   "source": [
    "We can see that the Decision Tree model is performing slightly better than the Logistic Regression model. Let's evaluate the model on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e52421a",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de27a93",
   "metadata": {},
   "source": [
    "##### Accuracy Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb31fee",
   "metadata": {},
   "source": [
    "Let's fit the best model to the reaminder set and calculate accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a15cbfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The runtime of your code is: 0:00:00.112416 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "# training model on remainder data\n",
    "time = timer() # start timer\n",
    "\n",
    "# Instantiate DT model\n",
    "dt = DecisionTreeClassifier(max_depth=6, random_state=1)\n",
    "\n",
    "# Fit the model\n",
    "dt.fit(X_remainder, y_remainder)\n",
    "\n",
    "runtime = timer(time) # stop timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "43baed16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remainder Set Score: 0.7221522665633475\n",
      "Test Set Score: 0.7175650152549761\n",
      "The runtime of your code is: 0:00:00.009015 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer()\n",
    "# Accuracy scores\n",
    "print(f'Remainder Set Score: {dt.score(X_remainder, y_remainder)}')\n",
    "print(f'Test Set Score: {dt.score(X_test, y_test)}')\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6968ce64",
   "metadata": {},
   "source": [
    "##### Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241e8d28",
   "metadata": {},
   "source": [
    "Let's plot the confusion matrix for the Decision Tree model and get prediction for test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f4151626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting confusion matrix\n",
    "plot_confusion_matrix(dt, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2b157657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class predictions\n",
    "y_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af1e82c",
   "metadata": {},
   "source": [
    "Let's get the Classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b410dde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.92      0.82      4751\n",
      "         1.0       0.60      0.26      0.36      2132\n",
      "\n",
      "    accuracy                           0.72      6883\n",
      "   macro avg       0.67      0.59      0.59      6883\n",
      "weighted avg       0.69      0.72      0.68      6883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification score\n",
    "dt_report = classification_report(y_test, y_pred)\n",
    "print(dt_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0fe895",
   "metadata": {},
   "source": [
    "Summary of Models:\n",
    "\n",
    "|      **Model**      | **Remainder Accuracy** | **Test Accuracy** | **Recall** | **Precision** | **F1 Score** | **Best Parameters**                                                          |\n",
    "|:-------------------:|:----------------------:|:-----------------:|------------|---------------|--------------|------------------------------------------------------------------------------|\n",
    "| Logistic Regression | 0.696                  | 0.691             | 0.14       | 0.51          | 0.23         | MinMaxScaler(), No dimension reduction,  LR__C=1000, LR__solver='liblinear'  |\n",
    "|  Decision Tree 1    | 0.722                  | 0.717             | 0.26       | 0.60          | 0.36         | max_depth=6                                                                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0674e728",
   "metadata": {},
   "source": [
    "Recall has increased to 0.26 and Precision to 0.60. These values are still quite bad. Let's continue testing other models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b906a",
   "metadata": {},
   "source": [
    "Let's run a `GridSearchCV` and see if we can improve on these scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a673c9b",
   "metadata": {},
   "source": [
    "#### 5-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "0327237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimators for pipeline\n",
    "estimators = [\n",
    "    ('reduce_dim', PCA()),\n",
    "    ('DT', DecisionTreeClassifier())\n",
    "]\n",
    "\n",
    "# pipeline creation\n",
    "pipe = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f8fc7",
   "metadata": {},
   "source": [
    "Next, let's create the `param-grid`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e9e6211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param-grid\n",
    "params = [\n",
    "    {'DT': [DecisionTreeClassifier(random_state=1)],\n",
    "     'reduce_dim': [PCA()],\n",
    "     'DT__max_depth': [5, 6, 7],\n",
    "     'DT__criterion': ['gini', 'entropy'],\n",
    "     'reduce_dim__n_components': [6, 8, None]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105fce07",
   "metadata": {},
   "source": [
    "Now we create `GridSearchCV` object and fit the grid to the remainder data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "94240e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=gini, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.0s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "[CV] END DT=DecisionTreeClassifier(random_state=1), DT__criterion=entropy, DT__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "The runtime of your code is: 0:00:14.056976 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer() # start timer\n",
    "# GridSearchCv object\n",
    "grid = GridSearchCV(pipe, param_grid=params, cv=5, verbose=2)\n",
    "\n",
    "# fitting the grid\n",
    "fittedgrid = grid.fit(X_remainder, y_remainder)\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2632ae",
   "metadata": {},
   "source": [
    "Let's find the best params and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "292cabfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model\n",
    "best_model = fittedgrid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f7358287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DT': DecisionTreeClassifier(max_depth=7, random_state=1),\n",
       " 'DT__criterion': 'gini',\n",
       " 'DT__max_depth': 7,\n",
       " 'reduce_dim': PCA(),\n",
       " 'reduce_dim__n_components': None}"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best set of parameters\n",
    "fittedgrid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "c7ec3cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7025376405123624"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best score\n",
    "fittedgrid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d1ebcc",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1f7a7b",
   "metadata": {},
   "source": [
    "##### Accuracy Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084efb4b",
   "metadata": {},
   "source": [
    "Let's fit the best model to the reaminder set and calculate accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "df4204cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The runtime of your code is: 0:00:00.208943 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer()\n",
    "# fit best_model\n",
    "best_model.fit(X_remainder, y_remainder)\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "d96c4460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remainder Set Score: 0.7284967067028284\n",
      "Test Set Score: 0.7046346070027604\n",
      "The runtime of your code is: 0:00:00.010992 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer()\n",
    "# accuracy scores\n",
    "print(f'Remainder Set Score: {best_model.score(X_remainder, y_remainder)}')\n",
    "print(f'Test Set Score: {best_model.score(X_test, y_test)}')\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f6d896",
   "metadata": {},
   "source": [
    "##### Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9c7d94",
   "metadata": {},
   "source": [
    "Let's plot the confusion matrix for the Decision Tree model and get prediction for test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "1e63d8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting confusion matrix\n",
    "plot_confusion_matrix(best_model, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b5537eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class predictions\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1471a7f1",
   "metadata": {},
   "source": [
    "Let's get the Classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "91b19f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.87      0.80      4751\n",
      "         1.0       0.54      0.34      0.42      2132\n",
      "\n",
      "    accuracy                           0.70      6883\n",
      "   macro avg       0.64      0.60      0.61      6883\n",
      "weighted avg       0.68      0.70      0.68      6883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification score\n",
    "dt_report = classification_report(y_test, y_pred)\n",
    "print(dt_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1c0a8d",
   "metadata": {},
   "source": [
    "Summary of Models:\n",
    "\n",
    "|      **Model**      | **Remainder Accuracy** | **Test Accuracy** | **Recall** | **Precision** | **F1 Score** | **Best Parameters**                                                          |\n",
    "|:-------------------:|:----------------------:|:-----------------:|------------|---------------|--------------|------------------------------------------------------------------------------|\n",
    "| Logistic Regression | 0.696                  | 0.691             | 0.14       | 0.51          | 0.23         | MinMaxScaler(), No dimension reduction,  LR__C=1000, LR__solver='liblinear'  |\n",
    "|  Decision Tree 1    | 0.722                  | 0.717             | 0.26       | 0.60          | 0.36         | max_depth=6                                                                  |\n",
    "| Decision Tree 2     | 0.728                  | 0.704             | 0.34       | 0.54          | 0.42         | max_depth=7, criterion='gini'                                                |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89d5dd8",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01db807d",
   "metadata": {},
   "source": [
    "#### Optimize for `max_depth`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa64e40e",
   "metadata": {},
   "source": [
    "Let's use a for loop to optimize for max_depth. We will also use the unscaled train and validation sets for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "d7bb2016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [05:54<00:00,  2.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# running model for different max depths\n",
    "depths = list(range(1, int(np.sqrt(len(X_train))))) # range of max_depths to be tested\n",
    "train_scores_rforest = []\n",
    "validation_scores_rforest = []\n",
    "\n",
    "for d in tqdm(depths):\n",
    "\n",
    "    rforest = RandomForestClassifier(max_depth = d)\n",
    "    rforest.fit(X_train, y_train)\n",
    "        \n",
    "    # Evaluate\n",
    "    train_scores_rforest.append(rforest.score(X_train, y_train))\n",
    "    validation_scores_rforest.append(rforest.score(X_validation, y_validation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419edc47",
   "metadata": {},
   "source": [
    "Let's plot the accuracy scores against max_depth to find out the best max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "cf037cd3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The runtime of your code is: 0:00:00.137456 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer()\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(depths, train_scores_rforest, c='blue', label='train')\n",
    "plt.plot(depths, validation_scores_rforest, c='red', label='validation')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title(\"Random Forest max_depth tuning\")\n",
    "plt.legend()\n",
    "\n",
    "sns.despine()\n",
    "plt.show()\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad48808",
   "metadata": {},
   "source": [
    "From the plot, we can see that the model starts to seriously over fit sometime around a max_depth of 20. Let's make a plot for max_depth from 1-20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e267e1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The runtime of your code is: 0:00:00.148258 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer()\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(depths, train_scores_rforest, c='blue', label='train')\n",
    "plt.plot(depths, validation_scores_rforest, c='red', label='validation')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title(\"Random Forest max_depth tuning\")\n",
    "plt.xlim([1,21])\n",
    "plt.xticks(range(0,21,1))\n",
    "plt.legend()\n",
    "\n",
    "sns.despine()\n",
    "plt.show()\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da8377a",
   "metadata": {},
   "source": [
    "Based on the plot, ideal values for `max_depth` could lie between 6 and 11. Let's run a `GridSearchCV` to see if we can find the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57621a9",
   "metadata": {},
   "source": [
    "#### 5-fold Cross Validation\n",
    "\n",
    "We will optimize for `max_depth` and `criterion`. I will also add PCA() optimization to the mix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "61591470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimators for pipeline\n",
    "estimators = [\n",
    "    ('reduce_dim', PCA()),\n",
    "    ('RF', RandomForestClassifier())\n",
    "]\n",
    "\n",
    "# pipeline creation\n",
    "pipe = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5754b15f",
   "metadata": {},
   "source": [
    "Next, let's create the `param-grid`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "0583690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param-grid\n",
    "params = [\n",
    "    {'RF': [RandomForestClassifier()],\n",
    "     'reduce_dim': [PCA()],\n",
    "     'RF__max_depth': [5, 6, 7, 8, 9, 10, 11, 12],\n",
    "     'RF__criterion': ['gini', 'entropy'],\n",
    "     'reduce_dim__n_components': [6, 8, None]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0da15c",
   "metadata": {},
   "source": [
    "Now we create `GridSearchCV` object and fit the grid to the remainder data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c80f6814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.3s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.7s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.7s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.7s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.7s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.7s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.0s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.0s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.9s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.9s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.9s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.3s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.3s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.3s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.3s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.7s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.9s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.7s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.5s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.5s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.5s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.9s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.9s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.0s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.0s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.0s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.0s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.7s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.7s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.0s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.9s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.3s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.5s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.3s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.5s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.3s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.3s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.3s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.5s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.5s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.5s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.7s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.3s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.5s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=gini, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.3s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   1.9s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.0s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.9s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.9s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.5s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=5, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.0s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.0s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=6, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.9s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.5s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.5s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=7, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.7s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.7s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.9s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   2.7s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.7s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.7s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.7s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   4.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=8, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   3.9s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   3.0s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   3.0s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   3.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   3.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   3.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.9s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.9s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.9s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   3.0s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   2.9s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   4.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   4.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   4.3s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   4.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=9, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   4.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   3.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   3.3s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   3.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   3.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   3.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   3.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   3.3s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   3.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   3.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   3.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   4.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   4.5s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   4.5s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   4.5s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   4.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   3.5s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   3.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   3.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   3.5s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   3.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   3.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   3.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   3.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   3.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   3.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   5.0s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   5.2s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   4.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   4.9s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=11, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   4.8s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   3.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   3.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   3.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   3.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=6; total time=   3.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   3.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   3.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   3.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   3.7s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   3.6s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   5.1s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   5.3s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   5.5s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   5.4s\n",
      "[CV] END RF=RandomForestClassifier(), RF__criterion=entropy, RF__max_depth=12, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   6.5s\n",
      "The runtime of your code is: 0:11:08.679923 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer() # start timer\n",
    "# GridSearchCv object\n",
    "grid = GridSearchCV(pipe, param_grid=params, cv=5, verbose=2)\n",
    "\n",
    "# fitting the grid\n",
    "fittedgrid = grid.fit(X_remainder, y_remainder)\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb61720",
   "metadata": {},
   "source": [
    "Since the model took ~11 minutes to train, I will save fittedgrid as a .pkl file to save future computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "3a000729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['randomForest_gridSearch.pkl']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving file as .pkl\n",
    "joblib.dump(fittedgrid, 'randomForest_gridSearch.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa40d8d8",
   "metadata": {},
   "source": [
    "Let's find the best params and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "def13439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .pkl file\n",
    "fitgrid = joblib.load('randomForest_gridSearch.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "5ab17b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model\n",
    "best_model = fitgrid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "90f65a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RF': RandomForestClassifier(max_depth=12),\n",
       " 'RF__criterion': 'gini',\n",
       " 'RF__max_depth': 12,\n",
       " 'reduce_dim': PCA(),\n",
       " 'reduce_dim__n_components': None}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best set of parameters\n",
    "fitgrid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b134565e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7420082250566917"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best score\n",
    "fitgrid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7c1056",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16970545",
   "metadata": {},
   "source": [
    "##### Accuracy Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e7b4bc",
   "metadata": {},
   "source": [
    "Let's fit the best model to the reaminder set and calculate accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "2e753ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The runtime of your code is: 0:00:04.209640 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer()\n",
    "# fit best_model\n",
    "best_model.fit(X_remainder, y_remainder)\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "cd01bcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remainder Set Score: 0.8604707477721814\n",
      "Test Set Score: 0.7444428301612669\n",
      "The runtime of your code is: 0:00:00.316700 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer()\n",
    "# accuracy scores\n",
    "print(f'Remainder Set Score: {best_model.score(X_remainder, y_remainder)}')\n",
    "print(f'Test Set Score: {best_model.score(X_test, y_test)}')\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad090d7",
   "metadata": {},
   "source": [
    "##### Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1567b8d3",
   "metadata": {},
   "source": [
    "Let's plot the confusion matrix for the Random Forest model and get prediction for test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "4602c10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting confusion matrix\n",
    "plot_confusion_matrix(best_model, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "363ddc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class predictions\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabd4a46",
   "metadata": {},
   "source": [
    "Let's get the Classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f869f919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.95      0.84      4751\n",
      "         1.0       0.71      0.29      0.41      2132\n",
      "\n",
      "    accuracy                           0.74      6883\n",
      "   macro avg       0.73      0.62      0.63      6883\n",
      "weighted avg       0.74      0.74      0.71      6883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification score\n",
    "rForest_report = classification_report(y_test, y_pred)\n",
    "print(rForest_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20266a28",
   "metadata": {},
   "source": [
    "Summary of Models:\n",
    "\n",
    "|      **Model**      | **Remainder Accuracy** | **Test Accuracy** | **Recall** | **Precision** | **F1 Score** | **Best Parameters**                                                          |\n",
    "|:-------------------:|:----------------------:|:-----------------:|------------|---------------|--------------|------------------------------------------------------------------------------|\n",
    "| Logistic Regression | 0.696                  | 0.691             | 0.14       | 0.51          | 0.23         | MinMaxScaler(), No dimension reduction,  LR__C=1000, LR__solver='liblinear'  |\n",
    "|  Decision Tree 1    | 0.722                  | 0.717             | 0.26       | 0.60          | 0.36         | max_depth=6                                                                  |\n",
    "| Decision Tree 2     | 0.728                  | 0.704             | 0.34       | 0.54          | 0.42         | max_depth=7, criterion='gini'                                                |\n",
    "| Random Forest 1     | 0.860                  | 0.744             | 0.29       | 0.71          | 0.41         | max_depth=12, criterion='gini'                                               |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d4e131",
   "metadata": {},
   "source": [
    "`GridSearchCv` has given us quite an overfitting model. I will try a RandomForestCalssifier() with a max_depth of 10. Based on the previously plotted graph for max_depth optimization, this should lower the overfitting whil maintaining similar accuracy scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "0fc91391",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the model\n",
    "rforest = RandomForestClassifier(max_depth=10)\n",
    "\n",
    "# fit the model\n",
    "rforest.fit(X_remainder, y_remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443b0b5d",
   "metadata": {},
   "source": [
    "##### Accuracy Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "088d9499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remainder Set Score: 0.7844827586206896\n",
      "Test Set Score: 0.7400842655818684\n",
      "The runtime of your code is: 0:00:00.293382 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer()\n",
    "# accuracy scores\n",
    "print(f'Remainder Set Score: {rforest.score(X_remainder, y_remainder)}')\n",
    "print(f'Test Set Score: {rforest.score(X_test, y_test)}')\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894a6697",
   "metadata": {},
   "source": [
    "##### Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb7d38b",
   "metadata": {},
   "source": [
    "Let's plot the confusion matrix for the Random Forest model and get prediction for test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "341eac84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting confusion matrix\n",
    "plot_confusion_matrix(rforest, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "87485a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class predictions\n",
    "y_pred = rforest.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36a081d",
   "metadata": {},
   "source": [
    "Let's get the Classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "cef81427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.95      0.84      4751\n",
      "         1.0       0.71      0.29      0.41      2132\n",
      "\n",
      "    accuracy                           0.74      6883\n",
      "   macro avg       0.73      0.62      0.63      6883\n",
      "weighted avg       0.74      0.74      0.71      6883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification score\n",
    "rforest_report = classification_report(y_test, y_pred)\n",
    "print(rforest_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dfb01f",
   "metadata": {},
   "source": [
    "Summary of Models:\n",
    "\n",
    "|      **Model**      | **Remainder Accuracy** | **Test Accuracy** | **Recall** | **Precision** | **F1 Score** | **Best Parameters**                                                          |\n",
    "|:-------------------:|:----------------------:|:-----------------:|------------|---------------|--------------|------------------------------------------------------------------------------|\n",
    "| Logistic Regression | 0.696                  | 0.691             | 0.14       | 0.51          | 0.23         | MinMaxScaler(), No dimension reduction,  LR__C=1000, LR__solver='liblinear'  |\n",
    "|  Decision Tree 1    | 0.722                  | 0.717             | 0.26       | 0.60          | 0.36         | max_depth=6                                                                  |\n",
    "| Decision Tree 2     | 0.728                  | 0.704             | 0.34       | 0.54          | 0.42         | max_depth=7, criterion='gini'                                                |\n",
    "| Random Forest 1     | 0.860                  | 0.744             | 0.29       | 0.71          | 0.41         | max_depth=12, criterion='gini'                                               |\n",
    "| Random Forest 2     | 0.784                  | 0.740             | 0.29       | 0.71       | 0.41         | max_depth=10                                                                 |                                           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f92351",
   "metadata": {},
   "source": [
    "A `max_depth` of 10 reduces the overfitting significantly while maintaining the same accuracy, recall and precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392152a1",
   "metadata": {},
   "source": [
    "### XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563f21cc",
   "metadata": {},
   "source": [
    "#### Optimize for `max_depth`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd20a48",
   "metadata": {},
   "source": [
    "Let's use a for loop to optimize for max_depth. We will also use the unscaled train and validation sets for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "f933fc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/123 [00:00<00:23,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:10] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:04:11] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/123 [00:00<00:30,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:11] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 3/123 [00:00<00:37,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:11] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 4/123 [00:01<00:53,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:12] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 5/123 [00:02<01:07,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:13] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 6/123 [00:03<01:16,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:14] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 7/123 [00:04<01:30,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:15] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 8/123 [00:05<01:45,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:16] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 9/123 [00:06<02:02,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:17] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 10/123 [00:08<02:19,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:19] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 11/123 [00:10<02:40,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:21] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 12/123 [00:12<03:01,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:23] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 13/123 [00:14<03:17,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:25] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█▏        | 14/123 [00:16<03:32,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:27] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 15/123 [00:19<04:02,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:30] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 16/123 [00:22<04:14,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:33] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 17/123 [00:25<04:21,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:36] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 18/123 [00:27<04:28,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:38] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 19/123 [00:30<04:32,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:41] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 20/123 [00:33<04:45,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:44] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 21/123 [00:36<04:55,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:47] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 22/123 [00:40<05:00,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:51] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 23/123 [00:43<05:05,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:54] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 24/123 [00:46<05:10,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:57] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 25/123 [00:50<05:17,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:05:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 26/123 [00:53<05:16,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:05:04] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 27/123 [00:56<05:19,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:05:07] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 28/123 [01:00<05:16,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:05:11] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 29/123 [01:03<05:18,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:05:14] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 30/123 [01:07<05:35,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:05:18] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 31/123 [01:11<05:27,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:05:22] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 32/123 [01:14<05:16,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:05:25] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 33/123 [01:18<05:08,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:05:28] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 34/123 [01:21<05:07,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:05:32] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 35/123 [01:25<05:06,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:05:35] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 36/123 [01:28<04:59,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:05:39] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 37/123 [01:31<04:56,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:05:42] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 38/123 [01:35<04:51,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:05:46] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 39/123 [01:39<04:57,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:05:49] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 40/123 [01:42<04:49,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:05:53] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 41/123 [01:46<04:52,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:05:57] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 42/123 [01:49<04:44,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:06:00] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▍      | 43/123 [01:52<04:33,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:06:03] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 44/123 [01:56<04:32,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:06:07] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 45/123 [01:59<04:26,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:06:10] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 46/123 [02:02<04:20,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:06:13] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 47/123 [02:06<04:17,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:06:17] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 48/123 [02:09<04:17,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:06:20] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███▉      | 49/123 [02:13<04:14,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:06:24] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 50/123 [02:16<04:11,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:06:27] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████▏     | 51/123 [02:20<04:11,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:06:31] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 52/123 [02:24<04:11,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:06:34] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 53/123 [02:28<04:19,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:06:39] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 54/123 [02:31<04:15,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:06:42] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▍     | 55/123 [02:35<04:12,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:06:46] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 56/123 [02:39<04:08,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:06:50] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▋     | 57/123 [02:43<04:09,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:06:54] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 58/123 [02:46<04:02,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:06:57] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 59/123 [02:50<03:57,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:07:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 60/123 [02:54<03:51,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:07:05] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████▉     | 61/123 [02:57<03:49,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:07:08] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 62/123 [03:01<03:46,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:07:12] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 63/123 [03:05<03:40,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:07:16] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 64/123 [03:08<03:36,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:07:19] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 65/123 [03:12<03:32,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:07:23] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▎    | 66/123 [03:16<03:34,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:07:27] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 67/123 [03:20<03:27,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:07:30] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 68/123 [03:23<03:20,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:07:34] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 69/123 [03:27<03:16,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:07:38] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 70/123 [03:31<03:17,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:07:42] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 71/123 [03:34<03:11,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:07:45] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▊    | 72/123 [03:38<03:11,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:07:49] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 73/123 [03:42<03:07,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:07:53] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 74/123 [03:46<03:04,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:07:57] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 75/123 [03:49<02:59,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:08:00] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 76/123 [03:53<02:54,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:08:04] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 77/123 [03:57<02:49,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:08:08] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 78/123 [04:01<02:51,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:08:12] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 79/123 [04:05<02:57,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:08:16] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 80/123 [04:09<02:52,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:08:20] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 81/123 [04:13<02:49,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:08:24] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 82/123 [04:17<02:45,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:08:28] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 83/123 [04:21<02:39,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:08:32] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 84/123 [04:25<02:37,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:08:36] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 85/123 [04:29<02:27,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:08:40] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████▉   | 86/123 [04:32<02:19,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:08:43] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 87/123 [04:36<02:17,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:08:47] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 88/123 [04:40<02:12,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:08:51] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 89/123 [04:44<02:06,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:08:55] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 90/123 [04:47<02:01,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:08:58] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 91/123 [04:51<02:00,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:09:02] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▍  | 92/123 [04:55<01:55,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:09:06] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 93/123 [04:58<01:50,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:09:09] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▋  | 94/123 [05:02<01:46,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:09:13] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 95/123 [05:06<01:44,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:09:17] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 96/123 [05:09<01:39,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:09:20] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 97/123 [05:13<01:34,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:09:24] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████▉  | 98/123 [05:17<01:30,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:09:28] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 99/123 [05:20<01:26,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:09:31] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████▏ | 100/123 [05:24<01:25,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:09:35] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 101/123 [05:28<01:21,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:09:39] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 102/123 [05:31<01:16,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:09:42] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▎ | 103/123 [05:35<01:14,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:09:46] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 104/123 [05:40<01:14,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:09:50] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 105/123 [05:43<01:10,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:09:54] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 106/123 [05:47<01:05,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:09:58] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 107/123 [05:51<01:00,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:10:02] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 108/123 [05:55<00:57,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:10:06] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▊ | 109/123 [05:58<00:52,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:10:09] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 110/123 [06:02<00:48,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:10:13] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 111/123 [06:06<00:44,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:10:16] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 112/123 [06:09<00:40,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:10:20] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 113/123 [06:13<00:37,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:10:24] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 114/123 [06:17<00:33,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:10:28] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 115/123 [06:20<00:29,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:10:31] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 116/123 [06:24<00:25,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:10:35] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 117/123 [06:28<00:22,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:10:39] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 118/123 [06:31<00:18,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:10:42] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 119/123 [06:35<00:14,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:10:46] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 120/123 [06:39<00:10,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:10:49] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 121/123 [06:43<00:07,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:10:54] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 122/123 [06:46<00:03,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:10:57] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [06:50<00:00,  3.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# running model for different max depths\n",
    "depths = list(range(1, int(np.sqrt(len(X_train))))) # range of max_depths to be tested\n",
    "train_scores_xgb = []\n",
    "validation_scores_xgb = []\n",
    "\n",
    "for d in tqdm(depths):\n",
    "\n",
    "    xgb = XGBClassifier(max_depth = d)\n",
    "    xgb.fit(X_train, y_train)\n",
    "        \n",
    "    # Evaluate\n",
    "    train_scores_xgb.append(xgb.score(X_train, y_train))\n",
    "    validation_scores_xgb.append(xgb.score(X_validation, y_validation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326f6b9b",
   "metadata": {},
   "source": [
    "Let's plot the accuracy scores against max_depth to find out the best max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "1c055904",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The runtime of your code is: 0:00:00.140269 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer()\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(depths, train_scores_xgb, c='blue', label='train')\n",
    "plt.plot(depths, validation_scores_xgb, c='red', label='validation')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title(\"XGBoost max_depth tuning\")\n",
    "plt.legend()\n",
    "\n",
    "sns.despine()\n",
    "plt.show()\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d875f1f2",
   "metadata": {},
   "source": [
    "From the plot, we can see that the model starts to seriously over fit sometime around a max_depth of 20. Let's make a plot for max_depth from 1-20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "f45782d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAJuCAYAAABcwPghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAACKv0lEQVR4nOzdeZxN9ePH8fedfSwzDJkhjH1fssWQX1G2JFJRJLIlZCtJUpSMJVtky5aS5RuhKEZJRLYMlbWym7GbMYNZz++P0wzXDGbGnTmzvJ6Px33Mueeee+/7Xlz3PZ9zPsdmGIYhAAAAAMB9cbI6AAAAAABkB5QrAAAAAHAAyhUAAAAAOADlCgAAAAAcgHIFAAAAAA5AuQIAAAAAB6BcAQAAAIADUK4AAAAAwAEoVwAAAADgAJQrAEhHXbt2lbu7u/74448kt40ZM0Y2m03ffvut3frw8HCNGTNGdevWVb58+eTq6ipfX181b95cX331laKiohK3PXbsmGw2m93Fy8tL1atX1+TJkxUXF5fur/Fepk+frgULFlgdI8P9/PPPstls+vnnn9P1ee70/iY8/9dff52mx926datGjBihK1eu3F/AFHrsscf02GOPZchzAUB6oVwBQDqaPHmy/Pz81LlzZ8XExCSu/+OPP/T++++rS5cuatWqVeL6I0eOqEaNGvroo4/0yCOPaOHChfrpp580depUPfjgg+ratatGjRqV5Hlef/11bdu2Tdu2bdOyZcvUoEEDDRw4UG+99VaGvM67yanlKqOk1/u7detWjRw5MsPK1fTp0zV9+vQMeS4ASC8uVgcAgOzMy8tLc+fOVdOmTTVq1CiNHDlSMTEx6tSpk3x9fTV58uTEbWNjY9WmTRtdunRJO3bsUMWKFe0eq127dnrvvfe0Z8+eJM9TvHhx1atXL/F68+bN9eeff2rx4sWaMGFCur0+wFEqVapkdQQAuG+MXAFAOnviiSfUq1cvjR49Wrt379aIESO0d+9ezZ07V97e3onbffPNN9q/f7+GDRuWpFgl8Pf3V5s2bVL0vN7e3nJ1dbVbFx8fr3HjxqlChQpyd3dXoUKF9PLLL+vUqVNJ7j9v3jxVr15dHh4e8vHx0TPPPKMDBw7YbfPvv//qhRdeUJEiReTu7i5fX189/vjjCg4OliSVKFFCf/31lzZt2pS422KJEiXumttms6lv376aP3++ypcvL09PT9WuXVu//fabDMPQ+PHjVbJkSeXJk0eNGzfW33//bXf/oKAgtW7dWkWLFpWHh4fKlCmjV199VRcuXEjc5saNG6pRo4bKlCmjsLCwxPWhoaHy8/PTY489lqpdKg8ePKjmzZsrV65cKliwoHr16qWrV68mu+2GDRv0+OOPy8vLS7ly5VKDBg30448/2m0zYsQI2Ww27dmzR23btpWXl5e8vb310ksv6fz584nbpeT9jYmJ0bBhw1SkSBF5eXnpiSee0KFDh+76ekaMGKHBgwdLkkqWLJn42Am7ONpsNo0YMSLJ/UqUKKEuXbokXl+wYIFsNps2btyo1157TQULFlSBAgXUtm1bnTlzxu6+t+8WmLDL68cff6yJEycm/pkHBATot99+S/Lcn332mcqVKyd3d3dVqlRJX331lbp06XLPv28A4FAGACDdRUREGKVKlTJKlChhODs7G7169UqyTY8ePQxJxqFDh1L8uEePHjUkGWPHjjViYmKMmJgY48KFC8bcuXMNFxcXY9iwYXbb9+zZ05Bk9O3b1/jhhx+MmTNnGg888IBRrFgx4/z584nbjR492pBkvPjii8aaNWuMhQsXGqVKlTK8vb2Nw4cPJ25Xvnx5o0yZMsYXX3xhbNq0yVi+fLnxxhtvGBs3bjQMwzB+//13o1SpUkaNGjWMbdu2Gdu2bTN+//33u74mSYa/v79Rv359Y8WKFcY333xjlCtXzvDx8TEGDhxotG7d2vjuu++MRYsWGb6+vka1atWM+Pj4xPvPmDHDCAwMNFavXm1s2rTJ+Pzzz43q1asb5cuXN6KjoxO3O3z4sJE3b16jbdu2hmEYRlxcnNG4cWOjUKFCxpkzZ1L8ZxAaGmoUKlTIePDBB4358+cba9euNTp27GgUL17ckJT4XhiGYXzxxReGzWYz2rRpY6xYscL49ttvjaeeespwdnY2NmzYkLjd+++/n/g+DB482Fi3bp0xceJEI3fu3EaNGjUSX8fd3t+NGzcakowSJUoYHTt2NNasWWMsXrzYKF68uFG2bFkjNjb2jq/p5MmTxuuvv25IMlasWJH42GFhYYl/Ru+//36S+/n7+xudO3dOvD5//nxDklGqVCnj9ddfN9atW2fMmTPHyJ8/v9GoUSO7+z766KPGo48+mng94e92iRIljObNmxsrV640Vq5caVStWtXInz+/ceXKlcRtZ82aZUgynn322cS/G+XKlTP8/f0Nf3//e/0RAoDDUK4AIIN89dVXhiTDz8/PuHr1apLbmzdvbkgybty4Ybc+Pj4+sTjFxMTYfSlO+AKa3KVLly522x44cMCQZPTu3dvu8bdv325IMt555x3DMAzj8uXLhqenp/Hkk0/abXfixAnD3d3d6NChg2EYhnHhwgVDkjF58uS7vu7KlSvbfWm+l4T3KCIiInHdypUrDUnGQw89ZFekJk+ebEgy9u3bl+xjJbx3x48fNyQZq1atsrt96dKlia/hvffeM5ycnIz169enOKthGMaQIUMMm81mBAcH261v0qSJXbmKjIw0fHx8jFatWtltFxcXZ1SvXt14+OGHE9cllKuBAwfabbto0SJDkvHll18mrrvT+5tQrm7/c1y2bJkhydi2bdtdX9f48eMNScbRo0eT3JbacnX737lx48YZkoyQkJDEdXcqV1WrVrX7e7xjxw5DkrF48WLDMMz3z8/Pz6hbt67dcxw/ftxwdXWlXAHIUOwWCAAZID4+XlOnTpWTk5POnTunvXv3pvi+U6ZMkaura+KlevXqSbbp37+/du7cqZ07d2rjxo0aPXq0li1bphdffDFxm40bN0qS3W5bkvTwww+rYsWKibumbdu2TdevX0+yXbFixdS4cePE7Xx8fFS6dGmNHz9eEydO1J49exQfH5/i13U3jRo1Uu7cuROvJ+wm2aJFC9lstiTrjx8/nrju3Llz6tWrl4oVKyYXFxe5urrK399fkpLs1tiuXTu99tprGjx4sEaNGqV33nlHTZo0SVXWjRs3qnLlykn+XDp06GB3fevWrbp06ZI6d+6s2NjYxEt8fLyaN2+unTt3KjIy0u4+HTt2TJLXxcUl8c8yJZ5++mm769WqVZNk/56lt/vJ0LJlSzk7O9/xvocOHVJoaKjatWtnd7/ixYurQYMG95UbAFKLcgUAGeDjjz/Wtm3b9NVXX6ls2bLq2rWrrl+/brdN8eLFJSX9wtmhQ4fE4lSzZs1kH79o0aKqXbu2ateurccee0xDhw7V8OHD9b///U/r1q2TJF28eFGSVLhw4ST3L1KkSOLtKd3OZrPpxx9/VLNmzTRu3DjVrFlTDzzwgPr163fH441SysfHx+66m5vbXdffuHFDkllimzZtqhUrVuitt97Sjz/+qB07diQeo3P7ey6Z0+XHxMTIxcVF/fr1S3XWixcvys/PL8n629edPXtWkvTcc8/ZlWVXV1eNHTtWhmHo0qVLd30MFxcXFShQIPHPICUKFChgd93d3V1S8u9FermfDPe6b8J74evrm+S+ya0DgPREuQKAdLZ//3699957evnll9W+fXstWLBAf//9t4YNG2a3XcKIyerVq+3WFypUKLE45c2bN8XPm/Ab/oRRsoQvqSEhIUm2PXPmjAoWLJiq7SRzgo25c+cqNDRUhw4d0sCBAzV9+vTEyRAy2p9//qm9e/dq/Pjxev311/XYY4+pTp06Sb6gJ4iMjFSnTp1Urlw5eXp6qnv37ql+zgIFCig0NDTJ+tvXJbxvU6dOTSzLt19uLwO3P0ZsbKwuXrx4x9eTUdzd3e3Ot5YgNaXPURLei4Tyeqvk/lwAID1RrgAgHcXGxqpz584qWLCgpkyZIkmqV6+eBg0apClTpujXX39N3PaZZ55RpUqVNHr0aB08ePC+nzthxr5ChQpJkho3bixJ+vLLL+2227lzpw4cOKDHH39ckhQQECBPT88k2506dUo//fRT4na3K1eunN59911VrVpVv//+e+J6d3f3DBslSdhlMGF0I8GsWbOS3b5Xr146ceKEVqxYoblz52r16tWaNGlSqp6zUaNG+uuvv5Ls6vnVV1/ZXW/QoIHy5cun/fv3J5bl2y8JI3EJFi1aZHd92bJlio2NtZtVL73e37uNLpUoUUL79u2zW/fTTz8pIiLC4TnupXz58vLz89OyZcvs1p84cUJbt27N8DwAcjbOcwUA6SgwMFC7du3S999/r3z58iWu//DDD/Xtt9+qa9euCg4Olqenp5ydnbVy5Uo1a9ZMDz/8sHr06KHHHntM+fPn15UrV7R9+3bt3bs32WnaT5w4kbjrW2RkpLZt26bAwED5+/urbdu2kswvoT179kw89qtFixY6duyYhg8frmLFimngwIGSpHz58mn48OF655139PLLL+vFF1/UxYsXNXLkSHl4eOj999+XJO3bt099+/bV888/r7Jly8rNzU0//fST9u3bp7fffjsxW9WqVbVkyRItXbpUpUqVkoeHh6pWrZou73eFChVUunRpvf322zIMQz4+Pvr2228VFBSUZNs5c+boyy+/1Pz581W5cmVVrlxZffv21ZAhQ9SgQQM9/PDDKXrOAQMGaN68eWrZsqVGjRolX19fLVq0KElBzpMnj6ZOnarOnTvr0qVLeu6551SoUCGdP39ee/fu1fnz5zVjxgy7+6xYsUIuLi5q0qSJ/vrrLw0fPlzVq1e3O74ovd7fhMeYMmWKOnfuLFdXV5UvX1558+ZVp06dNHz4cL333nt69NFHtX//fk2bNs3u1AIZxcnJSSNHjtSrr76q5557Tl27dtWVK1c0cuRIFS5cWE5O/B4ZQAayekYNAMiugoODDVdXV6NHjx7J3r5t2zbDyckpyYxwYWFhxujRo406deoYXl5ehouLi1GoUCGjSZMmxqeffmpERkYmbpvcbIEeHh5GuXLljAEDBtjNxmYY5sxqY8eONcqVK2e4uroaBQsWNF566SXj5MmTSfLNmTPHqFatmuHm5mZ4e3sbrVu3Nv7666/E28+ePWt06dLFqFChgpE7d24jT548RrVq1YxJkybZze527Ngxo2nTpkbevHkTpxe/G0lGnz597NYlvM7x48fbrU+YEe9///tf4rr9+/cbTZo0MfLmzWvkz5/feP75540TJ07YzXC3b98+w9PT025mO8MwjBs3bhi1atUySpQoYVy+fPmuOW+V8JweHh6Gj4+P0a1bN2PVqlVJpmI3DMPYtGmT0bJlS8PHx8dwdXU1HnzwQaNly5Z2ryFhtsDdu3cbrVq1MvLkyWPkzZvXePHFF42zZ8/aPd6d3t/k3ptb38v58+ff83UNHTrUKFKkiOHk5GT3WqKiooy33nrLKFasmOHp6Wk8+uijRnBw8B1nC9y5c6fd4yZku/W9udNsgbf/mRtG8rMVzp492yhTpozh5uZmlCtXzpg3b57RunVro0aNGvd8nQDgKDbDMIwM7nMAAOAuRowYoZEjR+r8+fN2x7gh5a5cuaJy5cqpTZs2mj17ttVxAOQQ7BYIAACytNDQUH300Udq1KiRChQooOPHj2vSpEm6evWq+vfvb3U8ADkI5QoAgGQYhqG4uLi7buPs7Gx33i1Yw93dXceOHVPv3r116dIl5cqVS/Xq1dPMmTNVuXJlq+MByEHYLRAAgGT8/PPPatSo0V23mT9/fpKTLQMAci7KFQAAybh69aoOHTp0121Klixp+TmnAACZB+UKAAAAAByAkz8AAAAAgANQrpJhGIbCw8PFoB4AAACAlKJcJePq1avy9vbW1atXrY4CAAAAIIugXAEAAACAA1CuAAAAAMABKFcAAAAA4ACUKwAAAABwAMoVAAAAADiAi9UBsirDMBQbG6u4uDiro8ABnJ2d5eLiIpvNZnUUAAAAZFGUqzSIjo5WSEiIrl27ZnUUOFCuXLlUuHBhubm5WR0FAAAAWRDlKpXi4+N19OhROTs7q0iRInJzc2O0I4szDEPR0dE6f/68jh49qrJly8rJiT1mAQAAkDqUq1SKjo5WfHy8ihUrply5clkdBw7i6ekpV1dXHT9+XNHR0fLw8LA6EgAAALIYfj2fRoxsZD/8mQIAAOB+8G0SAAAAAByAcgUAAAAADkC5QpqUKFFCkydPtjoGAAAAkGkwoUUO8thjj+mhhx5ySCnauXOncufOff+hAAAAgGyCcoVEhmEoLi5OLi73/mvxwAMPZEAiAAAAIOtgt0AHMAwpMtKai2GkLGOXLl20adMmTZkyRTabTTabTQsWLJDNZtO6detUu3Ztubu7a/Pmzfrnn3/UunVr+fr6Kk+ePKpTp442bNhg93i37xZos9k0Z84cPfPMM8qVK5fKli2r1atXO/BdBgAAADI3ypUDXLsm5cljzeXatZRlnDJligICAtSjRw+FhIQoJCRExYoVkyS99dZbCgwM1IEDB1StWjVFREToySef1IYNG7Rnzx41a9ZMrVq10okTJ+76HCNHjlS7du20b98+Pfnkk+rYsaMuXbp0v28vAAAAkCVQrnIIb29vubm5KVeuXPLz85Ofn5+cnZ0lSR988IGaNGmi0qVLq0CBAqpevbpeffVVVa1aVWXLltWoUaNUqlSpe45EdenSRS+++KLKlCmj0aNHKzIyUjt27MiIlwcAAABYjmOuHCBXLikiwrrnvl+1a9e2ux4ZGamRI0fqu+++05kzZxQbG6vr16/fc+SqWrVqicu5c+dW3rx5de7cufsPCAAAAGQBlo5c/fLLL2rVqpWKFCkim82mlStX3vM+mzZtUq1ateTh4aFSpUpp5syZSbZZvny5KlWqJHd3d1WqVEnffPNNOqS/yWaTcue25mKz3X/+22f9Gzx4sJYvX66PPvpImzdvVnBwsKpWraro6Oi7Po6rq+tt74tN8fHx9x8QAAAAyAIsLVeRkZGqXr26pk2blqLtjx49qieffFINGzbUnj179M4776hfv35avnx54jbbtm1T+/bt1alTJ+3du1edOnVSu3bttH379vR6GVmGm5ub4uLi7rnd5s2b1aVLFz3zzDOqWrWq/Pz8dOzYsfQPCAAAAGRhlu4W2KJFC7Vo0SLF28+cOVPFixdPnKWuYsWK2rVrlz7++GM9++yzkqTJkyerSZMmGjp0qCRp6NCh2rRpkyZPnqzFixc7/DVkJSVKlND27dt17Ngx5cmT546jSmXKlNGKFSvUqlUr2Ww2DR8+nBEoAAAA4B6y1DFX27ZtU9OmTe3WNWvWTHPnzlVMTIxcXV21bds2DRw4MMk2dztxblRUlKKiohKvh4eHOzR3ZvHmm2+qc+fOqlSpkq5fv6758+cnu92kSZPUtWtX1a9fXwULFtSQIUOy7XsCIGuKjZUuXpTOnzcvFy7Y/7xyRYqPN09XkRE/U7ptwkW6v+uOeAwAQMqldIbuLFWuQkND5evra7fO19dXsbGxunDhggoXLnzHbUJDQ+/4uIGBgRo5cmS6ZM5MypUrp23bttmt69KlS5LtSpQooZ9++sluXZ8+feyu376boJHM/9RXrlxJU04AOUvCuQJvLUfJFaZbf16+bHVqAACSylLlSjInSbhVwpf6W9cnt83t6241dOhQDRo0KPF6eHh44jmgAACpExdnjiqltCidPy/dsvNAitlsko+PVLCg9MAD9j/z55ecnc1tnJzMS8Jyev281za3XxJeg6Oup/UxAACOk6XKlZ+fX5IRqHPnzsnFxUUFChS46za3j2bdyt3dXe7u7o4PDADZ3IYN0qxZUkjIzaJ0+XLadjvz8Ehaku72M39+ySVL/S8GAMjustR/SwEBAfr222/t1q1fv161a9dOnAY8ICBAQUFBdsddrV+/XvXr18/QrACQnUVESG+9Jc2Ycedt7jSqdKefjjq9BAAAVrG0XEVEROjvv/9OvH706FEFBwfLx8dHxYsX19ChQ3X69GktXLhQktSrVy9NmzZNgwYNUo8ePbRt2zbNnTvXbhbA/v376//+7/80duxYtW7dWqtWrdKGDRu0ZcuWDH99AJAdbdkideki/fOPef3VV6UnnrAvSz4+jCoBAHIeS//r27Vrlxo1apR4PeG4p86dO2vBggUKCQnRiRMnEm8vWbKk1q5dq4EDB+rTTz9VkSJF9MknnyROwy5J9evX15IlS/Tuu+9q+PDhKl26tJYuXaq6detm3AsDgGzoxg3pvfekjz82d/srWlSaP98sVgAAQLIZyU3zlsOFh4fL29tbYWFh8vLysrvtxo0bOnr0qEqWLCkPDw+LEiI98GcL3NmePVKnTtJff5nXO3eWJk+W8uWzMhUAAJmLk9UBAACZV2ys9OGH0sMPm8WqUCHpm2+kBQsoVgAA3I494gEAyTpwwByh2rnTvN62rTRzpnlMFQAASIqRKwCAnfh4c5e/mjXNYpUvn/Tll9LXX1OsAAC4G8oVUqxEiRKaPHly4nWbzaaVK1fecftjx47JZrMpODj4vp7XUY8D4N6OHZMaN5YGDjQnsGjaVPrjD6ljR6ZJBwDgXtgtEGkWEhKi/PnzO/Qxu3TpoitXrtiVtmLFiikkJEQFCxZ06HMBuMkwpLlzzVIVESHlyiVNmGBOs06pAgAgZShXSDM/P78MeR5nZ+cMey4gJwoJkXr0kNasMa83aCB9/rlUurS1uQAAyGrYLdARDEOKjLTmksKZ9GfNmqUHH3xQ8fHxduuffvppde7cWf/8849at24tX19f5cmTR3Xq1NGGDRvu+pi37xa4Y8cO1ahRQx4eHqpdu7b27Nljt31cXJy6deumkiVLytPTU+XLl9eUKVMSbx8xYoQ+//xzrVq1SjabTTabTT///HOyuwVu2rRJDz/8sNzd3VW4cGG9/fbbio2NTbz9scceU79+/fTWW2/Jx8dHfn5+GjFiRIreKyAnWbJEqlzZLFZubtK4cdKmTRQrAADSgpErR7h2TcqTx5rnjoiQcue+52bPP/+8+vXrp40bN+rxxx+XJF2+fFnr1q3Tt99+q4iICD355JMaNWqUPDw89Pnnn6tVq1Y6dOiQihcvfs/Hj4yM1FNPPaXGjRvryy+/1NGjR9W/f3+7beLj41W0aFEtW7ZMBQsW1NatW9WzZ08VLlxY7dq105tvvqkDBw4oPDxc8+fPlyT5+PjozJkzdo9z+vRpPfnkk+rSpYsWLlyogwcPqkePHvLw8LArUJ9//rkGDRqk7du3a9u2berSpYsaNGigJk2a3PP1ANndxYtS797SsmXm9Zo1pYULzaIFAADShnKVQ/j4+Kh58+b66quvEsvV//73P/n4+Ojxxx+Xs7Ozqlevnrj9qFGj9M0332j16tXq27fvPR9/0aJFiouL07x585QrVy5VrlxZp06d0muvvZa4jaurq0aOHJl4vWTJktq6dauWLVumdu3aKU+ePPL09FRUVNRddwOcPn26ihUrpmnTpslms6lChQo6c+aMhgwZovfee09OTuaAbLVq1fT+++9LksqWLatp06bpxx9/pFwhx1uzRureXQoNlZydpWHDpHfflVxdrU4GAEDWRrlyhFy5zBEkq547hTp27KiePXtq+vTpcnd316JFi/TCCy/I2dlZkZGRGjlypL777judOXNGsbGxun79uk6cOJGixz5w4ICqV6+uXLfkCQgISLLdzJkzNWfOHB0/flzXr19XdHS0HnrooRS/hoTnCggIkO2Wo+wbNGigiIgInTp1KnGkrVq1anb3K1y4sM6dO5eq5wKyk/BwadAgc+IKSapQwRytqlPH2lwAAGQXlCtHsNlStGue1Vq1aqX4+HitWbNGderU0ebNmzVx4kRJ0uDBg7Vu3Tp9/PHHKlOmjDw9PfXcc88pOjo6RY9tpODYr2XLlmngwIGaMGGCAgIClDdvXo0fP17bt29P1eswDMOuWN36/Leud73t1/A2my3JMWdATvHzz1KXLtLx4+ZH1oAB0kcfSZ6eFgcDACAboVzlIJ6enmrbtq0WLVqkv//+W+XKlVOtWrUkSZs3b1aXLl30zDPPSJIiIiJ07NixFD92pUqV9MUXX+j69evy/O/b2m+//Wa3zebNm1W/fn317t07cd0///xjt42bm5vi4uLu+VzLly+3K1lbt25V3rx59eCDD6Y4M5ATXL8uvfOOeVJgSSpRQlqwQHr0UQtDAQCQTTFbYA7TsWNHrVmzRvPmzdNLL72UuL5MmTJasWKFgoODtXfvXnXo0CFVozwdOnSQk5OTunXrpv3792vt2rX6+OOP7bYpU6aMdu3apXXr1unw4cMaPny4du7cabdNiRIltG/fPh06dEgXLlxQTExMkufq3bu3Tp48qddff10HDx7UqlWr9P7772vQoEGJx1sBkHbuNCeqSChWPXpI+/ZRrAAASC98E81hGjduLB8fHx06dEgdOnRIXD9p0iTlz59f9evXV6tWrdSsWTPVrFkzxY+bJ08effvtt9q/f79q1KihYcOGaezYsXbb9OrVS23btlX79u1Vt25dXbx40W4US5J69Oih8uXLq3bt2nrggQf066+/JnmuBx98UGvXrtWOHTtUvXp19erVS926ddO7776byncDyJ6io6Xhw6WAAOngQalwYXMSi9mzpbx5rU4HAED2ZTNScrBMDhMeHi5vb2+FhYXJy8vL7rYbN27o6NGjKlmypDw8PCxKiPTAny2ygz//lF5+WUo4zdyLL0rTpkk+PtbmAgAgJ2DkCgCygbg48wTAtWqZxapAAfMcVl99RbECACCjMKEFAGRxf/9tzgSYsBftU09Jn30m3eV0cQAAIB0wcgUAWZRhSDNmSNWrm8Uqb17zHFarV1OsAACwAiNXAJAFnTolde0qBQWZ1x97TJo/35xqHQAAWIORqzRiHpDshz9TZAWGIX3xhVSlilmsPDykKVOkH3+kWAEAYDVGrlLJ1dVVknTt2rXEk+Uie7h27Zqkm3/GQGZz8aJ5rqpvvjGvP/ywtHChVL68tbkAAICJcpVKzs7Oypcvn86dOydJypUrl2w2m8WpcD8Mw9C1a9d07tw55cuXT87OzlZHApI4cUJq1sw8b5Wrq/T++9KQIZILn+IAAGQa/LecBn7/HSmeULCQPeTLly/xzxbITPbvN4vVqVNS0aLmhBU1alidCgAA3I5ylQY2m02FCxdWoUKFFBMTY3UcOICrqysjVsiUtm2TWraULl+WKlSQ1q+XihWzOhUAAEgO5eo+ODs784UcQLr5/nvp2Wel69elunWlNWvMkwMDAIDMidkCASAT+vJL6emnzWLVvLk5GyDFCgCAzI1yBQCZzMSJUqdOUmys1LGjeYxV7txWpwIAAPdCuQKATMIwzBkA33jDvD5woDnVOmcHAAAga+CYKwDIBGJjpZ49pfnzzetjxkhvvSVxpgcAALIOyhUAWOz6demFF8zd/5ycpNmzpW7drE4FAABSi3IFABa6fNmcuGLLFsnDQ1qyRGrd2upUAAAgLShXAGCRM2fMkwP/+afk7S19+63UsKHVqQAAQFpRrgDAAocPS02bSsePS4ULSz/8IFWrZnUqAABwP5gtEAAy2O7d0iOPmMWqbFnp118pVgAAZAeUKwDIQBs2SI89Jp0/L9WsaR5rVbKk1akAAIAjUK4AIIMsWyY9+aQUESE1bixt3CgVKmR1KgAA4CiUKwDIANOnm9Otx8RIzz8vrV0reXlZnQoAADgS5QoA0pFhSCNGSH36mMu9e0uLF0vu7lYnAwAAjsZsgQCQTuLipL59pZkzzesjRkjvvSfZbJbGAgAA6YRyBQDpICpKeukl6euvzTL16afSa69ZnQoAAKQnyhUAOFh4uPTMM9JPP0lubtKXX5rHWQEAgOyNcgUADnT2rDkj4O+/S3nySKtWmTMDAgCA7I9yBQAOcvSo1LSp9Pff0gMPSN9/L9WqZXUqAACQUShXAOAAe/dKzZtLoaFSiRLS+vVS2bJWpwIAABmJqdgB4D798ov0f/9nFqtq1aStWylWAADkRJQrALgPq1aZuwKGh0sNG0qbNkmFC1udCgAAWIFyBQBpNHeu1LatOe1669bSunVSvnxWpwIAAFahXAFAKhmGFBgode8uxcdLXbua57Py9LQ6GQAAsBLlCgBSIT5eGjhQeucd8/rQodKcOZIL0wMBAJDj8XUAAFIoOlp65RXpq6/M65MnS/37WxoJAABkIpQrAEiByEjp2WfN46pcXKQFC6SOHa1OBQAAMhPKFQDcw8WLUsuW0vbtUq5c0vLl5jmtAAAAbkW5AoC7OHFCatZMOnhQ8vGR1q6V6ta1OhUAAMiMKFcAcAf795vF6tQpqVgxc5fAihWtTgUAADIryhUAJGP/fvOkwJcumYVq3TqzYAEAANwJU7EDwG0MQ+rd2yxWdetKmzdTrAAAwL1RrgDgNitXSps2SR4e0rJlUoECVicCAABZAeUKAG4RFSUNHmwuv/mmVLy4tXkAAEDWQbkCgFtMnSr9849UuLA0ZIjVaQAAQFZCuQKA/5w7J334obkcGCjlyWNtHgAAkLVQrgDgP++/L4WHS7VqSZ06WZ0GAABkNZQrAJD0xx/S7Nnm8qRJkhOfjgAAIJX4+gAgxzMMadAgKT5eeu458/xWAAAAqUW5ApDjrVkjbdggublJ48ZZnQYAAGRVlCsAOVp0tPTGG+byoEFSyZLW5gEAAFkX5QpAjjZjhnT4sFSokDR0qNVpAABAVka5ApBjXbwojRhhLn/0keTlZWkcAACQxVGuAORYI0ZIV65I1atLr7xidRoAAJDVUa4A5EgHDpi7BErm1OvOztbmAQAAWR/lCkCO9MYbUlyc1KaN1KiR1WkAAEB2QLkCkOP88IP0/feSq6s0frzVaQAAQHZBuQKQo8TGmlOuS1K/flKZMtbmAQAA2QflCkCOMmuWebxVwYLSu+9anQYAAGQnlCsAOcbly9L775vLH3wg5ctnaRwAAJDNWF6upk+frpIlS8rDw0O1atXS5s2b77r9p59+qooVK8rT01Ply5fXwoUL7W5fsGCBbDZbksuNGzfS82UAyAI+/NA8t1XlylKPHlanAQAA2Y2LlU++dOlSDRgwQNOnT1eDBg00a9YstWjRQvv371fx4sWTbD9jxgwNHTpUn332merUqaMdO3aoR48eyp8/v1q1apW4nZeXlw4dOmR3Xw8Pj3R/PQAyr8OHpalTzeWJEyUXSz/9AABAdmQzDMOw6snr1q2rmjVrakbCyWYkVaxYUW3atFFgYGCS7evXr68GDRpo/C3Tew0YMEC7du3Sli1bJJkjVwMGDNCVK1fSnCs8PFze3t4KCwuTl5dXmh8HQObRurW0erXUsqX03XdWpwEAANmRZbsFRkdHa/fu3WratKnd+qZNm2rr1q3J3icqKirJCJSnp6d27NihmJiYxHURERHy9/dX0aJF9dRTT2nPnj13zRIVFaXw8HC7C4DsY8MGs1i5uEgff2x1GgAAkF1ZVq4uXLiguLg4+fr62q339fVVaGhosvdp1qyZ5syZo927d8swDO3atUvz5s1TTEyMLly4IEmqUKGCFixYoNWrV2vx4sXy8PBQgwYNdOTIkTtmCQwMlLe3d+KlWLFijnuhACwVF3dz6vXevaUKFazNAwAAsi/LJ7Sw2Wx21w3DSLIuwfDhw9WiRQvVq1dPrq6uat26tbp06SJJcnZ2liTVq1dPL730kqpXr66GDRtq2bJlKleunKYmHGyRjKFDhyosLCzxcvLkSce8OACWmztX+uMPKX/+mzMFAgAApAfLylXBggXl7OycZJTq3LlzSUazEnh6emrevHm6du2ajh07phMnTqhEiRLKmzevChYsmOx9nJycVKdOnbuOXLm7u8vLy8vuAiDrCwu7eS6rESMkHx9L4wAAgGzOsnLl5uamWrVqKSgoyG59UFCQ6tevf9f7urq6qmjRonJ2dtaSJUv01FNPyckp+ZdiGIaCg4NVuHBhh2UHkDWMHi2dPy+VLy+99prVaQAAQHZn6WTEgwYNUqdOnVS7dm0FBARo9uzZOnHihHr16iXJ3F3v9OnTieeyOnz4sHbs2KG6devq8uXLmjhxov788099/vnniY85cuRI1atXT2XLllV4eLg++eQTBQcH69NPP7XkNQKwxj//SJMnm8sTJ0qurpbGAQAAOYCl5ap9+/a6ePGiPvjgA4WEhKhKlSpau3at/P39JUkhISE6ceJE4vZxcXGaMGGCDh06JFdXVzVq1Ehbt25ViRIlEre5cuWKevbsqdDQUHl7e6tGjRr65Zdf9PDDD2f0ywNgobfekqKjpaZNpRYtrE4DAAByAkvPc5VZcZ4rIGvbtEl67DHJyUnat0+qXNnqRAAAICewfLZAAHCkuDhp4EBzuVcvihUAAMg4lCsA2crnn0t79kje3tLIkVanAQAAOQnlCkC2cfWqNGyYufzee9IdztAAAACQLihXALKNMWOk0FCpTBmpb1+r0wAAgJyGcgUgWzh+XJowwVz++GPJzc3aPAAAIOehXAHIFoYMkaKipMaNpaeftjoNAADIiShXALK8X3+Vli6VbDbzhME2m9WJAABATkS5ApClxcffnHq9e3epenVr8wAAgJyLcgUgS1u0SNq5U8qbV/rwQ6vTAACAnIxyBSDLioyU3n7bXB42TPL1tTYPAADI2ShXALKs8eOlM2ekkiWl/v2tTgMAAHI6yhWALOnUKWncOHN53DjJw8PaPAAAAJQrAFnS0KHS9etSw4bSs89anQYAAIByBSAL2r5d+vJLc8r1SZOYeh0AAGQOlCsAWYph3Jx6vXNnqVYta/MAAAAkoFwByFKWLpW2bZNy55Y++sjqNAAAADdRrgBkGdevS2+9ZS6//bZUpIi1eQAAAG5FuQKQZUyYIJ08KRUrJr3xhtVpAAAA7FGuAGQJZ85IY8aYy+PGSZ6e1uYBAAC4HeUKQJYwbJgUGSkFBEjt21udBgAAICnKFYBMb/du6fPPzWWmXgcAAJkV5QpAppYw9bphSB07SnXrWp0IAAAgeZQrAJna8uXS5s3mMVaBgVanAQAAuDPKFYBM68aNm1Ovv/WWOUsgAABAZkW5ApBpTZkiHT1qns9q8GCr0wAAANwd5QpApnT2rPTRR+bymDFS7tzW5gEAALgXyhWATGn4cOnqValOHXMiCwAAgMyOcgUg09m7V5ozx1yeNEly4pMKAABkAXxlAZCp3Dr1evv2UoMGVicCAABIGcoVgExl9Wpp40bJ3V0aO9bqNAAAAClHuQKQaURHS2++aS6/8Ybk729tHgAAgNSgXAHINKZNk/7+W/Lzk95+2+o0AAAAqUO5ApApnD8vffCBufzRR1LevNbmAQAASC3KFYBM4f33pbAwqUYNqXNnq9MAAACkHuUKgOUOHJBmzTKXJ02SnJ2tzQMAAJAWlCsAlps4UYqPl55+Wnr0UavTAAAApA3lCoClzp+XvvjCXB4yxNosAAAA94NyBcBSs2ZJUVFSnTpSQIDVaQAAANKOcgXAMtHR0qefmssDBkg2m6VxAAAA7gvlCoBlli2TQkOlIkWk556zOg0AAMD9oVwBsIRhmDMDSlLfvpKbm7V5AAAA7hflCoAltmyRfv9d8vCQeva0Og0AAMD9o1wBsMTkyebPl1+WChSwNAoAAIBDUK4AZLijR6WVK83l/v0tjQIAAOAwlCsAGW7qVPOkwc2aSZUqWZ0GAADAMShXADJUeLg0Z465PGCApVEAAAAcinIFIEMtWCBdvSpVqCA1bWp1GgAAAMehXAHIMHFx0iefmMv9+0tOfAIBAIBshK82ADLMd99J//wj5c9vzhIIAACQnVCuAGSYhOnXX31VypXL0igAAAAOR7kCkCGCg6Wff5acnaU+faxOAwAA4HiUKwAZYsoU8+fzz0tFi1qbBQAAID1QrgCku9BQ6auvzOWBA63NAgAAkF4oVwDS3cyZUnS0FBAgPfyw1WkAAADSB+UKQLq6cUOaMcNc5qTBAAAgO6NcAUhXS5ZI585JxYpJbdtanQYAACD9UK4ApBvDkCZNMpdff11ycbE2DwAAQHqiXAFINz//LO3bZ57Tqnt3q9MAAACkL8oVgHSTcNLgLl2k/PmtTAIAAJD+KFcA0sXff0vffmsu9+tnbRYAAICMQLkCkC4++cQ85qplS6l8eavTAAAApD/KFQCHu3JFmjfPXGb6dQAAkFNQrgA43Lx5UmSkVLmy9PjjVqcBAADIGJQrAA4VG2vuEiiZo1Y2m6VxAAAAMgzlCoBDrVolHT8uFSwodexodRoAAICMQ7kC4FAJ06/36iV5eloaBQAAIENRrgA4zK5d0pYtkqur9NprVqcBAADIWJQrAA4zZYr5s317qUgRa7MAAABkNMoVAIc4c0ZassRcZvp1AACQE1GuADjE9OnmTIENG0q1almdBgAAIONRrgDct+vXpZkzzWVGrQAAQE5FuQJw3xYtki5elEqUkFq3tjoNAACANShXAO6LYdycfv311yVnZ0vjAAAAWIZyBeC+bNgg/fWXlCeP1K2b1WkAAACsY3m5mj59ukqWLCkPDw/VqlVLmzdvvuv2n376qSpWrChPT0+VL19eCxcuTLLN8uXLValSJbm7u6tSpUr65ptv0is+kOMljFp17Sp5e1saBQAAwFKWlqulS5dqwIABGjZsmPbs2aOGDRuqRYsWOnHiRLLbz5gxQ0OHDtWIESP0119/aeTIkerTp4++/fbbxG22bdum9u3bq1OnTtq7d686deqkdu3aafv27Rn1soAc49Ahae1ayWYzdwkEAADIyWyGYRhWPXndunVVs2ZNzZgxI3FdxYoV1aZNGwUGBibZvn79+mrQoIHGjx+fuG7AgAHatWuXtmzZIklq3769wsPD9f333ydu07x5c+XPn1+LFy9OUa7w8HB5e3srLCxMXl5eaX15QLbXu7c0Y4b09NPSqlVWpwEAALCWZSNX0dHR2r17t5o2bWq3vmnTptq6dWuy94mKipKHh4fdOk9PT+3YsUMxMTGSzJGr2x+zWbNmd3zMhMcNDw+3uwC4u0uXpM8/N5cHDrQ2CwAAQGZgWbm6cOGC4uLi5Ovra7fe19dXoaGhyd6nWbNmmjNnjnbv3i3DMLRr1y7NmzdPMTExunDhgiQpNDQ0VY8pSYGBgfL29k68FCtW7D5fHZD9zZkjXbsmVa8uPfqo1WkAAACsZ/mEFjabze66YRhJ1iUYPny4WrRooXr16snV1VWtW7dWly5dJEnOt8z/nJrHlKShQ4cqLCws8XLy5Mk0vhogZ4iJkaZONZcHDDCPuQIAAMjpLCtXBQsWlLOzc5IRpXPnziUZeUrg6empefPm6dq1azp27JhOnDihEiVKKG/evCpYsKAkyc/PL1WPKUnu7u7y8vKyuwC4sxUrpFOnpEKFpBdesDoNAABA5mBZuXJzc1OtWrUUFBRktz4oKEj169e/631dXV1VtGhROTs7a8mSJXrqqafk5GS+lICAgCSPuX79+ns+JoCUS5h+vXdv6bbDIAEAAHIsFyuffNCgQerUqZNq166tgIAAzZ49WydOnFCvXr0kmbvrnT59OvFcVocPH9aOHTtUt25dXb58WRMnTtSff/6pzxOOqpfUv39//d///Z/Gjh2r1q1ba9WqVdqwYUPibIIA7s9vv5kXNzfpv3+qAAAAkMXlqn379rp48aI++OADhYSEqEqVKlq7dq38/f0lSSEhIXbnvIqLi9OECRN06NAhubq6qlGjRtq6datKlCiRuE39+vW1ZMkSvfvuuxo+fLhKly6tpUuXqm7duhn98oBsacoU82eHDtJd9rYFAADIcSw9z1VmxXmugOSdPCmVLCnFxUnBweZMgQAAADBZPlsggKzj00/NYtWoEcUKAADgdpQrACkSGSnNnm0uDxhgaRQAAIBMiXIFIEW++EK6fFkqXVpq2dLqNAAAAJkP5QrAPcXH35x+vV8/6ZZzdgMAAOA/lCsA97RunXTokOTlJb3yitVpAAAAMifKFYB7Shi16t5dypvX0igAAACZFuUKwF399Ze0fr3k5CT17Wt1GgAAgMyLcgXgrhJOGtymjXmOKwAAACSPcgXgji5cMGcJlKSBA63NAgAAkNlRrgDc0ezZ0o0bUq1aUoMGVqcBAADI3ChXAJIVHS19+qm5PGCAZLNZGgcAACDTo1wBSNb//iedOSMVLiy1a2d1GgAAgMyPcgUgCcO4Of16nz6Sm5ulcQAAALIEyhWAJLZulXbtkjw8pJ49rU4DAACQNVCuACSRMGr10kvSAw9YGgUAACDLoFwBsHPsmLRihbncv7+lUQAAALIUyhUAO9OmSfHxUpMmUpUqVqcBAADIOihXABJdvSrNmWMuDxhgaRQAAIAsh3IFINHnn0thYVK5clLz5lanAQAAyFooVwAkmbsCTpliLvfvLznx6QAAAJAqfH0CIElas0b6+28pXz7p5ZetTgMAAJD1UK4ASLo5/XrPnlKePJZGAQAAyJIoVwC0b5/000+Ss7PUp4/VaQAAALImyhWAxFGrZ5+Vihe3NAoAAECWRbkCcrhz56RFi8xlpl8HAABIO8oVkMPNnClFR0t160oBAVanAQAAyLooV0AOFhUlTZ9uLjNqBQAAcH8oV0AOtmSJdPas9OCD5vFWAAAASDvKFZBDGcbNiSz69pVcXS2NAwAAkOVRroAc6pdfpOBgydPTPLcVAAAA7g/lCsihEkatOneWfHwsjQIAAJAtUK6AHOiff6RVq8zlfv2szQIAAJBdUK6AHGjqVPOYq+bNpYoVrU4DAACQPVCugBzmyhVp3jxzeeBAS6MAAABkK5QrIId5913p6lWpcmWpSROr0wAAAGQflCsgB/ntt5snDZ4yRbLZrM0DAACQnVCugBwiJsacct0wpE6dpMcftzoRAABA9kK5AnKIiROlP/6QChSQJkywOg0AAED2Q7kCcoB//5VGjjSXJ0yQHnjA2jwAAADZUZrK1c8//+zgGADSi2FIr70mXb8uNW4svfyy1YkAAACypzSVq+bNm6t06dIaNWqUTp486ehMABxo8WJp/XrJ3V2aOZNJLAAAANJLmsrVmTNn1L9/f61YsUIlS5ZUs2bNtGzZMkVHRzs6H4D7cOmSNGCAufzuu1LZspbGAQAAyNZshmEY9/MAwcHBmjdvnhYvXqz4+Hh17NhR3bp1U/Xq1R2VMcOFh4fL29tbYWFh8vLysjoOkGbdupknDK5USdqzR3JzszoRAABA9nXf5UoyR7Jmz56tMWPGyMXFRTdu3FBAQIBmzpypypUrOyJnhqJcITvYtEl67DFzecsWqUEDS+MAAABke2meLTAmJkZff/21nnzySfn7+2vdunWaNm2azp49q6NHj6pYsWJ6/vnnHZkVQApFRUmvvmouv/oqxQoAACAjpGnk6vXXX9fixYslSS+99JK6d++uKlWq2G1z4sQJlShRQvHx8Y5JmoEYuUJWN2KEOfW6n5904ICUL5/ViQAAALI/l7Tcaf/+/Zo6daqeffZZud3hII4iRYpo48aN9xUOQOodPCgFBprLU6ZQrAAAADKKQ465ym4YuUJWFR8vNWok/fKL9OST0nffMfU6AABARknTMVeBgYGaN29ekvXz5s3T2LFj7zsUgLSZP98sVrlySZ9+SrECAADISGkqV7NmzVKFChWSrK9cubJmzpx536EApN7Zs9Kbb5rLH3wglShhaRwAAIAcJ03lKjQ0VIULF06y/oEHHlBISMh9hwKQegMHSleuSDVqSP37W50GAAAg50lTuSpWrJh+/fXXJOt//fVXFSlS5L5DAUidH36QFi+WnJykzz6TXNI0VQ0AAADuR5q+gnXv3l0DBgxQTEyMGjduLEn68ccf9dZbb+mNN95waEAAd3ftmtS7t7ncr59Uq5a1eQAAAHKqNJWrt956S5cuXVLv3r0VHR0tSfLw8NCQIUM0dOhQhwYEcHcjR0pHj0rFikkffmh1GgAAgJzrvqZij4iI0IEDB+Tp6amyZcvK3d3dkdksw1TsyCr27jVHquLipNWrpVatrE4EAACQc93XkRl58uRRnTp1HJUFQCrExUk9e5o/n32WYgUAAGC1NJernTt36n//+59OnDiRuGtgghUrVtx3MAB3N2OGtGOH5OUlffKJ1WkAAACQptkClyxZogYNGmj//v365ptvFBMTo/379+unn36St7e3ozMCuM2pU1LC4Y1jxkhM0gkAAGC9NJWr0aNHa9KkSfruu+/k5uamKVOm6MCBA2rXrp2KFy/u6IwAbvP661JEhBQQIL36qtVpAAAAIKWxXP3zzz9q2bKlJMnd3V2RkZGy2WwaOHCgZs+e7dCAAOytXGleXFyk2bPNc1sBAADAemn6Wubj46OrV69Kkh588EH9+eefkqQrV67o2rVrjksHwE54uNS3r7k8eLBUpYq1eQAAAHBTmia0aNiwoYKCglS1alW1a9dO/fv3108//aSgoCA9/vjjjs4I4D/vviudPi2VLi0NH251GgAAANwqTee5unTpkm7cuKEiRYooPj5eH3/8sbZs2aIyZcpo+PDhyp8/f3pkzTCc5wqZ0Y4dUr16kmFIQUHSE09YnQgAAAC3SnW5io2N1aJFi9SsWTP5+fmlVy5LUa6Q2cTESHXqmCcNfukl6YsvrE4EAACA26X6mCsXFxe99tprioqKSo88AJIxebJZrHx8pIkTrU4DAACA5KRpQou6detqz549js4CIBlHj0rvv28uT5ggPfCAtXkAAACQvDRNaNG7d2+98cYbOnXqlGrVqqXcuXPb3V6tWjWHhANyOsOQXntNun5datRI6tzZ6kQAAAC4kzRNaOGUzIl1bDabDMOQzWZTXFycQ8JZhWOukFksXix16CC5u0v79knlylmdCAAAAHeSppGro0ePOjoHgNtcuiQNGGAuDxtGsQIAAMjs0lSu/P39HZ0DwG2GDJHOnZMqVjSXAQAAkLmlqVwtXLjwrre//PLLaQoDwLR5szRnjrk8e7bk5mZtHgAAANxbmo65uv0kwTExMbp27Zrc3NyUK1cuXbp0yWEBrcAxV7BSVJT00EPSwYNSz57SrFlWJwIAAEBKpGkq9suXL9tdIiIidOjQIT3yyCNavHixozMCOcrYsWax8vWVxoyxOg0AAABSKk0jV3eya9cuvfTSSzp48KCjHtISjFzBKgcPStWrS9HR0pIlUvv2VicCAABASqVp5OpOnJ2ddebMmVTdZ/r06SpZsqQ8PDxUq1Ytbd68+a7bL1q0SNWrV1euXLlUuHBhvfLKK7p48WLi7QsWLJDNZktyuXHjRppeE5BRDEPq1cssVi1aSO3aWZ0IAAAAqZGmCS1Wr15td90wDIWEhGjatGlq0KBBih9n6dKlGjBggKZPn64GDRpo1qxZatGihfbv36/ixYsn2X7Lli16+eWXNWnSJLVq1UqnT59Wr1691L17d33zzTeJ23l5eenQoUN29/Xw8EjlqwQy1vz50qZNUq5c0vTpks1mdSIAAACkRprKVZs2beyu22w2PfDAA2rcuLEmTJiQ4seZOHGiunXrpu7du0uSJk+erHXr1mnGjBkKDAxMsv1vv/2mEiVKqF+/fpKkkiVL6tVXX9W4ceOS5PHz80vlqwKsc+6c9Oab5vLIkVKJEpbGAQAAQBqkabfA+Ph4u0tcXJxCQ0P11VdfqXDhwil6jOjoaO3evVtNmza1W9+0aVNt3bo12fvUr19fp06d0tq1a2UYhs6ePauvv/5aLVu2tNsuIiJC/v7+Klq0qJ566int2bPnrlmioqIUHh5udwEy0qBB0uXL5iyBCScOBgAAQNbi0GOuUuPChQuKi4uTr6+v3XpfX1+FhoYme5/69etr0aJFat++vdzc3OTn56d8+fJp6tSpidtUqFBBCxYs0OrVq7V48WJ5eHioQYMGOnLkyB2zBAYGytvbO/FSrFgxx7xIIAWCgqRFiyQnJ/OcVi5pGk8GAACA1dJUrp577jmNSWaO6PHjx+v5559P1WPZbjuwxDCMJOsS7N+/X/369dN7772n3bt364cfftDRo0fVq1evxG3q1aunl156SdWrV1fDhg21bNkylStXzq6A3W7o0KEKCwtLvJw8eTJVrwFIq2vXzEksJOn116U6dazNAwAAgLRL0+/IN23apPfffz/J+ubNm+vjjz9O0WMULFhQzs7OSUapzp07l2Q0K0FgYKAaNGigwYMHS5KqVaum3Llzq2HDhho1alSyuyQ6OTmpTp06dx25cnd3l7u7e4pyA4704YfSv/9KRYuaywAAAMi60jRyFRERITc3tyTrXV1dU3y8kpubm2rVqqWgoCC79UFBQapfv36y97l27ZqcnOwjOzs7SzJHvJJjGIaCg4NTfCwYkFH27ZPGjzeXP/1UypvX2jwAAAC4P2kqV1WqVNHSpUuTrF+yZIkqVaqU4scZNGiQ5syZo3nz5unAgQMaOHCgTpw4kbib39ChQ/Xyyy8nbt+qVSutWLFCM2bM0L///qtff/1V/fr108MPP6wiRYpIkkaOHKl169bp33//VXBwsLp166bg4GC7XQcBq8XFST17mj/btpWeftrqRAAAALhfadotcPjw4Xr22Wf1zz//qHHjxpKkH3/8UYsXL9b//ve/FD9O+/btdfHiRX3wwQcKCQlRlSpVtHbtWvn7+0uSQkJCdOLEicTtu3TpoqtXr2ratGl64403lC9fPjVu3Fhjx45N3ObKlSvq2bOnQkND5e3trRo1auiXX37Rww8/nJaXCqSLmTOl7dvN0apPPrE6DQAAABzBZtxpf7p7WLNmjUaPHq3g4GB5enqqWrVqev/99/Xoo486OmOGCw8Pl7e3t8LCwuTl5WV1HGQzp09LFStKV69K06ZJffpYnQgAAACOkOZylZ1RrpCenn1WWrFCqldP2rJF+u+wQQAAAGRxaTrmaufOndq+fXuS9du3b9euXbvuOxSQXa1ebRYrFxfznFYUKwAAgOwjTeWqT58+yZ4L6vTp0+rDPk5Asq5evbkL4JtvSlWrWpsHAAAAjpWmcrV//37VrFkzyfoaNWpo//799x0KyI6GD5dOnZJKlZLee8/qNAAAAHC0NJUrd3d3nT17Nsn6kJAQubikaQJCIFvbuVOaOtVcnjlT8vS0Ng8AAAAcL03lqkmTJho6dKjCwsIS1125ckXvvPOOmjRp4rBwQHYQG2ue0yo+XurYUeKfCAAAQPaUptkCT58+rf/7v//TxYsXVaNGDUlScHCwfH19FRQUpGLFijk8aEZitkA40scfS4MHSz4+0oEDUqFCVicCAABAekjzVOyRkZFatGiR9u7dm3ieqxdffFGurq6OzpjhKFdwlJAQqUwZ6do1ad486ZVXrE4EAACA9JLmA6Ry586tRx55RMWLF1d0dLQk6fvvv5ckPf30045JB2RxU6aYxapePalLF6vTAAAAID2lqVz9+++/euaZZ/THH3/IZrPJMAzZbLbE2+Pi4hwWEMiqwsKkGTPM5XfekW75JwIAAIBsKE0TWvTv318lS5bU2bNnlStXLv3555/atGmTateurZ9//tnBEYGsadYsKTxcqlRJatnS6jQAAABIb2kaudq2bZt++uknPfDAA3JycpKzs7MeeeQRBQYGql+/ftqzZ4+jcwJZSlSUNHmyuTx4sOSUpl9jAAAAICtJ01e+uLg45cmTR5JUsGBBnTlzRpLk7++vQ4cOOS4dkEV98YU5mUXRolKHDlanAQAAQEZI08hVlSpVtG/fPpUqVUp169bVuHHj5ObmptmzZ6tUqVKOzghkKXFx0vjx5vLAgZKbm7V5AAAAkDHSVK7effddRUZGSpJGjRqlp556Sg0bNlSBAgW0dOlShwYEsprVq6XDh6V8+aQePaxOAwAAgIyS5vNc3e7SpUvKnz+/3ayBWRXnuUJaGYYUECBt3y4NGyaNGmV1IgAAAGSUNJ/n6nY+Pj6Oeiggy/rlF7NYeXhI/fpZnQYAAAAZiTnMAAcaO9b8+corUqFC1mYBAABAxqJcAQ6yb5/0/ffmtOtvvGF1GgAAAGQ0yhXgIOPGmT+fe04qXdraLAAAAMh4lCvAAY4dk5YsMZeHDLE0CgAAACxCuQIcYOJE8/xWTzwh1axpdRoAAABYgXIF3KcLF6Q5c8xlRq0AAAByLsoVcJ+mTZOuXzdHrB5/3Oo0AAAAsArlCrgPkZFmuZLMUatscA5tAAAApBHlCrgP8+ZJFy+aswM++6zVaQAAAGAlyhWQRjEx0oQJ5vKbb0rOztbmAQAAgLUoV0AaLVsmHT8uFSokde5sdRoAAABYjXIFpIFh3DxpcP/+kqentXkAAABgPcoVkAY//CDt2yflySO99prVaQAAAJAZUK6ANBg71vzZs6eUP7+1WQAAAJA5UK6AVNq+Xdq0SXJ1lQYOtDoNAAAAMgvKFZBKCaNWHTtKRYtamwUAAACZB+UKSIVDh6SVK83lt96yNAoAAAAyGcoVkAoff2zOFPj001LFilanAQAAQGZCuQJSKCREWrjQXB4yxNosAAAAyHwoV0AKTZ4sRUdLjzwi1a9vdRoAAABkNpQrIAXCwqSZM81lRq0AAACQHMoVkAIzZ0rh4VKlStKTT1qdBgAAAJkR5Qq4hxs3zF0CJXOGQCf+1QAAACAZfE0E7uGLL6TQUPOcVi++aHUaAAAAZFaUK+Au4uKk8ePN5UGDJDc3a/MAAAAg86JcAXexcqV05IiUP7/Uo4fVaQAAAJCZUa6AOzAMaexYc7lPHylPHmvzAAAAIHOjXAF3sGmTtHOn5OEhvf661WkAAACQ2VGugDtIGLXq2lUqVMjaLAAAAMj8XKwOAGRGe/dKP/xgTrv+xhtWpwEAAMiGDEOKipIiI81LRIT589o1KSbGvMTG2v9M6TpHbh8bK506laKXRLkCkjFunPmzXTupVClrswAAAFgqPj5pAUr4ea9197o9Ls7qV+dQlCvgNseOSUuXmstvvWVpFAAAgPsXHy9dviydPWt/OXdOOn/eLDp3K0DXr6d/Rnd3KXducwaxXLkkV1fz4uJi/zO5dSm57X7vn0KUK+A2EyaYv0Rp0kSqUcPqNAAAAMmIjTWL0blzyZemW6+fP29uf79sNrP85M59swjdvpyWdblzmyUmG8gerwJwkPPnpblzzeUhQ6zNAgAAcpioqDsXpNvXXbxoHrOUGvnzS76+Ny+FCpmXvHlTVoo8PMyChTuiXAG3mDbNHPmuVUtq3NjqNAAAINu4ckXavFk6c+bOpSksLHWP6eQkFSxoX5gSStPt6x54QHJzS5eXhpsoV8B/IiPNciWZo1b8YgYAANyXf/+VVq+Wvv1W+uWXlO2a5+qafDlKbl2BApKzc/q/DqQY5Qr4z9y50qVLUpkyUtu2VqcBAABZTlyctH27WaZWr5b277e/vXx583K3wpQvH7/hzcIoV4DMUxhMmGAuv/kmvwQCAAApFBEhBQWZZWrNGvMA7gTOzlLDhtLTT0utWpm/wUW2RrkCZE69fuKE+Qujzp2tTgMAADK1U6ek774zC9VPP5kTUSTw9pZatDDLVIsW5iQSyDEoV8jxDOPmSYP79zcnwgEAh4uLY1gc2VdUlDlZQnbdnc0wpD17bh4/9fvv9reXLGmOTj39tDlSlYrzIiF7oVwhx/v+e+mPP8wZRnv1sjoNgGwlPFxauFCaMUM6eNA81uKhh+wvhQpZmxG4G8MwD0g+fdq8nDqVdPnUKfMEtXnzShUqSBUr2l9Klcqa5zC6cUPauPFmoTp9+uZtNptUr545OvX001KlStm3WCJVbIaR2gnys7/w8HB5e3srLCxMXl5eVsdBOnv0UXMCnzfekD7+2Oo0ALKF/fulTz81i1VExN23LVzYvmxVr24el5GTRrnCwqQjR6S//zaXXV3NL+O3/kxuXWq3yUnvaUrExkqhockXpluXb9y4v+dxc5PKlrUvXJUqSeXKSZ6ejnktjnLunHnc1LffSuvXm1MJJ8iVS2ra1CxTLVvyixEki3KVDMpVzvHbb1JAgPn/7tGj0oMPWp0IQJYVEyOtWmWWqp9/vrm+QgWpTx/z2IvDh6Xg4JuXI0eSPwlorlxStWr2patqVXN9VnXlilmeEkrUrT8vXMiYDDZb2sqah0fKTrB6p3W5c2f8bmKRkfcebTp7VoqPT9njFSxo/idZtKj589blokUlPz/z8Q4csL8cPGieQDI5Npu5O93tI10VK5oz5mUEwzB/GZIwu99vv9n/myxS5OboVOPGHDuAe6JcJYNylXM884y0cqX0yivSvHlWpwGQJYWGSp99Js2caZ4cVDJP7Nm6tdS3r9So0Z13F4qMNPdLvrVw7duX/JdRJyfzN/23j3L5+aXHq0qbK1eSL09//33vAuXnZ47YFSxojqjExCT9mdy6O90WF5chLznF3NzSVszuVNbCwu5enq5cSVkuFxdz9PTWonR7eSpSJO2lIj7enDHq9tK1f7+5K+Gd+PklX7oKF77/3e9iYsyT+Sbs7vfvv/a316hxc3a/mjXZ3Q+pQrlKBuUqZzh40NwrIeGXVhUrWp0IQJZhGNKvv5qjVMuXm1/WJHM3oR49pFdflYoVS9tjx8WZheTWwhUcbI4KJMfXN+lxXGXLpt8ucJcv33kE6uLFu9/Xz8/MVqaM/c/Spc3jdRwpPt58L9Nazm79ef26WYQjI83dPG/9ebd1ERHWlrzcue9emooWNf/OOjllfDbDMHfBu710HThgf2zT7by9kz+uq2TJu/+dv3xZ+uEHs1B9/71ZThO4uUmPP26WqaeeSvu/XUCUq2RRrnKGbt3M0arWrc3RKwC4p8hI6auvzFK1d+/N9QEB5ijVs89K7u7p89yhoeZz3lq4Dh1KfrdCT8/kdyvMnTtlz3X58p1HoO5VoAoXTlqeypQxL3nypOYVZ32GIUVHp7yMpWZdnjxJi9Lt5cnLK2uOuoSHm78Bvb10/fPPnXdjdHc3R3ZvLVz+/tK2bebo1C+/2BfdBx4wj5t6+mmpSZOc93cT6YZylQzKVfZ35oxUooT5C8mtW83vRQBwR0eOSNOnS/Pn3/yNt6en1KGDeTxVjRrW5IqMlP7882bZ2rvXvFy7lnRbm80sOrcWLh8fszDdXqIuXbr78xYufOcRKL6kIr3cuGH+/by9dB06ZH+eqTupVOnm7n516zLBCdIF5SoZlKvs7623pPHjzVNR/PKL1WkAZEpxcdLateYo1bp1N9eXLi317m0erJkZTw4aF2f+hv/23QpDQlL3OEWK3HkEKqUjYEBGiIuTjh1LWrr+/VeqXPlmoSpd2uqkyAEoV8mgXGVvV65IxYtLV6+aJ1dv2dLqRAAylQsXpLlzzQkqjh0z19ls0pNPmqNUzZpZc4zK/Tp79uZuhXv3midEDQ+/WZhuH4GiQAFAqmXBM7oB92fmTLNYValiflcCAEnSzp3mKNWSJTd3MfLxMQ/Q7NXLPBFqVubra56jp2lTq5MAQLZFuUKOcuOGNHmyuTx4cNY8zheAA924IS1dapaqnTtvrq9VyxyleuGFzHeSUwBApkW5Qo6ycKG5Z0yxYtKLL1qdBoBljh0zh7HnzLk5+52bm9S+vVmqHn6Y374AAFKNcoUcIy7OnMRCkgYNklxdrc0DIIPFx0sbNkjTppkHXCYccly8uLnbX/fu5vTMAACkEeUKOcY335izDOfPb36HApBDXLkiLVhgTqV+5MjN9U2amKNUTz3FlMwAAIegXCFHMAxp7FhzuW9fTsMC5Ah795rHUi1adPO8T15eUpcu5lTq5ctbGg8AkP1QrpAjbNwo7dplHpf++utWpwFwV/Hx5kQT16/f+XLt2t1v//136ddfbz5m1armKFXHjvx2BQCQbihXyBHGjTN/du3KIRWAQ4WHS9u2SRERKS8+97r9xg3HZHNxkdq2NYerH3mECSoAAOnO8nI1ffp0jR8/XiEhIapcubImT56shg0b3nH7RYsWady4cTpy5Ii8vb3VvHlzffzxxypQoEDiNsuXL9fw4cP1zz//qHTp0vroo4/0zDPPZMTLQSYUHCytW2ceUvHGG1anAbKBuDhzOHjBAmnFCrMQpRdXV3PI+U6XXLmSX//AA1K7dlLhwumXDQCA21harpYuXaoBAwZo+vTpatCggWbNmqUWLVpo//79Kl68eJLtt2zZopdfflmTJk1Sq1atdPr0afXq1Uvdu3fXN998I0natm2b2rdvrw8//FDPPPOMvvnmG7Vr105btmxR3bp1M/olIhNIGLVq104qWdLaLECWduSI9Pnn5jkNTp68ub5UKalIkZQXn5Te7ulpjj4BAJBF2AwjYS7ajFe3bl3VrFlTM2bMSFxXsWJFtWnTRoGBgUm2//jjjzVjxgz9888/ieumTp2qcePG6eR//9G3b99e4eHh+v777xO3ad68ufLnz6/FixenKFd4eLi8vb0VFhYmLy+vtL48ZAJHj0plypiHcPz+u1SjhtWJgCwmLExatswcpdq69eb6fPnMk8V17sw5oQAA+I+TVU8cHR2t3bt3q2nTpnbrmzZtqq23/gd+i/r16+vUqVNau3atDMPQ2bNn9fXXX6tly5aJ22zbti3JYzZr1uyOjylJUVFRCg8Pt7sge5gwwSxWTZtSrIAUi4uT1q83J3/w85N69jSLlZOT1KKFtHSpFBJiTm1ety7FCgCA/1i2v8WFCxcUFxcnX19fu/W+vr4KDQ1N9j7169fXokWL1L59e924cUOxsbF6+umnNXXq1MRtQkNDU/WYkhQYGKiRI0fex6tBZnT+vDRvnrk8ZIi1WYAs4dChm7v9nT59c32lSub05R07mrv/AQCAZFk2cpXAdttvPA3DSLIuwf79+9WvXz+999572r17t3744QcdPXpUvXr1SvNjStLQoUMVFhaWeDl567EEyLKmTjWPs69dW2rUyOo0QCZ15Yo0a5YUECBVqCAFBprFKn9+81xQO3ZIf/4pDR5MsQIA4B4sG7kqWLCgnJ2dk4wonTt3LsnIU4LAwEA1aNBAgwcPliRVq1ZNuXPnVsOGDTVq1CgVLlxYfn5+qXpMSXJ3d5e7u/t9viJkJhER0rRp5vKQIey1BNiJi5M2bDCPo/rmGykqylzv7Cw1b26OUrVqJfG5CABAqlg2cuXm5qZatWopKCjIbn1QUJDq16+f7H2uXbsmJyf7yM7OzpLM0SlJCggISPKY69evv+NjInuaM0e6fFkqW1ZiFn7gPwcOSG+/LRUvbpaoJUvMYlW5sjR+vDkD4HffSc89R7ECACANLJ3jdtCgQerUqZNq166tgIAAzZ49WydOnEjczW/o0KE6ffq0Fi5cKElq1aqVevTooRkzZqhZs2YKCQnRgAED9PDDD6vIf7ur9O/fX//3f/+nsWPHqnXr1lq1apU2bNigLVu2WPY6kbFiYqSJE83lN980fxkP5FiXL5sTUCxYIG3ffnO9j4/UoYM5SlWzJsO7AAA4gKXlqn379rp48aI++OADhYSEqEqVKlq7dq38/f0lSSEhITpx4kTi9l26dNHVq1c1bdo0vfHGG8qXL58aN26ssWPHJm5Tv359LVmyRO+++66GDx+u0qVLa+nSpZzjKgdZssT8Bbyvr/Tyy1anASwQGysFBZmFatUq+93+nnzSnD79qacYnQIAwMEsPc9VZsV5rrIuw5CqVTOPvw8MNPeAAtIkPl66eNE8kW3u3FljZGf/fnO2vy++MKdKT1ClivTKK+Zsf3c5/hQAANwfS0euAEdbu9YsVnnzSrdNIgkkde2aeabpf/81L//8c3P56FHpxg1zOzc3cze6hEuBAvbXk1tXoEDGlLJLl8zh2gULpJ07b64vUMAsU507myd5ywrlEACALI5yhWzDMKSEPURffVXKl8/SOMgMDEMKDU1anBKu3+X8d3aio81tU7p9AlfXu5evO13Pk+fuZSg21jzJb8Juf9HR5noXF3O3vy5dpJYtzVIIAAAyDOUK2cbixdLmzeb3yQEDrE6DDHP9uv3o061F6uhR8/a78fKSSpc2L6VK2V+KFzeLy6VL5i6Cly7dvNzt+sWL5v1iYqSzZ81Lari43LmARUdLX39tX/SqVTN3++vQQSpUKPXvIQAAcAjKFbKFs2el1183l999V3rwQWvzwIEMw/wDTm7XvX//lc6cufv9nZzMknRrabq1SOXPf/dRIldXc/e+YsVSl/naNfvyldKCFhVljkydO2de7qRgQXO3vy5dpIceSnk2AACQbihXyPIMQ+rd2/xu+tBDTGKRJRmGWZoOH05anv791ywqd5M3751Hn/z9zYKUkWw2s5ClpZRdv37n8nXpkvlePPGE1KIFu/0BAJDJUK6Q5f3vf9KKFeaeVAsWZPz3aKTR5cvShg3msUPr1pnz59+Jk5NZUu40+uTjkz0mbLDZpFy5zEvRolanAQAAqUS5QpZ2/rzUp4+5/M47UvXq1ubBXcTGSjt2mEVq/XpzOT7+5u3u7lKFCklHn0qXNnfrY5QGAABkcpQrZGmvvy5duCBVrSoNG2Z1GiRx/LhZptatk378UQoLs7+9UiWpWTOpaVPp//7PHLEBAADIoihXyLJWrJCWLpWcnc3dARnYyAQiI6Wff75ZqA4ftr89f36pSROzTDVtmrrjkQAAADI5yhWypIsXpddeM5fffluqWdPaPDlWfLy0b9/NMrVlizn9eAJnZ6lePbNINWsm1a5trgMAAMiGKFfIkvr1M2eprlxZGj7c6jQ5zNmzUlCQWaaCgpKew6lEiZu7+jVuzNmcAQBAjkG5QpazerX01VfmBHLz55vzICAdRUVJW7feHJ0KDra/PXduqVGjm6NTZctmj5n7AAAAUolyhSzl0iXp1VfN5cGDpTp1rM2TLRmGdOTIzTL188/msVS3qlHj5uhU/fo0XAAAAFGukMUMHCiFhpozdo8YYXWabOTKFemnn24WquPH7W/39b05CUWTJuZ1AAAA2KFcIctYs0ZauNDc42zePMnDw+pEWVhcnLRz580T+G7fbq5L4OYmPfLIzdGpatXM/TABAABwR5QrZAlXrtzcHXDQICkgwNI4WUdEhDkd+uHD0qFDNy+HD5u33ap8+Ztl6rHHzGOpAAAAkGKUK2QJb7whnT5tzpXw4YdWp8lk4uLM3fhuL0+HDplv2p14e0tPPHGzUPn7Z1xmAACAbIhyhUxv3TpzN8CE3QE9Pa1OZJGLF+2LU8Ll77+l6Og7369gQXNU6tZLuXJmU3XhIwAAAMBR+GaFTC08XOre3Vzu1888DChbi4qS/vkn6QjUoUNmuboTd3ezLCUUp1tLlI9PxuUHAADIwShXyNQGD5ZOnZJKlZI++sjqNA5iGFJIiP3oU0KROnpUio+/832LFk06AlW+vFS8uOTsnHGvAQAAAElQrpBpbdggzZ5tLs+dm0XnVzAMKShI2rbt7pNJ3Cpv3qQjUOXLmyNTWfJNAAAAyBkoV8iUrl69uTtgnz7m5HVZztGjZvjvv096m7OzVLJk8qNQfn7mAWYAAADIUihXyJTeftucAK9ECWnMGKvTpFJMjDRxojRypHT9unnOqBdekCpXvlmkSpUy1wMAACDboFwh0/n5Z2n6dHN5zhwpTx5L46TOtm1Sz57Sn3+a1x97TJo50yxUAAAAyNacrA4A3CoyUurWzVx+9VXp8cetzZNily9LvXpJ9eubxapAAWnBAumnnyhWAAAAOQQjV8hU3nlH+vdfqVgxadw4q9OkgGFIS5ZIAwdKZ8+a6155xQxfsKC12QAAAJChKFfINDZvlqZONZc/+0zy8rI2zz3984/Uu7e0fr15vXx5cxfALDn7BgAAAO4XuwUiU7h2Tera1RwI6tZNatbM6kR3ER0tjR4tValiFit3d+mDD6S9eylWAAAAORgjV8gUhg+X/v5bevBBacIEq9PcxZYt5sFg+/eb1xs3lmbMMKdRBwAAQI7GyBUst3WrNGmSuTx7tuTtbW2eZF26JPXoITVsaBarggWlL74wz3RMsQIAAIAYuYLFrl+/uTtg587Sk09aneg2hiF99ZU5YcX58+a67t2lsWMlHx9rswEAACBToVzBUiNGSIcOSYUL3xy9yjSOHDEnrNiwwbxesaI0a5Y5egUAAADcht0CYZnt26WPPzaXZ82S8ue3Nk+iqChp1CipalWzWHl4SB99JAUHU6wAAABwR4xcwRJRUebugPHxUseOUqtWVif6zy+/mBNWHDxoXm/SRJo+XSpTxtpcAAAAyPQYuYIlPvjAnBfC11eaMsXqNJIuXjTngH/0UbNYFSpkHmu1bh3FCgAAAClCuUKG273bnA9CMmcxL1DAwjCGIS1cKFWoIM2bZ67r2dMsWC++KNlsFoYDAABAVsJugchQ0dFSly5SXJzUvr30zDMWhjl8WOrVS9q40bxeubJ58FeDBhaGAgAAQFbFyBUy1KhR0p9/Sg88IE2dalGIqChp5EhzwoqNGyVPTykwUPr9d4oVAAAA0oyRK2SY4GCzw0jSp5+aBSvD/fyzOWHF4cPm9WbNzAkrSpWyIAwAAACyE0aukCFiYszdAWNjpWeflZ5/PoMDXLhgBmjUyCxWfn7SkiXS999TrAAAAOAQlCtkiMBAae9ec/KKTz/NwCc2DGn+fHPCis8/NyeoeO016cAB86AvJqwAAACAg7BbINLdH3+Yx1pJ5nFWvr4Z9MQHD5oTVmzaZF6vVs2csKJevQwKAAAAgJyEkSukq4TdAWNipNatpRdeyIAnvXFDeu89s0xt2mROWDFunLRrF8UKAAAA6YaRK6Sr8ePNSfjy5zfPaZXue+Ft3GhOWHHkiHn9ySfN/RBLlEjnJwYAAEBOx8gV0s1ff5kznkvSlClS4cLp+GTx8dKHH0qPP24Wq8KFpf/9T/ruO4oVAAAAMgQjV0gXsbFS167mSYNbtpReeikdnywsTHr5ZWn1avN6t27ShAmSt3c6PikAAABgj3KFdDFxorRjh9lvZs1Kx90BDxyQ2rQxp1d3czP3PezaNZ2eDAAAALgzyhUc7uBBcz4JSZo0SXrwwXR6ohUrpM6dpYgIqWhRafly6eGH0+nJAAAAgLvjmCs4VFyc9MorUlSU1KyZOVNgujzJO++YZyOOiJAefVTavZtiBQAAAEsxcgWHmjJF+u03KW9e6bPP0mF3wEuXpA4dpHXrzOsDBpjTrLu6OviJAAAAgNShXMFhjhyRhg0zlydMkIoVc/AT7N0rPfOMdPSoee6qOXPMogUAAABkAuwWCIeIjzfnkbhxQ3riCal7dwc/wVdfSQEBZrEqWVLato1iBQAAgEyFcgWHmDZN2rJFypPHwbsDxsRIAwdKHTtK16+bB3Lt2iVVr+6gJwAAAAAcg3KF+/bPP9LQoebyuHEOPGfvuXNSkybS5Mnm9XfekdaskXx8HPQEAAAAgONwzBXuS3y8ec7ea9ekxx6TXn3VQQ+8Y4c5G+CpU+Zw2MKF5vFWAAAAQCbFyBXuy8yZ0qZNUq5c0ty5kpMj/kbNnSs1bGgWq/LlzaJFsQIAAEAmR7lCmh09Kr31lrk8ZoxUqtR9PmBUlNSrlzkbRnS01Lq1WawqVrzvrAAAAEB6o1whzXr1kiIjzUGmPn3u88FOnzb3K5w1y5wN48MPpRUrJC8vR0QFAAAA0h3HXCFNdu6U1q83z91737sDbtkiPfecdPaslC+ftGiR9OSTjooKAAAAZAhGrpAmU6aYP9u3l8qWTeODGIY5h3ujRmaxqlrVbG0UKwAAAGRBlCukWkiItGyZuTxgQBof5Pp1qUsX6fXXpdhYs6Vt2yaVKeOglAAAAEDGYrdApNqMGea5fRs0kGrVSsMDHD8utW0r/f67uT/huHHSoEEOPPMwAAAAkPEoV0iVGzfM6dclqX//NDzAhg3SCy9IFy9KBQtKS5dKjRs7NCMAAABgBXYLRKosXiydPy8VK5bKU08ZhjR+vNSsmVmsatWSdu+mWAEAACDboFwhxQzj5kQWffpILikd94yIMEer3npLio83j7XavFkqXjy9ogIAAAAZjt0CkWK//CLt3St5eko9eqTwTn//bQ5x/fmnOW/7lCnmCbI4vgoAAADZDOUKKZYwavXyy5KPTwrusGaN1LGjFBYm+flJX39tzoIBAAAAZEPsFogUOXpUWrnSXO7X7x4bx8dLH3wgtWplFqv69c3jqyhWAAAAyMYYuUKKTJtmHnPVpIlUqdJdNgwLM4e2Vq82r7/2mjR5suTmlhExAQAAAMtQrnBPERHS3Lnm8l1PGrx/v3l81eHDkru7eUKsV17JiIgAAACA5ShXuKfPPzcHpMqVk5o3v8NGy5ebswBGRJjztK9YIdWunZExAQAAAEtxzBXuKj7+5kQWr78uOd3+NyYuTho6VHruObNYNWpkHl9FsQIAAEAOw8gV7uqHH6QjRyQvL6lz59tuvHhR6tBBWr/evP7GG9KYMak4ARYAAACQffAtGHeVMGrVvbuUN+8tN8TEmKNUf/wh5cplHpT1wguWZAQAAAAyA8t3C5w+fbpKliwpDw8P1apVS5s3b77jtl26dJHNZktyqVy5cuI2CxYsSHabGzduZMTLyVYOHDAHpZycpL59b7tx7lyzWBUsKG3bRrECAABAjmdpuVq6dKkGDBigYcOGac+ePWrYsKFatGihEydOJLv9lClTFBISkng5efKkfHx89Pzzz9tt5+XlZbddSEiIPDw8MuIlZSuffGL+fPppqWTJW26IjJRGjjSX339fqlYtw7MBAAAAmY2luwVOnDhR3bp1U/fu3SVJkydP1rp16zRjxgwFBgYm2d7b21ve3t6J11euXKnLly/rldum+7bZbPLz80txjqioKEVFRSVeDw8PT+1LyXYuXTJnCZSk/v1vu3HyZCk0VCpVSurZM6OjAQAAAJmSZSNX0dHR2r17t5o2bWq3vmnTptq6dWuKHmPu3Ll64okn5O/vb7c+IiJC/v7+Klq0qJ566int2bPnro8TGBiYWNy8vb1VrFix1L2YbGjOHOn6dal6denRR2+54cIFaexYc3nUKE4ODAAAAPzHsnJ14cIFxcXFydfX1269r6+vQkND73n/kJAQff/994mjXgkqVKigBQsWaPXq1Vq8eLE8PDzUoEEDHTly5I6PNXToUIWFhSVeTp48mbYXlU3ExkrTppnL/ftLNtstN44eLV29KtWoIbVvb0k+AAAAIDOyfLZAm903d8kwjCTrkrNgwQLly5dPbdq0sVtfr1491atXL/F6gwYNVLNmTU2dOlWfJBxEdBt3d3e5u7unPnw2tXKldPKk9MAD0osv3nLD8ePSp5+ay2PGJHPSKwAAACDnsuzbccGCBeXs7JxklOrcuXNJRrNuZxiG5s2bp06dOsntHrulOTk5qU6dOncduYK9yZPNn6++KtnNA/Lee1J0tNS4sdSkiRXRAAAAgEzLsnLl5uamWrVqKSgoyG59UFCQ6tevf9f7btq0SX///be6det2z+cxDEPBwcEqXLjwfeXNKXbvln791TwP8Guv3XLDvn3SF1+Yy2PG3LavIAAAAABLdwscNGiQOnXqpNq1aysgIECzZ8/WiRMn1KtXL0nmsVCnT5/WwoUL7e43d+5c1a1bV1WqVEnymCNHjlS9evVUtmxZhYeH65NPPlFwcLA+TdidDXeVcNLg9u2lIkVuueGddyTDkJ5/XqpTx5JsAAAAQGZmablq3769Ll68qA8++EAhISGqUqWK1q5dmzj7X0hISJJzXoWFhWn58uWaktACbnPlyhX17NlToaGh8vb2Vo0aNfTLL7/o4YcfTvfXk9WFhkpLlpjLdtOv//KLtGaN5OwsffSRJdkAAACAzM5mGIZhdYjMJjw8XN7e3goLC5OXl5fVcTLM++9LH3wgBQRIibPhG4ZUv770229Sr17SjBmWZgQAAAAyK6Z7gyQpKkqaOdNcthu1WrnSLFa5cpkTWgAAAABIFuUKkszdAc+dk4oWldq2/W9lbKx5rJUkDRwoMSkIAAAAcEeUK8gwbk5k0aeP5Or63w0LFkgHD0oFCkiDB1sVDwAAAMgSKFfQ5s3Snj2Sp6fUo8d/K69dk0aMMJeHDZO8va2KBwAAAGQJlCskjlq99JI5SCVJmjpVOn1a8veXeve2LBsAAACQVVCucrhjx8w5K6RbJrK4fNk8UbBkTh/o7m5BMgAAACBroVzlcJ9+KsXHS088IVWu/N/KMWOkK1ekqlWljh2tjAcAAABkGZSrHCwiQpozx1xOHLU6dUr65BNzOTDQPHEwAAAAgHuiXOVgCxeaA1RlykhPPvnfyhEjpBs3pP/7v1tWAgAAALgXylUOFR9/c4CqXz/JyUnS/v3S/PnmyrFjJZvNsnwAAABAVkO5yqHWr5cOHZK8vKQuXf5bOWyY2bratJHq1bMwHQAAAJD1UK5yqITp17t2lfLmlbR1qzltoJOTNHq0ldEAAACALIlylQMdPCj98IO519/rr0syDOntt80bX3lFqljR0nwAAABAVkS5yoESjrVq1UoqVUrSmjXS5s2Sh4c5oQUAAACAVKNc5TCXL0uff24uDxggKS5OGjrUXNGvn1S0qFXRAAAAgCyNcpXDzJ0rXbsmVasmPfaYpC+/lP78U8qX7+augQAAAABSjXKVg8TGSlOnmsv9+km2qBvSe++ZK4YOlfLnty4cAAAAkMVRrnKQVaukEyekAgWkDh0kTZ9urnjwwf9mtgAAAACQVpSrHCRh+vVevSTP6DDpo4/MFSNHSp6e1gUDAAAAsgHKVQ7x++/mhIAuLlLv3pLGjZMuXTKnXe/c2ep4AAAAQJZHucohEkatnn9eKmILkSZNMleMHm02LgAAAAD3hXKVA5w9Ky1ZYi737y9zN8Dr16WAAKl1a0uzAQAAANkF5SoHmDlTio6W6tWT6uY/LM2ZY94wdqxks1kbDgAAAMgmKFfZXFSUNGOGudy/v6Rhw8wTBz/1lNSwoaXZAAAAgOyEcpXNLVtm7hb44IPSc8V3SF9/bY5WjR5tdTQAAAAgW6FcZWOGIU2ebC73fs2Qy7tvm1deflmqWtWyXAAAAEB2RLnKxn791ZyC3cND6lN2vbRxo+TmZk5oAQAAAMChKFfZWML06506xst79BDzSt++kr+/daEAAACAbIpylU0dPy6tWGEuv1tmibR3r+TlJb3zjrXBAAAAgGyKcpVNffqpFB8vNX0sWsVnv2uuHDJEKlDA2mAAAABANkW5yoYiI6XPPjOXPy47Szp6VPLz+28udgAAAADpgXKVDX3xhXTlilSt5FVVWfmhuXLECCl3bitjAQAAANka5SqbiY+/OZHFrHITZDt/XipbVura1dpgAAAAQDZHucpmgoKkgwelUrnPqu6vE8yVo0dLrq7WBgMAAACyOcpVNpMwajW/9CjZIiKkOnWkZ5+1NhQAAACQA1CuspFDh6Tvv5dK6x81PDDLXDl2rGSzWRsMAAAAyAEoV9nI1Knmz7kPDpctJkZq1kxq1MjaUAAAAEAOYTMMw7A6RGYTHh4ub29vhYWFycvLy+o4KXLlilS0qFQ2co/2qKa5cs8e6aGHrIwFAAAA5BiMXGUTc+ea57ealudtc0WHDhQrAAAAIAMxcpWMrDZyFRcnlSkjlTr2o37UE+bMgAcPSqVKWR0NAAAAyDFcrA6A+7d6tXTsmKEVzm9LcZJ69aJYAQAAABmM3QKzgSlTpOf0tWrE7ZLy5JHefdfqSAAAAECOw8hVFhccLP26KUb79Y654s03pUKFLM0EAAAA5ESMXGVxU6ZI3TRXZfW3WaoGDbI6EgAAAJAjMXKVhZ07J61cFKn9GmmuGD5cypvX2lAAAABADsXIVRY2a5bUO2ayCivUnMCiZ0+rIwEAAAA5FiNXWVR0tLRk2gVt01hzxahRkpubtaEAAACAHIyRqyxq2TKp27nR8tJVxT9UQ2rf3upIAAAAQI7GyFUWZBjS0nHH9bU+lSQ5jR0jOdGTAQAAACvxjTwL2rZNeu6P9+SuaEU3fFxq0sTqSAAAAECOR7nKglaM2KdO+kKS5DZxjGSzWZwIAAAAAOUqizl5UmoU9I6cZOhK03ZS7dpWRwIAAAAgylWWs/btX9RSaxRrc1G+aaOsjgMAAADgP5SrLORapKGaS4dIkk426yGVLWtxIgAAAAAJKFdZyObBq1Qn7jdds+VS8TnvWR0HAAAAwC0oV1mEEROrMnOHSpL2PTFIzg/6WZwIAAAAwK0oV1nE/iGfq3T0QV1UAVWcO9jqOAAAAABuQ7nKCq5fl++M9yVJmx4ZJu9iXhYHAgAAAHA7ylUWcDXCpplu/bVHD6nazN5WxwEAAACQDJthGIbVITKb8PBweXt7KywsTF5emWOUKDpa2rLZUOPHOWEwAAAAkBkxcpVFuLmJYgUAAABkYpQrAAAAAHAAyhUAAAAAOADlCgAAAAAcgHIFAAAAAA5AuQIAAAAAB6BcAQAAAIADUK4AAAAAwAEoVwAAAADgAJQrAAAAAHAAyhUAAAAAOADlCgAAAAAcgHIFAAAAAA5gebmaPn26SpYsKQ8PD9WqVUubN2++47ZdunSRzWZLcqlcubLddsuXL1elSpXk7u6uSpUq6ZtvvknvlwEAAAAgh7O0XC1dulQDBgzQsGHDtGfPHjVs2FAtWrTQiRMnkt1+ypQpCgkJSbycPHlSPj4+ev755xO32bZtm9q3b69OnTpp79696tSpk9q1a6ft27dn1MsCAAAAkAPZDMMwrHryunXrqmbNmpoxY0biuooVK6pNmzYKDAy85/1Xrlyptm3b6ujRo/L395cktW/fXuHh4fr+++8Tt2vevLny58+vxYsXpyhXeHi4vL29FRYWJi8vr1S+KgAAAAA5kWUjV9HR0dq9e7eaNm1qt75p06baunVrih5j7ty5euKJJxKLlWSOXN3+mM2aNbvrY0ZFRSk8PNzuAgAAAACpYVm5unDhguLi4uTr62u33tfXV6Ghofe8f0hIiL7//nt1797dbn1oaGiqHzMwMFDe3t6Jl2LFiqXilQAAAABAJpjQwmaz2V03DCPJuuQsWLBA+fLlU5s2be77MYcOHaqwsLDEy8mTJ1MWHgAAAAD+42LVExcsWFDOzs5JRpTOnTuXZOTpdoZhaN68eerUqZPc3NzsbvPz80v1Y7q7u8vd3T2VrwAAAAAAbrJs5MrNzU21atVSUFCQ3fqgoCDVr1//rvfdtGmT/v77b3Xr1i3JbQEBAUkec/369fd8TAAAAAC4H5aNXEnSoEGD1KlTJ9WuXVsBAQGaPXu2Tpw4oV69ekkyd9c7ffq0Fi5caHe/uXPnqm7duqpSpUqSx+zfv7/+7//+T2PHjlXr1q21atUqbdiwQVu2bMmQ1wQAAAAgZ7K0XLVv314XL17UBx98oJCQEFWpUkVr165NnP0vJCQkyTmvwsLCtHz5ck2ZMiXZx6xfv76WLFmid999V8OHD1fp0qW1dOlS1a1bN8W5EmanZ9ZAAAAAAJKUN2/ee84NYel5rjKrf//9V6VLl7Y6BgAAAIBMIiXnwLV05Cqz8vHxkSSdOHFC3t7eFqcxhYeHq1ixYjp58mSmObExmVKGTClDppTJbJkyWx6JTClFppQhU8qQKWUyW6bMlkfKnJkS5M2b957bUK6S4eRkzvPh7e2d6f5Qvby8yJQCZEoZMqUMme4ts+WRyJRSZEoZMqUMmVIms2XKbHmkzJkpJSw/zxUAAAAAZAeUKwAAAABwAMpVMtzd3fX+++9nqhMLkyllyJQyZEoZMt1bZssjkSmlyJQyZEoZMqVMZsuU2fJImTNTajBbIAAAAAA4ACNXAAAAAOAAlCsAAAAAcADKFQAAAAA4AOUKAAAAAByAcpWM6dOnq2TJkvLw8FCtWrW0efNmy7L88ssvatWqlYoUKSKbzaaVK1daliVBYGCg6tSpo7x586pQoUJq06aNDh06ZGmmGTNmqFq1aoknnAsICND3339vaaZbBQYGymazacCAAZZlGDFihGw2m93Fz8/PsjwJTp8+rZdeekkFChRQrly59NBDD2n37t2W5SlRokSS98lms6lPnz6WZYqNjdW7776rkiVLytPTU6VKldIHH3yg+Ph4yzJJ0tWrVzVgwAD5+/vL09NT9evX186dOzPs+e/1+WgYhkaMGKEiRYrI09NTjz32mP766y9LM61YsULNmjVTwYIFZbPZFBwcnK557pUpJiZGQ4YMUdWqVZU7d24VKVJEL7/8ss6cOWNZJsn8vKpQoYJy586t/Pnz64knntD27dstzXSrV199VTabTZMnT7Y0U5cuXZJ8VtWrV8+yPJJ04MABPf300/L29lbevHlVr149nThxwrJMyX2e22w2jR8/3rJMERER6tu3r4oWLSpPT09VrFhRM2bMSLc8Kcl09uxZdenSRUWKFFGuXLnUvHlzHTlyJN3ypOS7pBWf4Y5AubrN0qVLNWDAAA0bNkx79uxRw4YN1aJFi3T9YLibyMhIVa9eXdOmTbPk+ZOzadMm9enTR7/99puCgoIUGxurpk2bKjIy0rJMRYsW1ZgxY7Rr1y7t2rVLjRs3VuvWrTPFP8KdO3dq9uzZqlatmtVRVLlyZYWEhCRe/vjjD0vzXL58WQ0aNJCrq6u+//577d+/XxMmTFC+fPksy7Rz50679ygoKEiS9Pzzz1uWaezYsZo5c6amTZumAwcOaNy4cRo/frymTp1qWSZJ6t69u4KCgvTFF1/ojz/+UNOmTfXEE0/o9OnTGfL89/p8HDdunCZOnKhp06Zp586d8vPzU5MmTXT16lXLMkVGRqpBgwYaM2ZMumVITaZr167p999/1/Dhw/X7779rxYoVOnz4sJ5++mnLMklSuXLlNG3aNP3xxx/asmWLSpQooaZNm+r8+fOWZUqwcuVKbd++XUWKFEm3LKnJ1Lx5c7vPrLVr11qW559//tEjjzyiChUq6Oeff9bevXs1fPhweXh4WJbp1vcmJCRE8+bNk81m07PPPmtZpoEDB+qHH37Ql19+qQMHDmjgwIF6/fXXtWrVKksyGYahNm3a6N9//9WqVau0Z88e+fv764knnki373Yp+S5pxWe4Qxiw8/DDDxu9evWyW1ehQgXj7bfftijRTZKMb775xuoYSZw7d86QZGzatMnqKHby589vzJkzx9IMV69eNcqWLWsEBQUZjz76qNG/f3/Lsrz//vtG9erVLXv+5AwZMsR45JFHrI5xV/379zdKly5txMfHW5ahZcuWRteuXe3WtW3b1njppZcsSmQY165dM5ydnY3vvvvObn316tWNYcOGZXie2z8f4+PjDT8/P2PMmDGJ627cuGF4e3sbM2fOtCTTrY4ePWpIMvbs2ZMhWVKSKcGOHTsMScbx48czTaawsDBDkrFhwwZLM506dcp48MEHjT///NPw9/c3Jk2alCF57pSpc+fORuvWrTMsw73ytG/f3tLPpZT8XWrdurXRuHHjjAlkJJ+pcuXKxgcffGC3rmbNmsa7775rSaZDhw4Zkow///wzcV1sbKzh4+NjfPbZZxmS6fbvkpnhMzytGLm6RXR0tHbv3q2mTZvarW/atKm2bt1qUarMLywsTJLk4+NjcRJTXFyclixZosjISAUEBFiapU+fPmrZsqWeeOIJS3MkOHLkiIoUKaKSJUvqhRde0L///mtpntWrV6t27dp6/vnnVahQIdWoUUOfffaZpZluFR0drS+//FJdu3aVzWazLMcjjzyiH3/8UYcPH5Yk7d27V1u2bNGTTz5pWabY2FjFxcUl+Y20p6entmzZYlGqm44eParQ0FC7z3N3d3c9+uijfJ7fQ1hYmGw2m6UjyLeKjo7W7Nmz5e3trerVq1uWIz4+Xp06ddLgwYNVuXJly3Lc7ueff1ahQoVUrlw59ejRQ+fOnbMkR3x8vNasWaNy5cqpWbNmKlSokOrWrZspDmdIcPbsWa1Zs0bdunWzNMcjjzyi1atX6/Tp0zIMQxs3btThw4fVrFkzS/JERUVJkt3nubOzs9zc3DLs8/z275JZ+TOccnWLCxcuKC4uTr6+vnbrfX19FRoaalGqzM0wDA0aNEiPPPKIqlSpYmmWP/74Q3ny5JG7u7t69eqlb775RpUqVbIsz5IlS/T7778rMDDQsgy3qlu3rhYuXKh169bps88+U2hoqOrXr6+LFy9alunff//VjBkzVLZsWa1bt069evVSv379tHDhQssy3WrlypW6cuWKunTpYmmOIUOG6MUXX1SFChXk6uqqGjVqaMCAAXrxxRcty5Q3b14FBAToww8/1JkzZxQXF6cvv/xS27dvV0hIiGW5EiR8ZvN5njo3btzQ22+/rQ4dOsjLy8vSLN99953y5MkjDw8PTZo0SUFBQSpYsKBlecaOHSsXFxf169fPsgy3a9GihRYtWqSffvpJEyZM0M6dO9W4cePEL8sZ6dy5c4qIiNCYMWPUvHlzrV+/Xs8884zatm2rTZs2ZXie5Hz++efKmzev2rZta2mOTz75RJUqVVLRokXl5uam5s2ba/r06XrkkUcsyVOhQgX5+/tr6NChunz5sqKjozVmzBiFhoZmyOd5ct8ls/JnuIvVATKj239DbRiGpb+1zsz69u2rffv2ZYrfVJcvX17BwcG6cuWKli9frs6dO2vTpk2WFKyTJ0+qf//+Wr9+fbrua54aLVq0SFyuWrWqAgICVLp0aX3++ecaNGiQJZni4+NVu3ZtjR49WpJUo0YN/fXXX5oxY4ZefvllSzLdau7cuWrRokWGHFtxN0uXLtWXX36pr776SpUrV1ZwcLAGDBigIkWKqHPnzpbl+uKLL9S1a1c9+OCDcnZ2Vs2aNdWhQwf9/vvvlmW6HZ/nKRcTE6MXXnhB8fHxmj59utVx1KhRIwUHB+vChQv67LPP1K5dO23fvl2FChXK8Cy7d+/WlClT9Pvvv2eqvz/t27dPXK5SpYpq164tf39/rVmzJsMLRMIEO61bt9bAgQMlSQ899JC2bt2qmTNn6tFHH83QPMmZN2+eOnbsaPn/y5988ol+++03rV69Wv7+/vrll1/Uu3dvFS5c2JI9XVxdXbV8+XJ169ZNPj4+cnZ21hNPPGH3vSE93e27ZFb8DGfk6hYFCxaUs7NzkkZ87ty5JM0Z0uuvv67Vq1dr48aNKlq0qNVx5ObmpjJlyqh27doKDAxU9erVNWXKFEuy7N69W+fOnVOtWrXk4uIiFxcXbdq0SZ988olcXFwUFxdnSa5b5c6dW1WrVk3X2YDupXDhwknKb8WKFS2bQOZWx48f14YNG9S9e3ero2jw4MF6++239cILL6hq1arq1KmTBg4caPmoaOnSpbVp0yZFRETo5MmT2rFjh2JiYlSyZElLc0lKnAmTz/OUiYmJUbt27XT06FEFBQVZPmolmZ9RZcqUUb169TR37ly5uLho7ty5lmTZvHmzzp07p+LFiyd+ph8/flxvvPGGSpQoYUmm5BQuXFj+/v6WfK4XLFhQLi4umfYzffPmzTp06JDln+nXr1/XO++8o4kTJ6pVq1aqVq2a+vbtq/bt2+vjjz+2LFetWrUSf0EdEhKiH374QRcvXkz3z/M7fZfMyp/hlKtbuLm5qVatWomzgyUICgpS/fr1LUqV+RiGob59+2rFihX66aefMsUXqeQYhmHJrhGS9Pjjj+uPP/5QcHBw4qV27drq2LGjgoOD5ezsbEmuW0VFRenAgQMqXLiwZRkaNGiQZOrVw4cPy9/f36JEN82fP1+FChVSy5YtrY6ia9euycnJ/uPa2dnZ8qnYE+TOnVuFCxfW5cuXtW7dOrVu3drqSCpZsqT8/PzsPs+jo6O1adMmPs9vk1Csjhw5og0bNqhAgQJWR0qWlZ/pnTp10r59++w+04sUKaLBgwdr3bp1lmRKzsWLF3Xy5ElLPtfd3NxUp06dTPuZPnfuXNWqVcvS4/Yk899bTExMpv1M9/b21gMPPKAjR45o165d6fZ5fq/vkln5M5zdAm8zaNAgderUSbVr11ZAQIBmz56tEydOqFevXpbkiYiI0N9//514/ejRowoODpaPj4+KFy9uSaY+ffroq6++0qpVq5Q3b97E3yp4e3vL09PTkkzvvPOOWrRooWLFiunq1atasmSJfv75Z/3www+W5MmbN2+SY9By586tAgUKWHZs2ptvvqlWrVqpePHiOnfunEaNGqXw8HBLdysbOHCg6tevr9GjR6tdu3basWOHZs+erdmzZ1uWSTJ3b5k/f746d+4sFxfrPyZbtWqljz76SMWLF1flypW1Z88eTZw4UV27drU017p162QYhsqXL6+///5bgwcPVvny5fXKK69kyPPf6/NxwIABGj16tMqWLauyZctq9OjRypUrlzp06GBZpkuXLunEiROJ55FK+CL6/+3df0hV9x/H8dfNvN0bhcsf5b3olWuCo1o/XDGV4ZRgTRil9sO11XKGUUm1MQxq/Zhj9Udl0CKbtfBqCeWNCgxSN7DRH6VjrSXVZEgSW7ZAJsGs2Lyf/RFddpdLv99dPcWeDzjgOedzPvd1j3K8bz7nfk58fPywPXfuaZncbrcWLVqky5cv6+zZs+rv7w9e06Ojo2W320c8U0xMjHbs2KH58+fL5XKpp6dHlZWV+umnn4b1kQiD/e7+XnRGRkYqPj5eqamplmSKjo7Wxx9/rIULF8rlcqmrq0ubN29WbGys8vPzRzyPx+NRWVmZCgsLlZWVpZycHDU2NqqhoUHnz58fljxDySRJ9+7dk9/vV0VFxbDl+F8yvfbaayorK5PT6VRSUpK+/vpr1dbWau/evZZl8vv9iouLk8fjUXt7uzZs2KC8vLwnJnkLl8E+Sz5+NuhIX8PDwqJZCp9pBw4cMElJScZut5u0tDRLpxhvaWkxkp5YVqxYYVmmgfJIMtXV1ZZlKi4uDv7O4uLizNy5c01zc7NleQZi9VTshYWFxuVymcjISON2u01BQYG5du2aZXkea2hoMNOmTTNjxowxL774ojl06JDVkUxTU5ORZDo6OqyOYowx5t69e2bDhg3G4/EYh8NhkpOTzUcffWQePnxoaa4TJ06Y5ORkY7fbTXx8vCktLTW9vb0j9vqDXR8DgYDZvn27iY+PN2PGjDFZWVmmvb3d0kzV1dUD7t++fbslmR5PCT/Q0tLSYkmm+/fvm/z8fON2u43dbjcul8vMnz/ftLW1DVuewTINZCSmYn9apr6+PvP666+buLg4ExkZaTwej1mxYoW5deuWJXkeO3LkiElJSTEOh8PMmDHDnDlzZtjyDDVTVVWVcTqdI3Z9GixTd3e3KSoqMm632zgcDpOammoqKiqG9ZEfg2Xat2+fSUhICP4tbdmyZVj/xwzls6QV1/BwsBljzP9RkwEAAAAA/oLvXAEAAABAGFBcAQAAAEAYUFwBAAAAQBhQXAEAAABAGFBcAQAAAEAYUFwBAAAAQBhQXAEAAABAGFBcAQAAAEAYUFwBADBEPp9PL7zwwoi8VlFRkfLy8kbktQAA4UFxBQCAhbq6umSz2XTlyhWrowAA/iWKKwAAAAAIA4orAMAzITs7W+vWrdP777+vCRMmaNKkSTp06JB+++03vffeexo/frwmT56sc+fOSZL6+/u1cuVKeb1eOZ1Opaamat++fcH+Hjx4oKlTp2rVqlXBbTdv3lRUVJQOHz48pEw+n08ej0djx45Vfn6+enp6nmjT0NCgl19+WQ6HQ8nJySovL9cff/wR3G+z2XTw4EHl5ubK6XTK6/XK7/cH93u9XknSrFmzZLPZlJ2dHdL/nj175HK5FBMTo9LSUv3+++9Dyg4AGHkUVwCAZ0ZNTY1iY2PV1tamdevWac2aNVq8eLEyMzN1+fJlzZs3T8uXL1dfX58CgYASEhJUX1+v69eva9u2bdq8ebPq6+slSQ6HQ3V1daqpqdGZM2fU39+v5cuXKycnRyUlJYNmaW1tVXFxsdauXasrV64oJydHn376aUibpqYmLVu2TOvXr9f169dVVVUln8+nHTt2hLTbunWrFi5cqO+//17Lli3T0qVLdePGDUlSW1ubJOmrr75Sd3e3Tp06FTyupaVFnZ2damlpUU1NjXw+n3w+3785xQCAYWQzxhirQwAAkJ2drf7+fl24cEHSo5GpqKgoFRQUqLa2VpJ0584duVwuXbx4Uenp6U/0UVpaql9++UUnT54Mbtu9e7d27dqlpUuXyu/3q729XbGxsYPmefvtt/Xrr78GR8ok6a233lJjY6N6e3slSVlZWcrNzdWmTZuCbY4dO6aNGzfq9u3bkh6NXK1evVoHDx4MtklPT1daWpoqKyvV1dUlr9er7777TjNnzgy2KSoq0vnz59XZ2amIiAhJ0pIlSzRq1CgdP3580PwAgJHHyBUA4Jkxffr04M8RERGKiYnRSy+9FNw2adIkSdLdu3clSZ9//rlmz56tuLg4jRs3TocPH9atW7dC+vzwww+Vmpqq/fv3q7q6ekiFlSTduHFDGRkZIdv+vv7tt9/qk08+0bhx44JLSUmJuru71dfX94/HZWRkBEeunmbq1KnBwkqSXC5X8L0DAJ49o60OAADAY5GRkSHrNpstZJvNZpMkBQIB1dfX64MPPlBFRYUyMjI0fvx47d69W62trSF93L17Vx0dHYqIiNCPP/6oN954Y0hZhnJjRyAQUHl5uQoKCp7Y53A4nnrs4/fyNAOdj0AgMOhxAABrUFwBAJ5LFy5cUGZmptauXRvc1tnZ+US74uJiTZs2TSUlJVq5cqXmzp2rKVOmDNr/lClTdOnSpZBtf19PS0tTR0eHUlJSntrXpUuX9O6774asz5o1S5Jkt9slPboNEgDwfKO4AgA8l1JSUlRbW6umpiZ5vV4dPXpU33zzTXD2PUk6cOCALl68qKtXryoxMVHnzp3TO++8o9bW1mBR80/Wr1+vzMxM7dq1S3l5eWpublZjY2NIm23btunNN99UYmKiFi9erFGjRunq1atqb28PmfzC7/dr9uzZevXVV1VXV6e2tjYdOXJEkjRx4kQ5nU41NjYqISFBDodDUVFRYTxTAICRwneuAADPpdWrV6ugoECFhYV65ZVX1NPTEzKK9cMPP6isrEyVlZVKTEyU9KjY6u3t1datWwftPz09XV988YX279+vmTNnqrm5WVu2bAlpM2/ePJ09e1Zffvml5syZo/T0dO3du1dJSUkh7crLy3X8+HFNnz5dNTU1qqurC46ejR49Wp999pmqqqrkdru1YMGCf3tqAAAWYbZAAACGkc1m0+nTp5WXl2d1FADAMGPkCgAAAADCgOIKAPCflJubGzKF+l+XnTt3Wh0PAPAc4rZAAMB/0s8//6z79+8PuC86OlrR0dEjnAgA8LyjuAIAAACAMOC2QAAAAAAIA4orAAAAAAgDiisAAAAACAOKKwAAAAAIA4orAAAAAAgDiisAAAAACAOKKwAAAAAIgz8BOrle9ac2SUEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The runtime of your code is: 0:00:00.148420 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer()\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(depths, train_scores_xgb, c='blue', label='train')\n",
    "plt.plot(depths, validation_scores_xgb, c='red', label='validation')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title(\"XGBoost max_depth tuning\")\n",
    "plt.xlim([1,21])\n",
    "plt.xticks(range(0,21,1))\n",
    "plt.legend()\n",
    "\n",
    "sns.despine()\n",
    "plt.show()\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada5bc97",
   "metadata": {},
   "source": [
    "Based on the plot, ideal values for `max_depth` could lie between 4 and 6. Let's run a `GridSearchCV` to see if we can find the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ff910",
   "metadata": {},
   "source": [
    "#### 5-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ecff2d",
   "metadata": {},
   "source": [
    "I will run a `GridSearchCV` to optimize for `max_depth`, `'n_estimators` and `learning_rate`. I will also add some dimension redcution with PCA()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "f7f6b2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "[02:16:15] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:16:16] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:16:16] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:16:16] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:16:16] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:16:16] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:16:16] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:16:16] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:16:16] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:16:16] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:16:16] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:16:17] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:16:17] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:16:17] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:16:17] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:16:18] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "[02:16:18] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "[02:16:18] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.3s\n",
      "[02:16:19] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "[02:16:19] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "[02:16:19] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:16:20] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.4s\n",
      "[02:16:20] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.4s\n",
      "[02:16:21] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.4s\n",
      "[02:16:21] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:16:22] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.6s\n",
      "[02:16:22] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.6s\n",
      "[02:16:23] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.5s\n",
      "[02:16:24] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.6s\n",
      "[02:16:24] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.5s\n",
      "[02:16:25] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.5s\n",
      "[02:16:26] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.5s\n",
      "[02:16:26] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.5s\n",
      "[02:16:27] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.5s\n",
      "[02:16:27] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.6s\n",
      "[02:16:28] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.1s\n",
      "[02:16:29] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.9s\n",
      "[02:16:30] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.8s\n",
      "[02:16:31] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.8s\n",
      "[02:16:32] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.8s\n",
      "[02:16:33] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.7s\n",
      "[02:16:34] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.7s\n",
      "[02:16:35] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.7s\n",
      "[02:16:35] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.7s\n",
      "[02:16:36] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.8s\n",
      "[02:16:37] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.1s\n",
      "[02:16:38] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.1s\n",
      "[02:16:39] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.1s\n",
      "[02:16:41] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.1s\n",
      "[02:16:42] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.1s\n",
      "[02:16:43] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:16:43] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:16:43] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:16:43] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:16:43] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:16:44] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:16:44] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:16:44] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:16:44] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[02:16:44] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[02:16:44] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:16:45] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:16:45] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:16:46] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:16:46] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:16:46] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.5s\n",
      "[02:16:47] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:16:48] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:16:48] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:16:49] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:16:49] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.4s\n",
      "[02:16:50] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.5s\n",
      "[02:16:50] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.5s\n",
      "[02:16:51] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.5s\n",
      "[02:16:51] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.5s\n",
      "[02:16:52] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.7s\n",
      "[02:16:53] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.7s\n",
      "[02:16:54] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.7s\n",
      "[02:16:54] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.7s\n",
      "[02:16:55] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.7s\n",
      "[02:16:56] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.7s\n",
      "[02:16:57] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.7s\n",
      "[02:16:58] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.7s\n",
      "[02:16:58] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.7s\n",
      "[02:16:59] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.8s\n",
      "[02:17:00] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.1s\n",
      "[02:17:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.0s\n",
      "[02:17:02] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.0s\n",
      "[02:17:04] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.1s\n",
      "[02:17:05] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.0s\n",
      "[02:17:06] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.9s\n",
      "[02:17:07] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.9s\n",
      "[02:17:08] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.9s\n",
      "[02:17:09] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.9s\n",
      "[02:17:10] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.9s\n",
      "[02:17:11] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.4s\n",
      "[02:17:12] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.4s\n",
      "[02:17:14] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.4s\n",
      "[02:17:15] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.6s\n",
      "[02:17:17] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.4s\n",
      "[02:17:19] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:17:19] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:17:19] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:17:19] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:17:19] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:17:19] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[02:17:19] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:17:19] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:17:20] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:17:20] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:17:20] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:17:20] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:17:21] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:17:21] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:17:22] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:17:22] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.5s\n",
      "[02:17:23] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:17:23] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.5s\n",
      "[02:17:24] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.5s\n",
      "[02:17:24] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:17:25] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.6s\n",
      "[02:17:25] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.6s\n",
      "[02:17:26] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.6s\n",
      "[02:17:27] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.6s\n",
      "[02:17:27] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.6s\n",
      "[02:17:28] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.9s\n",
      "[02:17:29] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.9s\n",
      "[02:17:30] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.9s\n",
      "[02:17:31] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.0s\n",
      "[02:17:32] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.0s\n",
      "[02:17:33] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.8s\n",
      "[02:17:34] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.9s\n",
      "[02:17:35] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.8s\n",
      "[02:17:36] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.9s\n",
      "[02:17:37] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.8s\n",
      "[02:17:38] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.3s\n",
      "[02:17:39] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.3s\n",
      "[02:17:41] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.3s\n",
      "[02:17:42] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.3s\n",
      "[02:17:44] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.3s\n",
      "[02:17:45] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.1s\n",
      "[02:17:46] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.1s\n",
      "[02:17:47] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.3s\n",
      "[02:17:49] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.1s\n",
      "[02:17:50] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.1s\n",
      "[02:17:51] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.7s\n",
      "[02:17:53] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.7s\n",
      "[02:17:55] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.7s\n",
      "[02:17:57] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.7s\n",
      "[02:17:59] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=0.5, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.7s\n",
      "[02:18:00] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:18:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:18:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:18:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:18:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:18:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:18:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:18:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:18:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:18:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:18:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:18:02] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:18:02] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:18:02] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:18:03] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:18:03] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.3s\n",
      "[02:18:03] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.3s\n",
      "[02:18:04] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.3s\n",
      "[02:18:04] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:18:05] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.3s\n",
      "[02:18:05] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.4s\n",
      "[02:18:06] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.4s\n",
      "[02:18:06] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.4s\n",
      "[02:18:07] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.4s\n",
      "[02:18:07] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.4s\n",
      "[02:18:08] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.6s\n",
      "[02:18:08] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.6s\n",
      "[02:18:09] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.6s\n",
      "[02:18:10] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.6s\n",
      "[02:18:10] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.6s\n",
      "[02:18:11] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.6s\n",
      "[02:18:12] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.6s\n",
      "[02:18:12] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.6s\n",
      "[02:18:13] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.6s\n",
      "[02:18:13] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.6s\n",
      "[02:18:14] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.9s\n",
      "[02:18:15] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.9s\n",
      "[02:18:16] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.9s\n",
      "[02:18:17] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.9s\n",
      "[02:18:18] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.9s\n",
      "[02:18:19] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.9s\n",
      "[02:18:20] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.9s\n",
      "[02:18:21] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.8s\n",
      "[02:18:22] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.8s\n",
      "[02:18:23] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.8s\n",
      "[02:18:24] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.2s\n",
      "[02:18:25] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.2s\n",
      "[02:18:26] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.2s\n",
      "[02:18:27] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.2s\n",
      "[02:18:29] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.2s\n",
      "[02:18:30] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:18:30] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:18:30] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:18:30] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:18:31] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:18:31] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:18:31] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:18:31] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:18:31] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:18:31] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[02:18:31] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:18:32] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:18:32] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:18:32] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:18:33] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:18:33] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:18:34] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:18:34] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:18:35] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:18:35] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.6s\n",
      "[02:18:36] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.7s\n",
      "[02:18:37] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.6s\n",
      "[02:18:37] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.5s\n",
      "[02:18:38] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.6s\n",
      "[02:18:39] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.5s\n",
      "[02:18:39] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.8s\n",
      "[02:18:40] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.8s\n",
      "[02:18:41] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.8s\n",
      "[02:18:42] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.9s\n",
      "[02:18:43] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.9s\n",
      "[02:18:44] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.8s\n",
      "[02:18:45] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.9s\n",
      "[02:18:46] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.8s\n",
      "[02:18:47] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.8s\n",
      "[02:18:48] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.9s\n",
      "[02:18:49] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.2s\n",
      "[02:18:50] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.3s\n",
      "[02:18:52] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.4s\n",
      "[02:18:53] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.2s\n",
      "[02:18:54] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.2s\n",
      "[02:18:56] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.1s\n",
      "[02:18:57] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.1s\n",
      "[02:18:58] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.1s\n",
      "[02:18:59] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.1s\n",
      "[02:19:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.1s\n",
      "[02:19:02] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.6s\n",
      "[02:19:04] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.6s\n",
      "[02:19:05] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.6s\n",
      "[02:19:07] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.9s\n",
      "[02:19:09] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.6s\n",
      "[02:19:11] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:19:11] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:19:11] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:19:11] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:19:11] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[02:19:11] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[02:19:12] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[02:19:12] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:19:12] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[02:19:12] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[02:19:12] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.4s\n",
      "[02:19:13] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.4s\n",
      "[02:19:13] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.4s\n",
      "[02:19:14] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:19:14] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.4s\n",
      "[02:19:15] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.6s\n",
      "[02:19:15] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.5s\n",
      "[02:19:16] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.6s\n",
      "[02:19:17] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.5s\n",
      "[02:19:17] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.6s\n",
      "[02:19:18] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.7s\n",
      "[02:19:19] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.7s\n",
      "[02:19:20] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.7s\n",
      "[02:19:20] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.7s\n",
      "[02:19:21] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.7s\n",
      "[02:19:22] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.0s\n",
      "[02:19:23] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.2s\n",
      "[02:19:24] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.2s\n",
      "[02:19:26] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.1s\n",
      "[02:19:27] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.0s\n",
      "[02:19:28] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.0s\n",
      "[02:19:29] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.0s\n",
      "[02:19:30] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.0s\n",
      "[02:19:31] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.0s\n",
      "[02:19:32] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.0s\n",
      "[02:19:33] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.5s\n",
      "[02:19:35] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.5s\n",
      "[02:19:37] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.5s\n",
      "[02:19:38] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.7s\n",
      "[02:19:40] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.6s\n",
      "[02:19:42] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.3s\n",
      "[02:19:43] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.3s\n",
      "[02:19:45] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.3s\n",
      "[02:19:46] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.3s\n",
      "[02:19:48] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   1.3s\n",
      "[02:19:49] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.0s\n",
      "[02:19:51] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.0s\n",
      "[02:19:53] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.0s\n",
      "[02:19:55] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.2s\n",
      "[02:19:58] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=1, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   2.0s\n",
      "[02:20:00] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:20:00] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:20:00] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:20:00] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:20:00] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:20:00] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:20:00] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:20:00] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:20:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:20:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:20:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:20:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[02:20:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:20:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[02:20:02] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[02:20:02] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "[02:20:02] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[02:20:02] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "[02:20:03] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.3s\n",
      "[02:20:03] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "[02:20:03] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:20:04] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[02:20:04] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[02:20:04] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[02:20:04] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[02:20:05] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.3s\n",
      "[02:20:05] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "[02:20:05] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "[02:20:06] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:20:06] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.5s\n",
      "[02:20:07] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:20:07] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[02:20:07] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:20:07] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[02:20:08] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:20:08] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.3s\n",
      "[02:20:08] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "[02:20:09] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.3s\n",
      "[02:20:09] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:20:10] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.6s\n",
      "[02:20:10] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:20:11] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:20:11] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:20:11] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:20:12] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:20:12] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.5s\n",
      "[02:20:13] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.3s\n",
      "[02:20:13] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.3s\n",
      "[02:20:13] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.5s\n",
      "[02:20:14] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=4, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.6s\n",
      "[02:20:15] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:20:15] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:20:15] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:20:15] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:20:15] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:20:15] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[02:20:15] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:20:16] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[02:20:16] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:20:16] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.0s\n",
      "[02:20:16] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[02:20:16] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:20:17] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:20:17] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[02:20:17] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[02:20:17] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:20:18] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.3s\n",
      "[02:20:18] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "[02:20:19] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.3s\n",
      "[02:20:19] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "[02:20:19] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.1s\n",
      "[02:20:20] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:20:20] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:20:20] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:20:20] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:20:21] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.6s\n",
      "[02:20:21] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.5s\n",
      "[02:20:22] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.2s\n",
      "[02:20:22] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.3s\n",
      "[02:20:23] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.3s\n",
      "[02:20:23] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:20:24] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:20:24] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:20:24] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:20:25] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:20:25] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.8s\n",
      "[02:20:26] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.5s\n",
      "[02:20:26] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.3s\n",
      "[02:20:27] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:20:27] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:20:28] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:20:28] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.4s\n",
      "[02:20:29] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.4s\n",
      "[02:20:29] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:20:30] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:20:30] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.9s\n",
      "[02:20:31] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.6s\n",
      "[02:20:32] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.3s\n",
      "[02:20:32] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:20:33] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=5, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:20:33] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:20:33] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:20:33] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:20:33] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:20:34] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.0s\n",
      "[02:20:34] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[02:20:34] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[02:20:34] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[02:20:34] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[02:20:34] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=10, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.1s\n",
      "[02:20:34] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:20:35] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:20:35] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:20:36] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.2s\n",
      "[02:20:36] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:20:36] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:20:37] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.5s\n",
      "[02:20:38] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.5s\n",
      "[02:20:38] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:20:39] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=50, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:20:39] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.5s\n",
      "[02:20:40] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.5s\n",
      "[02:20:40] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.5s\n",
      "[02:20:41] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.3s\n",
      "[02:20:41] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.5s\n",
      "[02:20:42] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.7s\n",
      "[02:20:43] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.0s\n",
      "[02:20:44] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.0s\n",
      "[02:20:45] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.7s\n",
      "[02:20:46] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=90, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.4s\n",
      "[02:20:46] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.7s\n",
      "[02:20:47] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.7s\n",
      "[02:20:48] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.7s\n",
      "[02:20:48] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.4s\n",
      "[02:20:49] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.7s\n",
      "[02:20:50] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.0s\n",
      "[02:20:51] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.2s\n",
      "[02:20:52] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.0s\n",
      "[02:20:53] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.8s\n",
      "[02:20:54] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=130, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.5s\n",
      "[02:20:55] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.8s\n",
      "[02:20:56] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.9s\n",
      "[02:20:57] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.7s\n",
      "[02:20:57] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.4s\n",
      "[02:20:58] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=8; total time=   0.9s\n",
      "[02:20:59] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.5s\n",
      "[02:21:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.6s\n",
      "[02:21:02] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   1.2s\n",
      "[02:21:04] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.9s\n",
      "[02:21:05] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None), model__learning_rate=2, model__max_depth=6, model__n_estimators=170, reduce_dim=PCA(), reduce_dim__n_components=None; total time=   0.5s\n",
      "[02:21:05] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The runtime of your code is: 0:04:52.343603 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "# specify the components\n",
    "estimators = [\n",
    "    ('reduce_dim', PCA()), \n",
    "    ('model', XGBClassifier())\n",
    "]\n",
    "\n",
    "# create pipeline\n",
    "my_pipe = Pipeline(estimators)\n",
    "\n",
    "\n",
    "# grid for searching\n",
    "param_grid = [\n",
    "    {\n",
    "        'model': [XGBClassifier()],\n",
    "        'reduce_dim': [PCA()],\n",
    "        'model__max_depth': [4, 5, 6],\n",
    "        'model__n_estimators': range(10, 201, 40),\n",
    "        'model__learning_rate': [0.5, 1, 2],\n",
    "        'reduce_dim__n_components': [8, None]\n",
    "    }\n",
    "]\n",
    "\n",
    "time = timer() # start timer\n",
    "grid = GridSearchCV(my_pipe, param_grid, cv=5, verbose=2)\n",
    "\n",
    "fittedgrid = grid.fit(X_train, y_train)\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74130b83",
   "metadata": {},
   "source": [
    "I will save the fittedgrid to a .pkl file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "84662fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XGBoost_gridsearch.pkl']"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving to .pkl\n",
    "joblib.dump(fittedgrid, 'XGBoost_gridsearch.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "67b19e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_fitgrid = joblib.load('XGBoost_gridsearch.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "08b57439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model\n",
    "best_model = xgb_fitgrid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "e07548da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "               colsample_bynode=None, colsample_bytree=None,\n",
       "               enable_categorical=False, gamma=None, gpu_id=None,\n",
       "               importance_type=None, interaction_constraints=None,\n",
       "               learning_rate=0.5, max_delta_step=None, max_depth=6,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               n_estimators=170, n_jobs=None, num_parallel_tree=None,\n",
       "               predictor=None, random_state=None, reg_alpha=None,\n",
       "               reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "               tree_method=None, validate_parameters=None, verbosity=None),\n",
       " 'model__learning_rate': 0.5,\n",
       " 'model__max_depth': 6,\n",
       " 'model__n_estimators': 170,\n",
       " 'reduce_dim': PCA(),\n",
       " 'reduce_dim__n_components': None}"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best set of parameters\n",
    "xgb_fitgrid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "3bc57830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.736988668306633"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best score\n",
    "xgb_fitgrid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa3762",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a168cb",
   "metadata": {},
   "source": [
    "##### Accuracy Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9ff42f",
   "metadata": {},
   "source": [
    "Let's fit the best model to the remainder set and calculate accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "df626db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:26:21] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The runtime of your code is: 0:00:02.546703 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer()\n",
    "# fit best_model\n",
    "best_model.fit(X_remainder, y_remainder)\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "5ea44208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remainder Set Score: 0.986536226268888\n",
      "Test Set Score: 0.7492372511986053\n",
      "The runtime of your code is: 0:00:00.055504 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer()\n",
    "# accuracy scores\n",
    "print(f'Remainder Set Score: {best_model.score(X_remainder, y_remainder)}')\n",
    "print(f'Test Set Score: {best_model.score(X_test, y_test)}')\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729b230",
   "metadata": {},
   "source": [
    "##### Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f2ab39",
   "metadata": {},
   "source": [
    "Let's plot the confusion matrix for the XGBoost model and get prediction for test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "02f81d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhEAAAGwCAYAAAAXNjfEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHIElEQVR4nO3deVxU9foH8M/IMizCKCAMKCKkEgqagsHY4o5SpGY37UeXqzfCTJNIzVJb7JaS3VIzS8lMzCXsZpqVTWIlZYIKSrmgbWigDGDBsMg6c35/EKdGOCMzw+7n/Xqd18s55zlnvmPkPDzP93uOTBAEAUREREQm6tbeAyAiIqLOiUkEERERmYVJBBEREZmFSQQRERGZhUkEERERmYVJBBEREZmFSQQRERGZxbq9B9DW9Ho9Ll++DCcnJ8hksvYeDhERmUgQBJSVlcHLywvdurXe78JVVVWoqamx+Dq2traws7NrgRF1PDdcEnH58mV4e3u39zCIiMhCubm56NOnT6tcu6qqCr4+3aEp1Fl8LaVSiZycnC6ZSNxwSYSTkxMA4OKJfnDuzm4OdU33Dgxq7yEQtZo61OIw9ov/nreGmpoaaAp1uJjZD85O5n9XlJbp4RN8ATU1NUwiuoKGFoZz924W/WAQdWTWMpv2HgJR6/nzYQ1t0ZLu7iRDdyfz30ePrt02v+GSCCIioubSCXroLHjClE7Qt9xgOiAmEURERBL0EKCH+VmEJed2BqznExERkVlYiSAiIpKghx6WNCQsO7vjYxJBREQkQScI0AnmtyQsObczYDuDiIiIzMJKBBERkQROrDSOSQQREZEEPQTomERIYjuDiIiIzMJKBBERkQS2M4xjEkFERCSBqzOMYzuDiIiog0pISIBMJkN8fLy4TxAELF++HF5eXrC3t8fo0aNx5swZg/Oqq6sxf/58uLm5wdHREZMnT0ZeXp5BTHFxMaKjo6FQKKBQKBAdHY2SkhKTxsckgoiISIK+BTZzHT9+HG+//TaGDBlisP+VV17B6tWrsX79ehw/fhxKpRITJkxAWVmZGBMfH489e/YgOTkZhw8fRnl5OSIjI6HT/fVo86ioKGRlZUGtVkOtViMrKwvR0dEmjZFJBBERkQTdn6szLNkAoLS01GCrrq42+r7l5eV48MEHsWnTJvTs2VPcLwgC1q5di2XLlmHatGkIDAzE1q1bcfXqVezcuRMAoNVqsXnzZrz22msYP348hg0bhu3bt+PUqVM4ePAgACA7OxtqtRrvvPMOVCoVVCoVNm3ahE8//RTnz59v9t8PkwgiIiIJOsHyDQC8vb3FtoFCoUBCQoLR9503bx7uvvtujB8/3mB/Tk4ONBoNwsPDxX1yuRyjRo3CkSNHAACZmZmora01iPHy8kJgYKAYk5aWBoVCgdDQUDEmLCwMCoVCjGkOTqwkIiJqZbm5uXB2dhZfy+Vyydjk5GScOHECx48fb3RMo9EAADw8PAz2e3h44OLFi2KMra2tQQWjIabhfI1GA3d390bXd3d3F2Oag0kEERGRBEvnNTSc6+zsbJBESMnNzcXjjz+OAwcOwM7OTjJOJpMZvBYEodG+a10b01R8c67zd2xnEBERSdBDBp0Fmx7N/0IG6lsRhYWFCA4OhrW1NaytrZGamop169bB2tparEBcWy0oLCwUjymVStTU1KC4uNhoTEFBQaP3LyoqalTlMIZJBBERUQcxbtw4nDp1CllZWeIWEhKCBx98EFlZWfDz84NSqURKSop4Tk1NDVJTUzFy5EgAQHBwMGxsbAxi8vPzcfr0aTFGpVJBq9Xi2LFjYszRo0eh1WrFmOZgO4OIiEiCXqjfLDnfFE5OTggMDDTY5+joCFdXV3F/fHw8Vq5ciQEDBmDAgAFYuXIlHBwcEBUVBQBQKBSIiYnBwoUL4erqChcXFyxatAhBQUHiRM2AgABMmjQJsbGxSExMBADMnj0bkZGR8Pf3b/Z4mUQQERFJaGhLWHJ+S1u8eDEqKysxd+5cFBcXIzQ0FAcOHICTk5MYs2bNGlhbW2P69OmorKzEuHHjkJSUBCsrKzFmx44diIuLE1dxTJ48GevXrzdpLDJB6OL35LxGaWkpFAoFin/0g7MTuznUNU30uqW9h0DUauqEWhzCx9Bqtc2arGiOhu+Ko2eU6G7Bd0V5mR6hgzWtOtb2xEoEERGRhI5YiehImEQQERFJ0Asy6AXzEwFLzu0MWM8nIiIis7ASQUREJIHtDOOYRBAREUnQoRt0FhTtddcP6dSYRBAREUkQLJwTIXBOBBEREVFjrEQQERFJ4JwI45hEEBERSdAJ3aATLJgT0cVv58h2BhEREZmFlQgiIiIJesigt+D3bT26dimCSQQREZEEzokwju0MIiIiMgsrEURERBIsn1jJdgYREdENqX5OhAUP4GI7g4iIiKgxViKIiIgk6C18dgZXZxAREd2gOCfCOCYRREREEvToxvtEGME5EURERGQWViKIiIgk6AQZdBY8ztuSczsDJhFEREQSdBZOrNSxnUFERETUGCsRREREEvRCN+gtWJ2h5+oMIiKiGxPbGcaxnUFERERmYSWCiIhIgh6WrbDQt9xQOiQmEURERBIsv9lU1y74d+1PR0RERK2GlQgiIiIJlj87o2v/rs4kgoiISIIeMuhhyZwI3rGSiIjohsRKhHFd+9MRERFRq2ElgoiISILlN5vq2r+rM4kgIiKSoBdk0Ftyn4gu/hTPrp0iERERUathJYKIiEiC3sJ2Rle/2RSTCCIiIgmWP8WzaycRXfvTERERUathJYKIiEiCDjLoLLhhlCXndgasRBAREUloaGdYspliw4YNGDJkCJydneHs7AyVSoXPP/9cPD5r1izIZDKDLSwszOAa1dXVmD9/Ptzc3ODo6IjJkycjLy/PIKa4uBjR0dFQKBRQKBSIjo5GSUmJyX8/TCKIiIg6iD59+uDll19GRkYGMjIyMHbsWEyZMgVnzpwRYyZNmoT8/Hxx279/v8E14uPjsWfPHiQnJ+Pw4cMoLy9HZGQkdDqdGBMVFYWsrCyo1Wqo1WpkZWUhOjra5PGynUFERCRBB8taErrrhxi45557DF6vWLECGzZsQHp6OgYPHgwAkMvlUCqVTZ6v1WqxefNmbNu2DePHjwcAbN++Hd7e3jh48CAmTpyI7OxsqNVqpKenIzQ0FACwadMmqFQqnD9/Hv7+/s0eLysRREREElqqnVFaWmqwVVdXX/e9dTodkpOTUVFRAZVKJe4/dOgQ3N3dMXDgQMTGxqKwsFA8lpmZidraWoSHh4v7vLy8EBgYiCNHjgAA0tLSoFAoxAQCAMLCwqBQKMSY5mISQUREJKHhAVyWbADg7e0tzj9QKBRISEiQfM9Tp06he/fukMvlmDNnDvbs2YNBgwYBACIiIrBjxw589dVXeO2113D8+HGMHTtWTEo0Gg1sbW3Rs2dPg2t6eHhAo9GIMe7u7o3e193dXYxpLrYziIiIWllubi6cnZ3F13K5XDLW398fWVlZKCkpwe7duzFz5kykpqZi0KBBmDFjhhgXGBiIkJAQ+Pj44LPPPsO0adMkrykIAmSyv9oyf/+zVExzMIkgIiKSIEAGvQVzIoQ/z21YbdEctra26N+/PwAgJCQEx48fx+uvv47ExMRGsZ6envDx8cFPP/0EAFAqlaipqUFxcbFBNaKwsBAjR44UYwoKChpdq6ioCB4eHiZ9PrYziIiIJLRUO8MSgiBIzqH4/fffkZubC09PTwBAcHAwbGxskJKSIsbk5+fj9OnTYhKhUqmg1Wpx7NgxMebo0aPQarViTHOxEkFERNRBLF26FBEREfD29kZZWRmSk5Nx6NAhqNVqlJeXY/ny5bjvvvvg6emJCxcuYOnSpXBzc8O9994LAFAoFIiJicHChQvh6uoKFxcXLFq0CEFBQeJqjYCAAEyaNAmxsbFidWP27NmIjIw0aWUGwCSCiIhIUls/CrygoADR0dHIz8+HQqHAkCFDoFarMWHCBFRWVuLUqVN47733UFJSAk9PT4wZMwa7du2Ck5OTeI01a9bA2toa06dPR2VlJcaNG4ekpCRYWVmJMTt27EBcXJy4imPy5MlYv369yZ9PJgiCYPJZnVhpaSkUCgWKf/SDsxO7OdQ1TfS6pb2HQNRq6oRaHMLH0Gq1zZ5nYKqG74r47yZD3t3G7OtUl9di7W37WnWs7YnfokRERGQWtjOIiIgktHU7o7NhEkFERCRBj27QW1C0t+TczqBrfzoiIiJqNaxEEBERSdAJMugsaElYcm5nwCSCiIhIAudEGMckgoiISILwtydxmnt+V9a1Px0RERG1GlYiiIiIJOggg86CB3BZcm5nwCSCiIhIgl6wbF6DvovfE5rtDCIiIjILKxFksuQ33LElwQtTHy7Co/+5BAA4vF+B/dtc8dMPDigttsZbB87jpsDKRueezXBA0ipPnDvhAGsb4KbBlXhp+y+Q29en6/+6dRAK8mwNzpk+rwAxy/Jb/4MR/emfCzWIXlhgsO+PQmv83y2DAQB2DjrELMuHamIpnHvWoSDPFh9vdsOn77kZnBMQXIFZT2lw8/CrqKsFfjljj2f+6YeaKv7+1lnoLZxYacm5nQGTCDLJ+Sx77N/uCt9BhglC1dVuGDSiAndElmDtk32bPPdshgOWPXgTHnisAHNfugQbGz1+PWsP2TX/j/3ryXxEPPi7+NreUd/in4Poei6cs8PTM/zE13rdXyXtOS9cxtCR5Xhlfl8U5Npi+KgyzE/Iw+8FNkj7QgGgPoFYseNXJK93x1vP9EZtrQx+gyoh8Me5U9FDBr0F8xosObczaPcU6a233oKvry/s7OwQHByMb7/91mh8amoqgoODYWdnBz8/P2zcuLGNRkqVFd2w6jEfxP83F04KncGx8f8oxj8XFGDYneWS5ycu742pMUWYMb8Q/fyr0NuvBndEamErN2wa2nfXw8W9TtyYRFB70OmA4iIbcdP+8dfvXAHBV5HyPxf8kNYdBXm2+HyHK349a48BQ66KMY8sv4y9m93wwXoPXPzRDpdz5Dj8WQ/U1rT7P7tELaZdf5p37dqF+Ph4LFu2DCdPnsQdd9yBiIgI/Pbbb03G5+Tk4K677sIdd9yBkydPYunSpYiLi8Pu3bvbeOQ3pvVL++DWcaUYbiRRkFJyxRrnTjiih2sd4u8ZgBlDBmPRtP44fdSxUez/3nTHPwYH4tHx/tj5ugdqa7p2Jk8dU2/fGuw8cQZb07OxZMNFKPtWi8fOHHNEWLgWrspaAAKGjixHb79qZKY6AQAUrrUICL6Kkt+tsWbfT0j+/gz+u/tnDL7V9P93qH013LHSkq0ra9d2xurVqxETE4OHH34YALB27Vp88cUX2LBhAxISEhrFb9y4EX379sXatWsBAAEBAcjIyMCrr76K++67ry2HfsM5tLcHfj5ljzf2/2jW+fkX6+c5bFutROyzl3HT4Eoc/LAnnp5xExK/OofefjUAgKkPF6F/0FV0V+hw/qQDtiR4oeA3WzzxWm6LfRai6zl3wgH/jfNG3q9y9OxVh/97vABr9v2M2WP8UVZsjbee9UL8f/Ow88RZ1NUCer0Maxf1wZlj3QEAnj71P8/RCwqw6UUv/HLGDuP/UYyXd/2KR8b643KOvD0/HpmAcyKMa7ckoqamBpmZmXj66acN9oeHh+PIkSNNnpOWlobw8HCDfRMnTsTmzZtRW1sLGxubRudUV1ejuvqv3yBKS0tbYPQ3lsJLNtjwXG+sfP8X2NqZt15J/2dH4q5//o6JD/wBAOgfVImsw074ItkVDy2tnzg5bXaReI7foCp076HDS7G+iFl2Gc4uukbXJWoNGV87i3++cO7PCcFp5zDh/mJ89HYvTI25gpuDr+K5mf1QmGeLoLAKPJZwCX8U2uDkt07o9uf3xv7trjiwywUA8MtpB9xyezkmPvAHtiR4tsfHImpx7ZZEXLlyBTqdDh4eHgb7PTw8oNFomjxHo9E0GV9XV4crV67A07Px/5gJCQl44YUXWm7gN6Cff3BAyRUbPDbJX9yn18lwKt0R+7a44dML38PKyvg1XD3qAAA+A6sM9nv3r0LhpcbJX4OA4fU95ssX5HB2uSoZR9SaqiutcOGcHXr7VsPWTo9ZT2vwn5h+OPZlfbKRk20Pv8GV+MecIpz81gm/F9T/03rxRzuD6+T+LId775o2Hz+ZTw8Ln53RxSdWtvvqDJnM8C9YEIRG+64X39T+BkuWLMGCBQvE16WlpfD29jZ3uDekW+4oQ+JX5wz2vfZEX3j3r8L0eYXXTSAAwMO7Bq7KGuT9YljGvfSrHCFjyyTP+/m0PQDAxb3W9IETtRAbWz28+1fj9FFHWFsLsLEVxOpaA70OkHWr//eoINcWV/Kt0ecmw6S5t181Mr5yBnUegoWrMwQmEa3Dzc0NVlZWjaoOhYWFjaoNDZRKZZPx1tbWcHV1bfIcuVwOuZz9R0s4dNej382G/xjaOejh1FMn7i8ttkLRJVvxN7DcP5OFnu61cHGvg0wG/OPRImx7VQm/QZXwG1yJg/9zQe4vdnhm0wUA9SXjcyccMXRkORyddTif5YDE5V4IC9fCvQ+TCGo7sc9dRvoBZxReskEPtzpExRfCwUmHlA9ccLXcCt8fcUTss/moqeqGgjwbDFFVYPw/ivH2C15/XkGGDze4I3qRBr+etcevZ+wx/v4/4H1TNV6KdWnXz0am4VM8jWu3JMLW1hbBwcFISUnBvffeK+5PSUnBlClTmjxHpVLhk08+Mdh34MABhISENDkfgtpO+gEFXnvir/tDJDzaDwDwzwUaRC+qT/ymxRahtkqGjc/3RlmJFfwGVSHh/V/g1a++vGtjKyB1Xw9sX61EbY0M7r1rEBH1B+6fW9Do/Yhak5tnLZa8dRHOLjpof7fCuROOiI8cgMJL9ROEEx71wUNL8/HU+otw6qFD4SVbJK3yxKfv/fXLzJ53esHGTo85L1yGUw8dfj1rhyX/54f8i/ylhroOmdDQD2gHu3btQnR0NDZu3AiVSoW3334bmzZtwpkzZ+Dj44MlS5bg0qVLeO+99wDUL/EMDAzEI488gtjYWKSlpWHOnDl4//33m706o7S0FAqFAsU/+sHZqWvPmqUb10SvW9p7CEStpk6oxSF8DK1WC2fn1mkPNXxX3Jvyb9g42l7/BAm1FTXYM2FLq461PbXrnIgZM2bg999/x3/+8x/k5+cjMDAQ+/fvh4+PDwAgPz/f4J4Rvr6+2L9/P5544gm8+eab8PLywrp167i8k4iIWgXbGca1+8TKuXPnYu7cuU0eS0pKarRv1KhROHHiRCuPioiIiK6n3ZMIIiKijorPzjCOSQQREZEEtjOM48xCIiIiMgsrEURERBJYiTCOSQQREZEEJhHGsZ1BREREZmElgoiISAIrEcYxiSAiIpIgwLJlmu12S+g2wiSCiIhIAisRxnFOBBEREZmFlQgiIiIJrEQYxySCiIhIApMI49jOICIiIrOwEkFERCSBlQjjmEQQERFJEAQZBAsSAUvO7QzYziAiIiKzsBJBREQkQQ+ZRTebsuTczoCVCCIiIgkNcyIs2UyxYcMGDBkyBM7OznB2doZKpcLnn38uHhcEAcuXL4eXlxfs7e0xevRonDlzxuAa1dXVmD9/Ptzc3ODo6IjJkycjLy/PIKa4uBjR0dFQKBRQKBSIjo5GSUmJyX8/TCKIiIg6iD59+uDll19GRkYGMjIyMHbsWEyZMkVMFF555RWsXr0a69evx/Hjx6FUKjFhwgSUlZWJ14iPj8eePXuQnJyMw4cPo7y8HJGRkdDpdGJMVFQUsrKyoFaroVarkZWVhejoaJPHKxMEoavf2ttAaWkpFAoFin/0g7MTcyjqmiZ63dLeQyBqNXVCLQ7hY2i1Wjg7O7fKezR8V9y653FYO8rNvk5dRTWO3fs6cnNzDcYql8shlzfvui4uLvjvf/+Lhx56CF5eXoiPj8dTTz0FoL7q4OHhgVWrVuGRRx6BVqtFr169sG3bNsyYMQMAcPnyZXh7e2P//v2YOHEisrOzMWjQIKSnpyM0NBQAkJ6eDpVKhXPnzsHf37/Zn4/fokRERBJaqp3h7e0ttg4UCgUSEhKu+946nQ7JycmoqKiASqVCTk4ONBoNwsPDxRi5XI5Ro0bhyJEjAIDMzEzU1tYaxHh5eSEwMFCMSUtLg0KhEBMIAAgLC4NCoRBjmosTK4mIiCS01BLPpioRUk6dOgWVSoWqqip0794de/bswaBBg8QveA8PD4N4Dw8PXLx4EQCg0Whga2uLnj17NorRaDRijLu7e6P3dXd3F2Oai0kEERFRK2uYKNkc/v7+yMrKQklJCXbv3o2ZM2ciNTVVPC6TGSY1giA02neta2Oaim/Oda7FdgYREZEEwcJWhjlVDFtbW/Tv3x8hISFISEjA0KFD8frrr0OpVAJAo2pBYWGhWJ1QKpWoqalBcXGx0ZiCgoJG71tUVNSoynE9TCKIiIgkCAAEwYKtJcYgCKiuroavry+USiVSUlLEYzU1NUhNTcXIkSMBAMHBwbCxsTGIyc/Px+nTp8UYlUoFrVaLY8eOiTFHjx6FVqsVY5qL7QwiIqIOYunSpYiIiIC3tzfKysqQnJyMQ4cOQa1WQyaTIT4+HitXrsSAAQMwYMAArFy5Eg4ODoiKigIAKBQKxMTEYOHChXB1dYWLiwsWLVqEoKAgjB8/HgAQEBCASZMmITY2FomJiQCA2bNnIzIy0qSVGQCTCCIiIkl6yCBrwztWFhQUIDo6Gvn5+VAoFBgyZAjUajUmTJgAAFi8eDEqKysxd+5cFBcXIzQ0FAcOHICTk5N4jTVr1sDa2hrTp09HZWUlxo0bh6SkJFhZWYkxO3bsQFxcnLiKY/LkyVi/fr3Jn4/3iSDqgnifCOrK2vI+EUP+twhWDubfJ0J3tRo/3P9qq461PfFblIiIiMzCdgYREZEEvSCDzIL7RJj67IzOhkkEERGRhIZVFpac35WxnUFERERmYSWCiIhIQkvd9rqrYhJBREQkgUmEcUwiiIiIJHBipXGcE0FERERmYSWCiIhIAldnGMckgoiISEJ9EmHJnIgWHEwHxHYGERERmYWVCCIiIglcnWEckwgiIiIJwp+bJed3ZWxnEBERkVlYiSAiIpLAdoZxTCKIiIiksJ9hFJMIIiIiKRZWItDFKxGcE0FERERmYSWCiIhIAu9YaRyTCCIiIgmcWGkc2xlERERkFlYiiIiIpAgyyyZHdvFKBJMIIiIiCZwTYRzbGURERGQWViKIiIik8GZTRjGJICIiksDVGcY1K4lYt25dsy8YFxdn9mCIiIio82hWErFmzZpmXUwmkzGJICKirqWLtyQs0awkIicnp7XHQURE1OGwnWGc2aszampqcP78edTV1bXkeIiIiDoOoQW2LszkJOLq1auIiYmBg4MDBg8ejN9++w1A/VyIl19+ucUHSERERB2TyUnEkiVL8P333+PQoUOws7MT948fPx67du1q0cERERG1L1kLbF2XyUs89+7di127diEsLAwy2V9/OYMGDcIvv/zSooMjIiJqV7xPhFEmVyKKiorg7u7eaH9FRYVBUkFERERdm8lJxIgRI/DZZ5+JrxsSh02bNkGlUrXcyIiIiNobJ1YaZXI7IyEhAZMmTcLZs2dRV1eH119/HWfOnEFaWhpSU1NbY4xERETtg0/xNMrkSsTIkSPx3Xff4erVq7jppptw4MABeHh4IC0tDcHBwa0xRiIiIuqAzHp2RlBQELZu3drSYyEiIupQ+Chw48xKInQ6Hfbs2YPs7GzIZDIEBARgypQpsLbm87yIiKgL4eoMo0z+1j99+jSmTJkCjUYDf39/AMCPP/6IXr16Yd++fQgKCmrxQRIREVHHY/KciIcffhiDBw9GXl4eTpw4gRMnTiA3NxdDhgzB7NmzW2OMRERE7aNhYqUlmwkSEhIwYsQIODk5wd3dHVOnTsX58+cNYmbNmgWZTGawhYWFGcRUV1dj/vz5cHNzg6OjIyZPnoy8vDyDmOLiYkRHR0OhUEChUCA6OholJSUmjdfkJOL7779HQkICevbsKe7r2bMnVqxYgaysLFMvR0RE1GHJBMs3U6SmpmLevHlIT09HSkoK6urqEB4ejoqKCoO4SZMmIT8/X9z2799vcDw+Ph579uxBcnIyDh8+jPLyckRGRkKn04kxUVFRyMrKglqthlqtRlZWFqKjo00ar8ntDH9/fxQUFGDw4MEG+wsLC9G/f39TL0dERNRxtfGcCLVabfB6y5YtcHd3R2ZmJu68805xv1wuh1KpbPIaWq0WmzdvxrZt2zB+/HgAwPbt2+Ht7Y2DBw9i4sSJyM7OhlqtRnp6OkJDQwH8db+n8+fPi9MVrqdZlYjS0lJxW7lyJeLi4vDhhx8iLy8PeXl5+PDDDxEfH49Vq1Y1602JiIhuJH//Hi0tLUV1dXWzztNqtQAAFxcXg/2HDh2Cu7s7Bg4ciNjYWBQWForHMjMzUVtbi/DwcHGfl5cXAgMDceTIEQBAWloaFAqFmEAAQFhYGBQKhRjTHM2qRPTo0cPgltaCIGD69OniPuHPNSz33HOPQamEiIioU2uhm015e3sb7H7++eexfPly46cKAhYsWIDbb78dgYGB4v6IiAjcf//98PHxQU5ODp599lmMHTsWmZmZkMvl0Gg0sLW1NZh2AAAeHh7QaDQAAI1G0+QjLNzd3cWY5mhWEvH11183+4JERERdRgu1M3Jzc+Hs7Czulsvl1z31scceww8//IDDhw8b7J8xY4b458DAQISEhMDHxwefffYZpk2bJj0UQTAoCDT1vKtrY66nWUnEqFGjmn1BIiIiMuTs7GyQRFzP/PnzsW/fPnzzzTfo06eP0VhPT0/4+Pjgp59+AgAolUrU1NSguLjYoBpRWFiIkSNHijEFBQWNrlVUVAQPD49mj9Pk1RkNrl69inPnzuGHH34w2IiIiLqMNn4AlyAIeOyxx/DRRx/hq6++gq+v73XP+f3335GbmwtPT08AQHBwMGxsbJCSkiLG5Ofn4/Tp02ISoVKpoNVqcezYMTHm6NGj0Gq1YkxzmLw6o6ioCP/+97/x+eefN3mccyKIiKjLaOPVGfPmzcPOnTvx8ccfw8nJSZyfoFAoYG9vj/Lycixfvhz33XcfPD09ceHCBSxduhRubm649957xdiYmBgsXLgQrq6ucHFxwaJFixAUFCSu1ggICMCkSZMQGxuLxMREAMDs2bMRGRnZ7JUZgBmViPj4eBQXFyM9PR329vZQq9XYunUrBgwYgH379pl6OSIiIvrThg0boNVqMXr0aHh6eorbrl27AABWVlY4deoUpkyZgoEDB2LmzJkYOHAg0tLS4OTkJF5nzZo1mDp1KqZPn47bbrsNDg4O+OSTT2BlZSXG7NixA0FBQQgPD0d4eDiGDBmCbdu2mTRekysRX331FT7++GOMGDEC3bp1g4+PDyZMmABnZ2ckJCTg7rvvNvWSREREHVMbPwpcuM4Tu+zt7fHFF19c9zp2dnZ444038MYbb0jGuLi4YPv27SaN71omVyIqKirEZSEuLi4oKioCUP9kzxMnTlg0GCIioo6kre9Y2dmYnET4+/uL9/G+5ZZbkJiYiEuXLmHjxo3ipA4iIiLq+kxuZ8THxyM/Px9A/c0yJk6ciB07dsDW1hZJSUktPT4iIqL2w0eBG2VyEvHggw+Kfx42bBguXLiAc+fOoW/fvnBzc2vRwREREVHHZXIScS0HBwcMHz68JcZCRETUochg2bwGC6ZkdgrNSiIWLFjQ7AuuXr3a7MEQERFR59GsJOLkyZPNupgp99tub9MemA5rK7v2HgZRq7Dyr2rvIRC1GkFXDfzUVm/Wtks8Oxs+gIuIiEgKJ1YaZfazM4iIiOjGZvHESiIioi6LlQijmEQQERFJsPSuk7xjJREREVETWIkgIiKSwnaGUWZVIrZt24bbbrsNXl5euHjxIgBg7dq1+Pjjj1t0cERERO1KaIGtCzM5idiwYQMWLFiAu+66CyUlJdDpdACAHj16YO3atS09PiIiIuqgTE4i3njjDWzatAnLli2DlZWVuD8kJASnTp1q0cERERG1Jz4K3DiT50Tk5ORg2LBhjfbL5XJUVFS0yKCIiIg6BN6x0iiTKxG+vr7IyspqtP/zzz/HoEGDWmJMREREHQPnRBhlciXiySefxLx581BVVQVBEHDs2DG8//77SEhIwDvvvNMaYyQiIqIOyOQk4t///jfq6uqwePFiXL16FVFRUejduzdef/11PPDAA60xRiIionbBm00ZZ9Z9ImJjYxEbG4srV65Ar9fD3d29pcdFRETU/nifCKMsutmUm5tbS42DiIiIOhmTkwhfX1/IZNKzTX/99VeLBkRERNRhWLpMk5UIQ/Hx8Qava2trcfLkSajVajz55JMtNS4iIqL2x3aGUSYnEY8//niT+998801kZGRYPCAiIiLqHFrsKZ4RERHYvXt3S12OiIio/fE+EUa12FM8P/zwQ7i4uLTU5YiIiNodl3gaZ3ISMWzYMIOJlYIgQKPRoKioCG+99VaLDo6IiIg6LpOTiKlTpxq87tatG3r16oXRo0fj5ptvbqlxERERUQdnUhJRV1eHfv36YeLEiVAqla01JiIioo6BqzOMMmlipbW1NR599FFUV1e31niIiIg6DD4K3DiTV2eEhobi5MmTrTEWIiIi6kRMnhMxd+5cLFy4EHl5eQgODoajo6PB8SFDhrTY4IiIiNpdF68mWKLZScRDDz2EtWvXYsaMGQCAuLg48ZhMJoMgCJDJZNDpdC0/SiIiovbAORFGNTuJ2Lp1K15++WXk5OS05niIiIiok2h2EiEI9emUj49Pqw2GiIioI+HNpowzaU6Esad3EhERdTlsZxhlUhIxcODA6yYSf/zxh0UDIiIios7BpCTihRdegEKhaK2xEBERdShsZxhnUhLxwAMPwN3dvbXGQkRE1LGwnWFUs282xfkQRERE9HfNTiIaVmcQERHdMIQW2EyQkJCAESNGwMnJCe7u7pg6dSrOnz9vOCRBwPLly+Hl5QV7e3uMHj0aZ86cMYiprq7G/Pnz4ebmBkdHR0yePBl5eXkGMcXFxYiOjoZCoYBCoUB0dDRKSkpMGm+zkwi9Xs9WBhER3VDa+tkZqampmDdvHtLT05GSkoK6ujqEh4ejoqJCjHnllVewevVqrF+/HsePH4dSqcSECRNQVlYmxsTHx2PPnj1ITk7G4cOHUV5ejsjISIMbQkZFRSErKwtqtRpqtRpZWVmIjo42abwm3/aaiIjohtHGcyLUarXB6y1btsDd3R2ZmZm48847IQgC1q5di2XLlmHatGkA6m8G6eHhgZ07d+KRRx6BVqvF5s2bsW3bNowfPx4AsH37dnh7e+PgwYOYOHEisrOzoVarkZ6ejtDQUADApk2boFKpcP78efj7+zdrvCY/gIuIiIhMU1paarA192nYWq0WAODi4gIAyMnJgUajQXh4uBgjl8sxatQoHDlyBACQmZmJ2tpagxgvLy8EBgaKMWlpaVAoFGICAQBhYWFQKBRiTHMwiSAiIpLSQnMivL29xbkHCoUCCQkJ139rQcCCBQtw++23IzAwEACg0WgAAB4eHgaxHh4e4jGNRgNbW1v07NnTaExTUxTc3d3FmOZgO4OIiEhCS90nIjc3F87OzuJ+uVx+3XMfe+wx/PDDDzh8+HDj616zYrLhIZjGXBvTVHxzrvN3rEQQERG1MmdnZ4PteknE/PnzsW/fPnz99dfo06ePuF+pVAJAo2pBYWGhWJ1QKpWoqalBcXGx0ZiCgoJG71tUVNSoymEMkwgiIiIpbbzEUxAEPPbYY/joo4/w1VdfwdfX1+C4r68vlEolUlJSxH01NTVITU3FyJEjAQDBwcGwsbExiMnPz8fp06fFGJVKBa1Wi2PHjokxR48ehVarFWOag+0MIiIiCW192+t58+Zh586d+Pjjj+Hk5CRWHBQKBezt7SGTyRAfH4+VK1diwIABGDBgAFauXAkHBwdERUWJsTExMVi4cCFcXV3h4uKCRYsWISgoSFytERAQgEmTJiE2NhaJiYkAgNmzZyMyMrLZKzMAJhFEREQdxoYNGwAAo0ePNti/ZcsWzJo1CwCwePFiVFZWYu7cuSguLkZoaCgOHDgAJycnMX7NmjWwtrbG9OnTUVlZiXHjxiEpKQlWVlZizI4dOxAXFyeu4pg8eTLWr19v0nhlwg12K8rS0lIoFAqMGf40rK3s2ns4RK2iW1lVew+BqNXU6arx5U9roNVqDSYrtqSG74qAeSthJTf/u0JXXYXsN5e26ljbEysRREREUvgALqM4sZKIiIjMwkoEERGRBNmfmyXnd2VMIoiIiKSwnWEUkwgiIiIJbb3Es7PhnAgiIiIyCysRREREUtjOMIpJBBERkTFdPBGwBNsZREREZBZWIoiIiCRwYqVxTCKIiIikcE6EUWxnEBERkVlYiSAiIpLAdoZxTCKIiIiksJ1hFNsZREREZBZWIoiIiCSwnWEckwgiIiIpbGcYxSSCiIhICpMIozgngoiIiMzCSgQREZEEzokwjkkEERGRFLYzjGI7g4iIiMzCSgQREZEEmSBAJphfTrDk3M6ASQQREZEUtjOMYjuDiIiIzMJKBBERkQSuzjCOSQQREZEUtjOMYjuDiIiIzMJKBBERkQS2M4xjEkFERCSF7QyjmEQQERFJYCXCOM6JICIiIrOwEkFERCSF7QyjmEQQEREZ0dVbEpZgO4OIiIjMwkoEERGRFEGo3yw5vwtjEkFERCSBqzOMYzuDiIiIzMJKBBERkRSuzjCKSQQREZEEmb5+s+T8roztDCIiIjILkwhqlsDBBVj+zCHs2PIR1Pt2QBWaa3D8NtVvWLH8K+za/iHU+3bAz/cPI1cT8OLzXzV5ne6O1Xjyie+w+/0PsPv9D/DkE9/B0bGmFT4RkXH29rWYPe97JL3/Ofao9+DVN77GAP+/fq579KzCE09lYNv/PsNHn+/Ff1YdhlfvMvF4d6cazJmfhbe3foGPPt+LpOT9eGR+Fhwca9vj45C5hBbYTPTNN9/gnnvugZeXF2QyGfbu3WtwfNasWZDJZAZbWFiYQUx1dTXmz58PNzc3ODo6YvLkycjLyzOIKS4uRnR0NBQKBRQKBaKjo1FSUmLSWJlEULPYyeuQk9MDb70dInn8THYvbNl6y3Wvde/kcxAEWZPHnlr0Hfx8i/HM8jF4ZvkY+PkW48knjlgydCKzPP7kCQwLKcCrCSGY+9AEnMzwwMpXv4WrWyUAAc++mAZPzwr85xkV5s8eh8ICB6x89TDkdnUAAFfXSri6VeKdjUGYGzMea1aFIGREAeKfzGzfD0YmaVidYclmqoqKCgwdOhTr16+XjJk0aRLy8/PFbf/+/QbH4+PjsWfPHiQnJ+Pw4cMoLy9HZGQkdDqdGBMVFYWsrCyo1Wqo1WpkZWUhOjrapLG2axJxvWyrKampqQgODoadnR38/PywcePG1h8oIeNEb2zdcQu+S+vb5PEvD/lh564gnPxeafQ6vv2KMW3KOaxZF9bomHcfLUYE52Pt+jBkn++F7PO98PqbYQi79RL69C5tkc9B1By2tjrcduclvJsYhNM/9EL+5e7YsXUQNBpH3D35V/TuU46AwX9g/dph+Om8Cy7lOuGttcNgZ1+H0WPrq2sXLyiw4nkVjqV5QXO5O74/6Y6tmwcjVJWPbt26eKO8K2m4T4QlG4DS0lKDrbq6WvItIyIi8NJLL2HatGmSMXK5HEqlUtxcXFzEY1qtFps3b8Zrr72G8ePHY9iwYdi+fTtOnTqFgwcPAgCys7OhVqvxzjvvQKVSQaVSYdOmTfj0009x/vz5Zv/1tGsS0Zxs6+9ycnJw11134Y477sDJkyexdOlSxMXFYffu3a08UmoJcts6PL3oMN58OwTFJfaNjgfcfAXl5TY4/6ObuO/ceTeUl9sg4Oaithwq3eCsrPSwshJQU2NlsL+m2gqDgq7AxqY+Caip+eufUL1ehrq6bhgU9LvkdR0da3H1qjX0ehaBbzTe3t5i20ChUCAhIcGi6x06dAju7u4YOHAgYmNjUVhYKB7LzMxEbW0twsPDxX1eXl4IDAzEkSP1ld20tDQoFAqEhoaKMWFhYVAoFGJMc7Tr6oyIiAhEREQ0O37jxo3o27cv1q5dCwAICAhARkYGXn31Vdx3331NnlNdXW2Q8ZWW8jfa9vLIw5nIPtcL6Ue9mzzes2clSrR2jfaXaO3g0rOytYdHJKqstMHZ0y74v+hs5F50QkmxHUaNzYV/wB+4nNcdub85oUDjgH/HnsYbrw1HVZU17r3/J7i4VsHFtemfVSfnavxf9Dl8/olfG38askRL3WwqNzcXzs7O4n65XG72NSMiInD//ffDx8cHOTk5ePbZZzF27FhkZmZCLpdDo9HA1tYWPXv2NDjPw8MDGo0GAKDRaODu7t7o2u7u7mJMc3SqJZ5paWkGmRUATJw4EZs3b0ZtbS1sbGwanZOQkIAXXnihrYZIEsJuzcPQIQWYF3+dpLGJ/1llMkjOoSBqLa8mjMATizOx/cP90Olk+PnHHjj0pTf6DyiBTtcNK54Pw+NPZuKDTz6BTifDyUx3HE/3aPJa9g61eCHhCH676IQdWwPa+JOQRVroPhHOzs4GSYQlZsyYIf45MDAQISEh8PHxwWeffWa0BSIIAmSyv/4t/fufpWKup1MlERqNBh4ehv+Tenh4oK6uDleuXIGnp2ejc5YsWYIFCxaIr0tLS+Ht3fRvwtR6hg7RwFNZht3v/89g/zNPf4szZ3th8bIJKC62R48eVY3OVThXobikcYWCqDVpLnfHU/GjILerg4NDLYr/sMfTzx2FRuMIAPj5x56YHzseDo61sLbWo1Qrx5q3vsJP5w1/+7O3r8WLqw6jstIKLz6rgk7HVga1LE9PT/j4+OCnn34CACiVStTU1KC4uNigGlFYWIiRI0eKMQUFBY2uVVRU1Oh71phOlUQAjTMn4c9JK1KZk1wut6hsRC3jgw8HQ32gv8G+xPWf4e3Nw5F+vA8AIPucG7p3r8XAAVfw40/18yL8B15B9+61yD7Xq83HTAQA1VXWqK6yRvfuNRg+ogDvJgYaHL9aUV8B9epdhv4Di/Heu4PFY/YOtXjplcOore2G/ywbidpawzkW1PF1hmdn/P7778jNzRV/kQ4ODoaNjQ1SUlIwffp0AEB+fj5Onz6NV155BQCgUqmg1Wpx7Ngx3HrrrQCAo0ePQqvViolGc3SqJEKpVDbq1RQWFsLa2hqurq7tNKobg51dLbw8/1oDr/Qoh5/vHygrk6PoiiO6d6+Ge68KuLrU94MbVlMUF9ujuOSv7VqFRY4oKOgOAMjNU+B4pifiHzuKdW/VT/Z5fN5RpB/rjbxLLVMGJGqu4SM0kAHIy3WCV+9yPDTnFC7ldkfK5/0AALePyoO2RI6iQnv08yvFI499j/TvvHAyo/63OHv7Wqz472HI5XX470oVHBzq4OBQv/xTq5VDr2eLrlNoh6d4lpeX4+effxZf5+TkICsrCy4uLnBxccHy5ctx3333wdPTExcuXMDSpUvh5uaGe++9FwCgUCgQExODhQsXwtXVFS4uLli0aBGCgoIwfvx4APVzCidNmoTY2FgkJiYCAGbPno3IyEj4+/s3e6ydKolQqVT45JNPDPYdOHAAISEhTc6HoJYzsP8feGXlQfH1Iw+fAACkfOmH115XQXVrHhbGp4vHly7+DgCw/f0gbH9/SLPfZ9Vrt2Hu7AyseOFLAMDRY33wZuKIlvgIRCZxdKzDrIdPw61XJcrKbPHdN17YujlQbEe4uFYhdu4P6NGzCsW/2+PLA33x/ra/5jv0H1iCmwfV35zq3R1fGFx71gOTUFjg2HYfhjqVjIwMjBkzRnzd0JKfOXMmNmzYgFOnTuG9995DSUkJPD09MWbMGOzatQtOTk7iOWvWrIG1tTWmT5+OyspKjBs3DklJSbCy+qsatmPHDsTFxYlzDSdPntzs1ZINZILQfg87/3u2NWzYMKxevRpjxoyBi4sL+vbtiyVLluDSpUt47733ANRnY4GBgXjkkUcQGxuLtLQ0zJkzB++//77k6oxrlZaWQqFQYMzwp2FtxT47dU3dyhrPLSHqKup01fjypzXQarUtNlnxWg3fFaqI/8DaxvzvirraKqR9/lyrjrU9tWslwli2lZSUhPz8fPz222/icV9fX+zfvx9PPPEE3nzzTXh5eWHdunXNTiCIiIhMwqd4GtWuScTo0aNhrBCSlJTUaN+oUaNw4sSJVhwVERERNUenmhNBRETUljrD6oz2xCSCiIhIil6o3yw5vwtjEkFERCSFcyKM4q3TiIiIyCysRBAREUmQwcI5ES02ko6JSQQREZGUdrhjZWfCdgYRERGZhZUIIiIiCVziaRyTCCIiIilcnWEU2xlERERkFlYiiIiIJMgEATILJkdacm5nwCSCiIhIiv7PzZLzuzC2M4iIiMgsrEQQERFJYDvDOCYRREREUrg6wygmEURERFJ4x0qjOCeCiIiIzMJKBBERkQTesdI4JhFERERS2M4wiu0MIiIiMgsrEURERBJk+vrNkvO7MiYRREREUtjOMIrtDCIiIjILKxFERERSeLMpo5hEEBERSeBtr41jO4OIiIjMwkoEERGRFE6sNIpJBBERkRQBgCXLNLt2DsEkgoiISArnRBjHORFERERkFlYiiIiIpAiwcE5Ei42kQ2ISQUREJIUTK41iO4OIiIjMwkoEERGRFD0AmYXnd2FMIoiIiCRwdYZxbGcQERGRWViJICIiksKJlUYxiSAiIpLCJMIotjOIiIg6kG+++Qb33HMPvLy8IJPJsHfvXoPjgiBg+fLl8PLygr29PUaPHo0zZ84YxFRXV2P+/Plwc3ODo6MjJk+ejLy8PIOY4uJiREdHQ6FQQKFQIDo6GiUlJSaNlUkEERGRlIZKhCWbiSoqKjB06FCsX7++yeOvvPIKVq9ejfXr1+P48eNQKpWYMGECysrKxJj4+Hjs2bMHycnJOHz4MMrLyxEZGQmdTifGREVFISsrC2q1Gmq1GllZWYiOjjZprGxnEBERSWmHJZ4RERGIiIho8pggCFi7di2WLVuGadOmAQC2bt0KDw8P7Ny5E4888gi0Wi02b96Mbdu2Yfz48QCA7du3w9vbGwcPHsTEiRORnZ0NtVqN9PR0hIaGAgA2bdoElUqF8+fPw9/fv1ljZSWCiIhIQsMST0s2ACgtLTXYqqurzRpPTk4ONBoNwsPDxX1yuRyjRo3CkSNHAACZmZmora01iPHy8kJgYKAYk5aWBoVCISYQABAWFgaFQiHGNAeTCCIiolbm7e0tzj1QKBRISEgw6zoajQYA4OHhYbDfw8NDPKbRaGBra4uePXsajXF3d290fXd3dzGmOdjOICIiktJCqzNyc3Ph7Ows7pbL5RYNSyYz7LEIgtBoX+OhGMY0Fd+c6/wdKxFERERS9ILlGwBnZ2eDzdwkQqlUAkCjakFhYaFYnVAqlaipqUFxcbHRmIKCgkbXLyoqalTlMIZJBBERUSfh6+sLpVKJlJQUcV9NTQ1SU1MxcuRIAEBwcDBsbGwMYvLz83H69GkxRqVSQavV4tixY2LM0aNHodVqxZjmYDuDiIhISjvcbKq8vBw///yz+DonJwdZWVlwcXFB3759ER8fj5UrV2LAgAEYMGAAVq5cCQcHB0RFRQEAFAoFYmJisHDhQri6usLFxQWLFi1CUFCQuFojICAAkyZNQmxsLBITEwEAs2fPRmRkZLNXZgBMIoiIiIywMImA6edmZGRgzJgx4usFCxYAAGbOnImkpCQsXrwYlZWVmDt3LoqLixEaGooDBw7AyclJPGfNmjWwtrbG9OnTUVlZiXHjxiEpKQlWVlZizI4dOxAXFyeu4pg8ebLkvSmkyAShi9+T8xqlpaVQKBQYM/xpWFvZtfdwiFpFt7Kq9h4CUaup01Xjy5/WQKvVGkxWbEkN3xXj/eJg3c38SZB1+moc/HVdq461PbESQUREJIXPzjCKSQQREZEUvQBzWhKG53ddXJ1BREREZmElgoiISIqgr98sOb8LYxJBREQkhXMijGISQUREJIVzIozinAgiIiIyCysRREREUtjOMIpJBBERkRQBFiYRLTaSDontDCIiIjILKxFERERS2M4wikkEERGRFL0egAX3etB37ftEsJ1BREREZmElgoiISArbGUYxiSAiIpLCJMIotjOIiIjILKxEEBERSeFtr41iEkFERCRBEPQQLHgSpyXndgZMIoiIiKQIgmXVBM6JICIiImqMlQgiIiIpgoVzIrp4JYJJBBERkRS9HpBZMK+hi8+JYDuDiIiIzMJKBBERkRS2M4xiEkFERCRB0OshWNDO6OpLPNnOICIiIrOwEkFERCSF7QyjmEQQERFJ0QuAjEmEFLYziIiIyCysRBAREUkRBACW3Ceia1cimEQQERFJEPQCBAvaGQKTCCIiohuUoIdllQgu8SQiIiJqhJUIIiIiCWxnGMckgoiISArbGUbdcElEQ1ZYp6tu55EQtZ5u/PmmLqzh3++2+C2/DrUW3WuqDrUtN5gO6IZLIsrKygAA336/pp1HQkREligrK4NCoWiVa9va2kKpVOKwZr/F11IqlbC1tW2BUXU8MqGrN2yuodfrcfnyZTg5OUEmk7X3cG4IpaWl8Pb2Rm5uLpydndt7OEQtjj/jbUsQBJSVlcHLywvdurXe+oCqqirU1NRYfB1bW1vY2dm1wIg6nhuuEtGtWzf06dOnvYdxQ3J2duY/sNSl8We87bRWBeLv7OzsuuyXf0vhEk8iIiIyC5MIIiIiMguTCGp1crkczz//PORyeXsPhahV8GecblQ33MRKIiIiahmsRBAREZFZmEQQERGRWZhEEBERkVmYRBAREZFZmERQi3jrrbfg6+sLOzs7BAcH49tvvzUan5qaiuDgYNjZ2cHPzw8bN25so5ESmeabb77BPffcAy8vL8hkMuzdu/e65/Dnm24UTCLIYrt27UJ8fDyWLVuGkydP4o477kBERAR+++23JuNzcnJw11134Y477sDJkyexdOlSxMXFYffu3W08cqLrq6iowNChQ7F+/fpmxfPnm24kXOJJFgsNDcXw4cOxYcMGcV9AQACmTp2KhISERvFPPfUU9u3bh+zsbHHfnDlz8P333yMtLa1NxkxkDplMhj179mDq1KmSMfz5phsJKxFkkZqaGmRmZiI8PNxgf3h4OI4cOdLkOWlpaY3iJ06ciIyMDNTWdu3H5lLXx59vupEwiSCLXLlyBTqdDh4eHgb7PTw8oNFomjxHo9E0GV9XV4crV6602liJ2gJ/vulGwiSCWsS1j1UXBMHoo9abim9qP1FnxJ9vulEwiSCLuLm5wcrKqlHVobCwsNFvYw2USmWT8dbW1nB1dW21sRK1Bf58042ESQRZxNbWFsHBwUhJSTHYn5KSgpEjRzZ5jkqlahR/4MABhISEwMbGptXGStQW+PNNNxImEWSxBQsW4J133sG7776L7OxsPPHEE/jtt98wZ84cAMCSJUvwr3/9S4yfM2cOLl68iAULFiA7OxvvvvsuNm/ejEWLFrXXRyCSVF5ejqysLGRlZQGoX8KZlZUlLmHmzzfd0ASiFvDmm28KPj4+gq2trTB8+HAhNTVVPDZz5kxh1KhRBvGHDh0Shg0bJtja2gr9+vUTNmzY0MYjJmqer7/+WgDQaJs5c6YgCPz5phsb7xNBREREZmE7g4iIiMzCJIKIiIjMwiSCiIiIzMIkgoiIiMzCJIKIiIjMwiSCiIiIzMIkgoiIiMzCJIKIiIjMwiSCqB0sX74ct9xyi/h61qxZmDp1apuP48KFC5DJZOItnZvSr18/rF27ttnXTEpKQo8ePSwem0wmw969ey2+DhG1HiYRRH+aNWsWZDIZZDIZbGxs4Ofnh0WLFqGioqLV3/v1119HUlJSs2Kb88VPRNQWrNt7AEQdyaRJk7BlyxbU1tbi22+/xcMPP4yKigps2LChUWxtbW2LPZVRoVC0yHWIiNoSKxFEfyOXy6FUKuHt7Y2oqCg8+OCDYkm9oQXx7rvvws/PD3K5HIIgQKvVYvbs2XB3d4ezszPGjh2L77//3uC6L7/8Mjw8PODk5ISYmBhUVVUZHL+2naHX67Fq1Sr0798fcrkcffv2xYoVKwAAvr6+AIBhw4ZBJpNh9OjR4nlbtmxBQEAA7OzscPPNN+Ott94yeJ9jx45h2LBhsLOzQ0hICE6ePGny39Hq1asRFBQER0dHeHt7Y+7cuSgvL28Ut3fvXgwcOBB2dnaYMGECcnNzDY5/8sknCA4Ohp2dHfz8/PDCCy+grq7O5PEQUfthEkFkhL29PWpra8XXP//8Mz744APs3r1bbCfcfffd0Gg02L9/PzIzMzF8+HCMGzcOf/zxBwDggw8+wPPPP48VK1YgIyMDnp6ejb7cr7VkyRKsWrUKzz77LM6ePYudO3fCw8MDQH0iAAAHDx5Efn4+PvroIwDApk2bsGzZMqxYsQLZ2dlYuXIlnn32WWzduhUAUFFRgcjISPj7+yMzMxPLly836/HU3bp1w7p163D69Gls3boVX331FRYvXmwQc/XqVaxYsQJbt27Fd999h9LSUjzwwAPi8S+++AL//Oc/ERcXh7NnzyIxMRFJSUliokREnUQ7P0WUqMOYOXOmMGXKFPH10aNHBVdXV2H69OmCIAjC888/L9jY2AiFhYVizJdffik4OzsLVVVVBte66aabhMTEREEQBEGlUglz5swxOB4aGioMHTq0yfcuLS0V5HK5sGnTpibHmZOTIwAQTp48abDf29tb2Llzp8G+F198UVCpVIIgCEJiYqLg4uIiVFRUiMc3bNjQ5LX+zsfHR1izZo3k8Q8++EBwdXUVX2/ZskUAIKSnp4v7srOzBQDC0aNHBUEQhDvuuENYuXKlwXW2bdsmeHp6iq8BCHv27JF8XyJqf5wTQfQ3n376Kbp37466ujrU1tZiypQpeOONN8TjPj4+6NWrl/g6MzMT5eXlcHV1NbhOZWUlfvnlFwBAdnY25syZY3BcpVLh66+/bnIM2dnZqK6uxrhx45o97qKiIuTm5iImJgaxsbHi/rq6OnG+RXZ2NoYOHQoHBweDcZjq66+/xsqVK3H27FmUlpairq4OVVVVqKiogKOjIwDA2toaISEh4jk333wzevTogezsbNx6663IzMzE8ePHDSoPOp0OVVVVuHr1qsEYiajjYhJB9DdjxozBhg0bYGNjAy8vr0YTJxu+JBvo9Xp4enri0KFDja5l7jJHe3t7k8/R6/UA6lsaoaGhBsesrKwAAIIgmDWev7t48SLuuusuzJkzBy+++CJcXFxw+PBhxMTEGLR9gPolmtdq2KfX6/HCCy9g2rRpjWLs7OwsHicRtQ0mEUR/4+joiP79+zc7fvjw4dBoNLC2tka/fv2ajAkICEB6ejr+9a9/ifvS09MlrzlgwADY29vjyy+/xMMPP9zouK2tLYD639wbeHh4oHfv3vj111/x4IMPNnndQYMGYdu2baisrBQTFWPjaEpGRgbq6urw2muvoVu3+ilVH3zwQaO4uro6ZGRk4NZbbwUAnD9/HiUlJbj55psB1P+9nT9/3qS/ayLqeJhEEFlg/PjxUKlUmDp1KlatWgV/f39cvnwZ+/fvx9SpUxESEoLHH38cM2fOREhICG6//Xbs2LEDZ86cgZ+fX5PXtLOzw1NPPYXFixfD1tYWt912G4qKinDmzBnExMTA3d0d9vb2UKvV6NOnD+zs7KBQKLB8+XLExcXB2dkZERERqK6uRkZGBoqLi7FgwQJERUVh2bJliImJwTPPPIMLFy7g1VdfNenz3nTTTairq8Mbb7yBe+65B9999x02btzYKM7Gxgbz58/HunXrYGNjg8ceewxhYWFiUvHcc88hMjIS3t7euP/++9GtWzf88MMPOHXqFF566SXT/0MQUbvg6gwiC8hkMuzfvx933nknHnroIQwcOBAPPPAALly4IK6mmDFjBp577jk89dRTCA4OxsWLF/Hoo48ave6zzz6LhQsX4rnnnkNAQABmzJiBwsJCAPXzDdatW4fExER4eXlhypQpAICHH34Y77zzDpKSkhAUFIRRo0YhKSlJXBLavXt3fPLJJzh79iyGDRuGZcuWYdWqVSZ93ltuuQWrV6/GqlWrEBgYiB07diAhIaFRnIODA5566ilERUVBpVLB3t4eycnJ4vGJEyfi008/RUpKCkaMGIGwsDCsXr0aPj4+Jo2HiNqXTGiJRikRERHdcFiJICIiIrMwiSAiIiKzMIkgIiIiszCJICIiIrMwiSAiIiKzMIkgIiIiszCJICIiIrMwiSAiIiKzMIkgIiIiszCJICIiIrMwiSAiIiKz/D8DAU61sr40fAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting confusion matrix\n",
    "plot_confusion_matrix(best_model, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "166411db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class predictions\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ce0ff1",
   "metadata": {},
   "source": [
    "Let's get the Classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ff6c42c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.88      0.83      4751\n",
      "         1.0       0.63      0.47      0.53      2132\n",
      "\n",
      "    accuracy                           0.75      6883\n",
      "   macro avg       0.71      0.67      0.68      6883\n",
      "weighted avg       0.74      0.75      0.74      6883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification score\n",
    "xgb_report = classification_report(y_test, y_pred)\n",
    "print(xgb_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bdd408",
   "metadata": {},
   "source": [
    "Summary of Models:\n",
    "\n",
    "|      **Model**      | **Remainder Accuracy** | **Test Accuracy** | **Recall** | **Precision** | **F1 Score** | **Best Parameters**                                                          |\n",
    "|:-------------------:|:----------------------:|:-----------------:|------------|---------------|--------------|------------------------------------------------------------------------------|\n",
    "| Logistic Regression | 0.696                  | 0.691             | 0.14       | 0.51          | 0.23         | MinMaxScaler(), No dimension reduction,  LR__C=1000, LR__solver='liblinear'  |\n",
    "|  Decision Tree 1    | 0.722                  | 0.717             | 0.26       | 0.60          | 0.36         | max_depth=6                                                                  |\n",
    "| Decision Tree 2     | 0.728                  | 0.704             | 0.34       | 0.54          | 0.42         | max_depth=7, criterion='gini'                                                |\n",
    "| Random Forest 1     | 0.860                  | 0.744             | 0.29       | 0.71          | 0.41         | max_depth=12, criterion='gini'                                               |\n",
    "| Random Forest 2     | 0.784                  | 0.740             | 0.29       | 0.71          | 0.41         | max_depth=10                                                                 |\n",
    "| XGBoost 1           | 0.986                  | 0.749             | 0.47       | 0.63          | 0.53         | learning_rate=0.5, max_depth=6, n_estimators=170                             |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448725f4",
   "metadata": {},
   "source": [
    "This model gives us a much better F1 score (0.53), providing the best recall yet (0.47). The test accuracy score is also quite strong with (0.749). However, it is incredibly overfitting. I will train a model with `max_depth` of 4 to try and reduce overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "17d67045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:33:23] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_components\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:33:23] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.5, max_delta_step=0,\n",
       "              max_depth=4, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_components=170, n_estimators=100,\n",
       "              n_jobs=6, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the model\n",
    "xgb = XGBClassifier(max_depth=4, n_components=170, learning_rate=0.5)\n",
    "\n",
    "# fit the model\n",
    "xgb.fit(X_remainder, y_remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe4efe9",
   "metadata": {},
   "source": [
    "##### Accuracy Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "97465f12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remainder Set Score: 0.8526249515691593\n",
      "Test Set Score: 0.7793113467964551\n",
      "The runtime of your code is: 0:00:00.023003 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "time = timer()\n",
    "# accuracy scores\n",
    "print(f'Remainder Set Score: {xgb.score(X_remainder, y_remainder)}')\n",
    "print(f'Test Set Score: {xgb.score(X_test, y_test)}')\n",
    "runtime = timer(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2253def2",
   "metadata": {},
   "source": [
    "##### Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334e3a0e",
   "metadata": {},
   "source": [
    "Let's plot the confusion matrix for the XGBoost model and get prediction for test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "36faac6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting confusion matrix\n",
    "plot_confusion_matrix(xgb, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "254e61cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class predictions\n",
    "y_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865fa607",
   "metadata": {},
   "source": [
    "Let's get the Classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "791461f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.90      0.85      4751\n",
      "         1.0       0.69      0.52      0.59      2132\n",
      "\n",
      "    accuracy                           0.78      6883\n",
      "   macro avg       0.75      0.71      0.72      6883\n",
      "weighted avg       0.77      0.78      0.77      6883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification score\n",
    "xgb_report = classification_report(y_test, y_pred)\n",
    "print(xgb_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7861b6",
   "metadata": {},
   "source": [
    "Summary of Models:\n",
    "\n",
    "|      **Model**      | **Remainder Accuracy** | **Test Accuracy** | **Recall** | **Precision** | **F1 Score** | **Best Parameters**                                                          |\n",
    "|:-------------------:|:----------------------:|:-----------------:|------------|---------------|--------------|------------------------------------------------------------------------------|\n",
    "| Logistic Regression | 0.696                  | 0.691             | 0.14       | 0.51          | 0.23         | MinMaxScaler(), No dimension reduction,  LR__C=1000, LR__solver='liblinear'  |\n",
    "|  Decision Tree 1    | 0.722                  | 0.717             | 0.26       | 0.60          | 0.36         | max_depth=6                                                                  |\n",
    "| Decision Tree 2     | 0.728                  | 0.704             | 0.34       | 0.54          | 0.42         | max_depth=7, criterion='gini'                                                |\n",
    "| Random Forest 1     | 0.860                  | 0.744             | 0.29       | 0.71          | 0.41         | max_depth=12, criterion='gini'                                               |\n",
    "| Random Forest 2     | 0.784                  | 0.740             | 0.29       | 0.71          | 0.41         | max_depth=10                                                                 |\n",
    "| XGBoost 1           | 0.986                  | 0.749             | 0.47       | 0.63          | 0.53         | learning_rate=0.5, max_depth=6, n_estimators=170                             |\n",
    "| XGBoost 2           | 0.852                  | 0.779             | 0.69       | 0.52          | 0.59         | learning_rate=0.5, max_depth=4, n_estimators=170                             |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d3fad",
   "metadata": {},
   "source": [
    "A `max_depth` of 4 reduces the overfitting significantly while giving a significant increase in test accuracy score (0.779), recall (0.69) and F1 score (0.59). The precision does go down to 0.52 however. \n",
    "\n",
    "This model is significantly better than the other models we have had so far. \n",
    "\n",
    "**XGBoost shows great promise**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a4ff1c",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716e724b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Below is the summary table for modeling and evaluation of models.\n",
    "\n",
    "Summary of Models:\n",
    "\n",
    "|      **Model**      | **Remainder Accuracy** | **Test Accuracy** | **Recall** | **Precision** | **F1 Score** | **Best Parameters**                                                          |\n",
    "|:-------------------:|:----------------------:|:-----------------:|------------|---------------|--------------|------------------------------------------------------------------------------|\n",
    "| Logistic Regression | 0.696                  | 0.691             | 0.14       | 0.51          | 0.23         | MinMaxScaler(), No dimension reduction,  LR__C=1000, LR__solver='liblinear'  |\n",
    "|  Decision Tree 1    | 0.722                  | 0.717             | 0.26       | 0.60          | 0.36         | max_depth=6                                                                  |\n",
    "| Decision Tree 2     | 0.728                  | 0.704             | 0.34       | 0.54          | 0.42         | max_depth=7, criterion='gini'                                                |\n",
    "| Random Forest 1     | 0.860                  | 0.744             | 0.29       | 0.71          | 0.41         | max_depth=12, criterion='gini'                                               |\n",
    "| Random Forest 2     | 0.784                  | 0.740             | 0.29       | 0.71          | 0.41         | max_depth=10                                                                 |\n",
    "| XGBoost 1           | 0.986                  | 0.749             | 0.47       | 0.63          | 0.53         | learning_rate=0.5, max_depth=6, n_estimators=170                             |\n",
    "| XGBoost 2           | 0.852                  | 0.779             | 0.69       | 0.52          | 0.59         | learning_rate=0.5, max_depth=4, n_estimators=170                             |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4165e78e",
   "metadata": {},
   "source": [
    "The XGBoost model with `leanring_rate=0.5`, `max_depth=4` and `n_estimators=170` is by far the best model we have found. It gives us a test accuracy score of ~0.78, a Recall of 0.69, a Precision of 0.52 and a F1 Score of 0.59. \n",
    "\n",
    "I think these values can be further increased by:\n",
    "- Adding more weather features to the dataset\n",
    "- Tuning the hyperparameters in more detail\n",
    "\n",
    "**Note: The Random Forest models give us the best Precision i.e. the least False positives. This would help minimize loss unneeded economic loss by not making people who don't need to evacuate, evacuate.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e9a2a",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearningtest]",
   "language": "python",
   "name": "conda-env-deeplearningtest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
